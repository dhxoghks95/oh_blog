<!DOCTYPE html>
<html class="no-js" lang="en-us">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<title>Bayesian Method with TensorFlow Chapter 1. 연습문제 풀이 - Oh Data Science</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="Bayesian Method with TensorFlow Chapter 1. 연습문제 풀이" />
<meta property="og:description" content="Bayesian Method with TensorFlow - Chapter1 Introduction 연습문제 풀이 기본 설정 #@title Imports and Global Variables (make sure to run this cell) { display-mode: &#34;form&#34; } try: # %tensorflow_version only exists in Colab. %tensorflow_version 2.x except Exception: pass from __future__ import absolute_import, division, print_function #@markdown This sets the warning status (default is `ignore`, since this notebook runs correctly) warning_status = &#34;ignore&#34; #@param [&#34;ignore&#34;, &#34;always&#34;, &#34;module&#34;, &#34;once&#34;, &#34;default&#34;, &#34;error&#34;] import warnings warnings." />
<meta property="og:type" content="article" />
<meta property="og:url" content="http://example.org/ch1example/" />
<meta property="article:published_time" content="2020-08-30T00:00:00+00:00" />
<meta property="article:modified_time" content="2020-08-30T00:00:00+00:00" />

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="Oh Data Science" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">Oh Data Science</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Bayesian Method with TensorFlow Chapter 1. 연습문제 풀이</h1>
			
		</header><div class="content post__content clearfix">
			<h1 id="bayesian-method-with-tensorflow---chapter1-introduction"><strong>Bayesian Method with TensorFlow - Chapter1 Introduction</strong></h1>
<h2 id="연습문제-풀이"><strong>연습문제 풀이</strong></h2>
<h3 id="기본-설정">기본 설정</h3>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e">#@title Imports and Global Variables (make sure to run this cell)  { display-mode: &#34;form&#34; }</span>

<span style="color:#66d9ef">try</span>:
  <span style="color:#75715e"># %tensorflow_version only exists in Colab.</span>
  <span style="color:#f92672">%</span>tensorflow_version <span style="color:#ae81ff">2.</span>x
<span style="color:#66d9ef">except</span> <span style="color:#a6e22e">Exception</span>:
  <span style="color:#66d9ef">pass</span>


<span style="color:#f92672">from</span> __future__ <span style="color:#f92672">import</span> absolute_import, division, print_function


<span style="color:#75715e">#@markdown This sets the warning status (default is `ignore`, since this notebook runs correctly)</span>
warning_status <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;ignore&#34;</span> <span style="color:#75715e">#@param [&#34;ignore&#34;, &#34;always&#34;, &#34;module&#34;, &#34;once&#34;, &#34;default&#34;, &#34;error&#34;]</span>
<span style="color:#f92672">import</span> warnings
warnings<span style="color:#f92672">.</span>filterwarnings(warning_status)
<span style="color:#66d9ef">with</span> warnings<span style="color:#f92672">.</span>catch_warnings():
    warnings<span style="color:#f92672">.</span>filterwarnings(warning_status, category<span style="color:#f92672">=</span><span style="color:#a6e22e">DeprecationWarning</span>)
    warnings<span style="color:#f92672">.</span>filterwarnings(warning_status, category<span style="color:#f92672">=</span><span style="color:#a6e22e">UserWarning</span>)

<span style="color:#f92672">import</span> numpy <span style="color:#f92672">as</span> np
<span style="color:#f92672">import</span> os
<span style="color:#75715e">#@markdown This sets the styles of the plotting (default is styled like plots from [FiveThirtyeight.com](https://fivethirtyeight.com/)</span>
matplotlib_style <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;fivethirtyeight&#39;</span> <span style="color:#75715e">#@param [&#39;fivethirtyeight&#39;, &#39;bmh&#39;, &#39;ggplot&#39;, &#39;seaborn&#39;, &#39;default&#39;, &#39;Solarize_Light2&#39;, &#39;classic&#39;, &#39;dark_background&#39;, &#39;seaborn-colorblind&#39;, &#39;seaborn-notebook&#39;]</span>
<span style="color:#f92672">import</span> matplotlib.pyplot <span style="color:#f92672">as</span> plt; plt<span style="color:#f92672">.</span>style<span style="color:#f92672">.</span>use(matplotlib_style)
<span style="color:#f92672">import</span> matplotlib.axes <span style="color:#f92672">as</span> axes;
<span style="color:#f92672">from</span> matplotlib.patches <span style="color:#f92672">import</span> Ellipse
<span style="color:#f92672">import</span> matplotlib <span style="color:#f92672">as</span> mpl
<span style="color:#75715e">#%matplotlib inline</span>
<span style="color:#f92672">import</span> seaborn <span style="color:#f92672">as</span> sns; sns<span style="color:#f92672">.</span>set_context(<span style="color:#e6db74">&#39;notebook&#39;</span>)
<span style="color:#f92672">from</span> IPython.core.pylabtools <span style="color:#f92672">import</span> figsize
<span style="color:#75715e">#@markdown This sets the resolution of the plot outputs (`retina` is the highest resolution)</span>
notebook_screen_res <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;retina&#39;</span> <span style="color:#75715e">#@param [&#39;retina&#39;, &#39;png&#39;, &#39;jpeg&#39;, &#39;svg&#39;, &#39;pdf&#39;]</span>
<span style="color:#75715e">#%config InlineBackend.figure_format = notebook_screen_res</span>

<span style="color:#f92672">import</span> tensorflow <span style="color:#f92672">as</span> tf

<span style="color:#f92672">import</span> tensorflow_probability <span style="color:#f92672">as</span> tfp
tfd <span style="color:#f92672">=</span> tfp<span style="color:#f92672">.</span>distributions
tfb <span style="color:#f92672">=</span> tfp<span style="color:#f92672">.</span>bijectors

<span style="color:#66d9ef">class</span> <span style="color:#a6e22e">_TFColor</span>(object):
    <span style="color:#e6db74">&#34;&#34;&#34;Enum of colors used in TF docs.&#34;&#34;&#34;</span>
    red <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;#F15854&#39;</span>
    blue <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;#5DA5DA&#39;</span>
    orange <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;#FAA43A&#39;</span>
    green <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;#60BD68&#39;</span>
    pink <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;#F17CB0&#39;</span>
    brown <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;#B2912F&#39;</span>
    purple <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;#B276B2&#39;</span>
    yellow <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;#DECF3F&#39;</span>
    gray <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;#4D4D4D&#39;</span>
    <span style="color:#66d9ef">def</span> __getitem__(self, i):
        <span style="color:#66d9ef">return</span> [
            self<span style="color:#f92672">.</span>red,
            self<span style="color:#f92672">.</span>orange,
            self<span style="color:#f92672">.</span>green,
            self<span style="color:#f92672">.</span>blue,
            self<span style="color:#f92672">.</span>pink,
            self<span style="color:#f92672">.</span>brown,
            self<span style="color:#f92672">.</span>purple,
            self<span style="color:#f92672">.</span>yellow,
            self<span style="color:#f92672">.</span>gray,
        ][i <span style="color:#f92672">%</span> <span style="color:#ae81ff">9</span>]
TFColor <span style="color:#f92672">=</span> _TFColor()

<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">session_options</span>(enable_gpu_ram_resizing<span style="color:#f92672">=</span>True, enable_xla<span style="color:#f92672">=</span>False):
    <span style="color:#e6db74">&#34;&#34;&#34;
</span><span style="color:#e6db74">    Allowing the notebook to make use of GPUs if they&#39;re available.
</span><span style="color:#e6db74">
</span><span style="color:#e6db74">    XLA (Accelerated Linear Algebra) is a domain-specific compiler for linear
</span><span style="color:#e6db74">    algebra that optimizes TensorFlow computations.
</span><span style="color:#e6db74">    &#34;&#34;&#34;</span>
    config <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>config
    gpu_devices <span style="color:#f92672">=</span> config<span style="color:#f92672">.</span>experimental<span style="color:#f92672">.</span>list_physical_devices(<span style="color:#e6db74">&#39;GPU&#39;</span>)
    <span style="color:#66d9ef">if</span> enable_gpu_ram_resizing:
        <span style="color:#66d9ef">for</span> device <span style="color:#f92672">in</span> gpu_devices:
           tf<span style="color:#f92672">.</span>config<span style="color:#f92672">.</span>experimental<span style="color:#f92672">.</span>set_memory_growth(device, True)
    <span style="color:#66d9ef">if</span> enable_xla:
        config<span style="color:#f92672">.</span>optimizer<span style="color:#f92672">.</span>set_jit(True)
    <span style="color:#66d9ef">return</span> config

session_options(enable_gpu_ram_resizing<span style="color:#f92672">=</span>True, enable_xla<span style="color:#f92672">=</span>True)

<span style="color:#960050;background-color:#1e0010">!</span>apt <span style="color:#f92672">-</span>qq <span style="color:#f92672">-</span>y install fonts<span style="color:#f92672">-</span>nanum
 
<span style="color:#f92672">import</span> matplotlib.font_manager <span style="color:#f92672">as</span> fm
fontpath <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;/usr/share/fonts/truetype/nanum/NanumBarunGothic.ttf&#39;</span>
font <span style="color:#f92672">=</span> fm<span style="color:#f92672">.</span>FontProperties(fname<span style="color:#f92672">=</span>fontpath, size<span style="color:#f92672">=</span><span style="color:#ae81ff">9</span>)
plt<span style="color:#f92672">.</span>rc(<span style="color:#e6db74">&#39;font&#39;</span>, family<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;NanumBarunGothic&#39;</span>) 
mpl<span style="color:#f92672">.</span>font_manager<span style="color:#f92672">.</span>_rebuild()

</code></pre></div><pre><code>fonts-nanum is already the newest version (20170925-1).
The following package was automatically installed and is no longer required:
  libnvidia-common-440
Use 'apt autoremove' to remove it.
0 upgraded, 0 newly installed, 0 to remove and 39 not upgraded.
</code></pre>
<h3 id="0-데이터-만들고-hmc-모델링하기">0) 데이터 만들고 HMC 모델링하기</h3>
<h3 id="0-1-데이터-만들기">0-1) 데이터 만들기</h3>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">count_data <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>constant([
    <span style="color:#ae81ff">13</span>,  <span style="color:#ae81ff">24</span>,   <span style="color:#ae81ff">8</span>,  <span style="color:#ae81ff">24</span>,   <span style="color:#ae81ff">7</span>,  <span style="color:#ae81ff">35</span>,  <span style="color:#ae81ff">14</span>,  <span style="color:#ae81ff">11</span>,  <span style="color:#ae81ff">15</span>,  <span style="color:#ae81ff">11</span>,  <span style="color:#ae81ff">22</span>,  <span style="color:#ae81ff">22</span>,  <span style="color:#ae81ff">11</span>,  <span style="color:#ae81ff">57</span>,  
    <span style="color:#ae81ff">11</span>,  <span style="color:#ae81ff">19</span>,  <span style="color:#ae81ff">29</span>,   <span style="color:#ae81ff">6</span>,  <span style="color:#ae81ff">19</span>,  <span style="color:#ae81ff">12</span>,  <span style="color:#ae81ff">22</span>,  <span style="color:#ae81ff">12</span>,  <span style="color:#ae81ff">18</span>,  <span style="color:#ae81ff">72</span>,  <span style="color:#ae81ff">32</span>,   <span style="color:#ae81ff">9</span>,   <span style="color:#ae81ff">7</span>,  <span style="color:#ae81ff">13</span>,  
    <span style="color:#ae81ff">19</span>,  <span style="color:#ae81ff">23</span>,  <span style="color:#ae81ff">27</span>,  <span style="color:#ae81ff">20</span>,   <span style="color:#ae81ff">6</span>,  <span style="color:#ae81ff">17</span>,  <span style="color:#ae81ff">13</span>,  <span style="color:#ae81ff">10</span>,  <span style="color:#ae81ff">14</span>,   <span style="color:#ae81ff">6</span>,  <span style="color:#ae81ff">16</span>,  <span style="color:#ae81ff">15</span>,   <span style="color:#ae81ff">7</span>,   <span style="color:#ae81ff">2</span>,  
    <span style="color:#ae81ff">15</span>,  <span style="color:#ae81ff">15</span>,  <span style="color:#ae81ff">19</span>,  <span style="color:#ae81ff">70</span>,  <span style="color:#ae81ff">49</span>,   <span style="color:#ae81ff">7</span>,  <span style="color:#ae81ff">53</span>,  <span style="color:#ae81ff">22</span>,  <span style="color:#ae81ff">21</span>,  <span style="color:#ae81ff">31</span>,  <span style="color:#ae81ff">19</span>,  <span style="color:#ae81ff">11</span>,  <span style="color:#ae81ff">18</span>,  <span style="color:#ae81ff">20</span>,  
    <span style="color:#ae81ff">12</span>,  <span style="color:#ae81ff">35</span>,  <span style="color:#ae81ff">17</span>,  <span style="color:#ae81ff">23</span>,  <span style="color:#ae81ff">17</span>,   <span style="color:#ae81ff">4</span>,   <span style="color:#ae81ff">2</span>,  <span style="color:#ae81ff">31</span>,  <span style="color:#ae81ff">30</span>,  <span style="color:#ae81ff">13</span>,  <span style="color:#ae81ff">27</span>,   <span style="color:#ae81ff">0</span>,  <span style="color:#ae81ff">39</span>,  <span style="color:#ae81ff">37</span>,   
    <span style="color:#ae81ff">5</span>,  <span style="color:#ae81ff">14</span>,  <span style="color:#ae81ff">13</span>,  <span style="color:#ae81ff">22</span>,
], dtype<span style="color:#f92672">=</span>tf<span style="color:#f92672">.</span>float32)
n_count_data <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>shape(count_data)
days <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>range(n_count_data[<span style="color:#ae81ff">0</span>],dtype<span style="color:#f92672">=</span>tf<span style="color:#f92672">.</span>int32)
</code></pre></div><h3 id="0-2-joint-log-probability-만들기">0-2) Joint log Probability 만들기</h3>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">joint_log_prob</span>(count_data, lambda_1, lambda_2, tau):
    tfd <span style="color:#f92672">=</span> tfp<span style="color:#f92672">.</span>distributions
 
    alpha <span style="color:#f92672">=</span> (<span style="color:#ae81ff">1.</span> <span style="color:#f92672">/</span> tf<span style="color:#f92672">.</span>reduce_mean(count_data))
    rv_lambda_1 <span style="color:#f92672">=</span> tfd<span style="color:#f92672">.</span>Exponential(rate<span style="color:#f92672">=</span>alpha)
    rv_lambda_2 <span style="color:#f92672">=</span> tfd<span style="color:#f92672">.</span>Exponential(rate<span style="color:#f92672">=</span>alpha)
 
    rv_tau <span style="color:#f92672">=</span> tfd<span style="color:#f92672">.</span>Uniform()
 
    lambda_ <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>gather(
         [lambda_1, lambda_2],
         indices<span style="color:#f92672">=</span>tf<span style="color:#f92672">.</span>cast(tau <span style="color:#f92672">*</span> tf<span style="color:#f92672">.</span>cast(tf<span style="color:#f92672">.</span>size(count_data), dtype<span style="color:#f92672">=</span>tf<span style="color:#f92672">.</span>float32) <span style="color:#f92672">&lt;=</span> tf<span style="color:#f92672">.</span>cast(tf<span style="color:#f92672">.</span>range(tf<span style="color:#f92672">.</span>size(count_data)), dtype<span style="color:#f92672">=</span>tf<span style="color:#f92672">.</span>float32), dtype<span style="color:#f92672">=</span>tf<span style="color:#f92672">.</span>int32))
    rv_observation <span style="color:#f92672">=</span> tfd<span style="color:#f92672">.</span>Poisson(rate<span style="color:#f92672">=</span>lambda_)
 
    <span style="color:#66d9ef">return</span> (
         rv_lambda_1<span style="color:#f92672">.</span>log_prob(lambda_1)
         <span style="color:#f92672">+</span> rv_lambda_2<span style="color:#f92672">.</span>log_prob(lambda_2)
         <span style="color:#f92672">+</span> rv_tau<span style="color:#f92672">.</span>log_prob(tau)
         <span style="color:#f92672">+</span> tf<span style="color:#f92672">.</span>reduce_sum(rv_observation<span style="color:#f92672">.</span>log_prob(count_data))
    )


<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">unnormalized_log_posterior</span>(lambda1, lambda2, tau):
    <span style="color:#66d9ef">return</span> joint_log_prob(count_data, lambda1, lambda2, tau)
</code></pre></div><h3 id="0-3-사후-샘플러-만들기">0-3) 사후 샘플러 만들기</h3>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#a6e22e">@tf.function</span>(autograph<span style="color:#f92672">=</span>False)
<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">graph_sample_chain</span>(<span style="color:#f92672">*</span>args, <span style="color:#f92672">**</span>kwargs):
  <span style="color:#66d9ef">return</span> tfp<span style="color:#f92672">.</span>mcmc<span style="color:#f92672">.</span>sample_chain(<span style="color:#f92672">*</span>args, <span style="color:#f92672">**</span>kwargs)

num_burnin_steps <span style="color:#f92672">=</span> <span style="color:#ae81ff">5000</span>
num_results <span style="color:#f92672">=</span> <span style="color:#ae81ff">20000</span>


initial_chain_state <span style="color:#f92672">=</span> [
    tf<span style="color:#f92672">.</span>cast(tf<span style="color:#f92672">.</span>reduce_mean(count_data), tf<span style="color:#f92672">.</span>float32) <span style="color:#f92672">*</span> tf<span style="color:#f92672">.</span>ones([], dtype<span style="color:#f92672">=</span>tf<span style="color:#f92672">.</span>float32, name<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;init_lambda1&#34;</span>),
    tf<span style="color:#f92672">.</span>cast(tf<span style="color:#f92672">.</span>reduce_mean(count_data), tf<span style="color:#f92672">.</span>float32) <span style="color:#f92672">*</span> tf<span style="color:#f92672">.</span>ones([], dtype<span style="color:#f92672">=</span>tf<span style="color:#f92672">.</span>float32, name<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;init_lambda2&#34;</span>),
    <span style="color:#ae81ff">0.5</span> <span style="color:#f92672">*</span> tf<span style="color:#f92672">.</span>ones([], dtype<span style="color:#f92672">=</span>tf<span style="color:#f92672">.</span>float32, name<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;init_tau&#34;</span>),
]


unconstraining_bijectors <span style="color:#f92672">=</span> [
    tfp<span style="color:#f92672">.</span>bijectors<span style="color:#f92672">.</span>Exp(),       
    tfp<span style="color:#f92672">.</span>bijectors<span style="color:#f92672">.</span>Exp(),       
    tfp<span style="color:#f92672">.</span>bijectors<span style="color:#f92672">.</span>Sigmoid(),   
]

step_size <span style="color:#f92672">=</span> <span style="color:#ae81ff">0.2</span>

kernel<span style="color:#f92672">=</span>tfp<span style="color:#f92672">.</span>mcmc<span style="color:#f92672">.</span>TransformedTransitionKernel(
        inner_kernel<span style="color:#f92672">=</span>tfp<span style="color:#f92672">.</span>mcmc<span style="color:#f92672">.</span>HamiltonianMonteCarlo(
            target_log_prob_fn<span style="color:#f92672">=</span>unnormalized_log_posterior,
            num_leapfrog_steps<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>,
            step_size<span style="color:#f92672">=</span>step_size,
            state_gradients_are_stopped<span style="color:#f92672">=</span>True),
        bijector<span style="color:#f92672">=</span>unconstraining_bijectors)

kernel <span style="color:#f92672">=</span> tfp<span style="color:#f92672">.</span>mcmc<span style="color:#f92672">.</span>SimpleStepSizeAdaptation(
    inner_kernel<span style="color:#f92672">=</span>kernel, num_adaptation_steps<span style="color:#f92672">=</span>int(num_burnin_steps <span style="color:#f92672">*</span> <span style="color:#ae81ff">0.8</span>))



[
    lambda_1_samples,
    lambda_2_samples,
    posterior_tau,
], kernel_results <span style="color:#f92672">=</span> graph_sample_chain(
    num_results<span style="color:#f92672">=</span>num_results,
    num_burnin_steps<span style="color:#f92672">=</span>num_burnin_steps,
    current_state<span style="color:#f92672">=</span>initial_chain_state,
    kernel <span style="color:#f92672">=</span> kernel)
    
tau_samples <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>floor(posterior_tau <span style="color:#f92672">*</span> tf<span style="color:#f92672">.</span>cast(tf<span style="color:#f92672">.</span>size(count_data),dtype<span style="color:#f92672">=</span>tf<span style="color:#f92672">.</span>float32))
</code></pre></div><h1 id="예제-풀이">예제 풀이</h1>
<ol>
<li><code>lambda_1_samples</code>와 <code>lambda_2_samples</code>를 사용해서 $\lambda_1$ 과 $\lambda_2$의 사후 분포의 평균을 구해보세요</li>
</ol>
<p>이 문제는 쉽습니다. 그저 표본들의 평균만 구하면 됩니다.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#34;lambda_1_samples의 사후 분포의 평균 : &#34;</span>, lambda_1_samples<span style="color:#f92672">.</span>numpy()<span style="color:#f92672">.</span>mean())
<span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#34;lambda_2_samples의 사후 분포의 평균 : &#34;</span>, lambda_2_samples<span style="color:#f92672">.</span>numpy()<span style="color:#f92672">.</span>mean())
</code></pre></div><pre><code>lambda_1_samples의 사후 분포의 평균 :  17.752668
lambda_2_samples의 사후 분포의 평균 :  22.713673
</code></pre>
<p>주의할 점은 tensor를 numpy array로 바꾸고 평균 함수를 써야한다는 점입니다.</p>
<ol start="2">
<li>문자 메시지 사용률이 몇 % 증가했는지의 기댓값을 구해보세요(힌트 : <code>lambda_1_samples/lambda_2_samples</code>의 평균을 구해보세요. 그리고 <code>lambda_1_samples.numpy().mean()/lambda_2_samples.numpy().mean()</code>의 값과는 다른 결과가 나온다는 점에 주목해보세요)</li>
</ol>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">incre_percent <span style="color:#f92672">=</span> lambda_1_samples <span style="color:#f92672">/</span> lambda_2_samples
</code></pre></div><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#34;문자메시지 사용률 증가량의 기댓값 : &#34;</span>, incre_percent<span style="color:#f92672">.</span>numpy()<span style="color:#f92672">.</span>mean())
</code></pre></div><pre><code>문자메시지 사용률 증가량의 기댓값 :  0.78283226
</code></pre>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#34;문자메시지 사용률 기댓값의 증가량 : &#34;</span>, lambda_1_samples<span style="color:#f92672">.</span>numpy()<span style="color:#f92672">.</span>mean()<span style="color:#f92672">/</span>lambda_2_samples<span style="color:#f92672">.</span>numpy()<span style="color:#f92672">.</span>mean())
</code></pre></div><pre><code>문자메시지 사용률 기댓값의 증가량 :  0.7815851
</code></pre>
<p>둘의 값이 다른 것을 알 수 있습니다.</p>
<p>문자 메시지 사용률 증가량의 사후 확률 분포를 그려봅시다</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">plt<span style="color:#f92672">.</span>figure(figsize<span style="color:#f92672">=</span>(<span style="color:#ae81ff">12.5</span>, <span style="color:#ae81ff">4</span>))
plt<span style="color:#f92672">.</span>hist(lambda_1_samples <span style="color:#f92672">/</span> lambda_2_samples, histtype<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;stepfilled&#39;</span>, bins<span style="color:#f92672">=</span><span style="color:#ae81ff">30</span>, alpha<span style="color:#f92672">=</span><span style="color:#ae81ff">0.85</span>,
         label<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;문자메시지 사용률 증가량에 대한 사후확률분포&#34;</span>, color<span style="color:#f92672">=</span>TFColor[<span style="color:#ae81ff">6</span>], density <span style="color:#f92672">=</span> True)
plt<span style="color:#f92672">.</span>legend(loc<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;upper left&#34;</span>)
plt<span style="color:#f92672">.</span>xlabel(<span style="color:#e6db74">&#34;증가량 %&#34;</span>)
plt<span style="color:#f92672">.</span>ylabel(<span style="color:#e6db74">&#34;밀도&#34;</span>)
</code></pre></div><pre><code>Text(0, 0.5, '밀도')
</code></pre>
<p><img src="https://user-images.githubusercontent.com/57588650/91650899-a15bf480-eac0-11ea-8814-bf63a907133e.png" alt="output_21_1"></p>
<ol start="3">
<li>$\tau$가 45 미만이라는 사실이 주어지면 $\lambda_1$의 평균은 무엇일까요? 즉 우리에게 행동 패턴의 변화가 45번째 날 이전에 이루어진다는 정보가 주어졌다고 가정합시다. 이제 $\lambda_1$의 기댓값은 뭘까요?(코딩을 다시 할 필요는 없습니다. 그냥 &lsquo;tau_samples &lt; 45&rsquo;인 상태들을 모두 고려해보세요)</li>
</ol>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">index <span style="color:#f92672">=</span> tau_samples <span style="color:#f92672">&lt;</span> <span style="color:#ae81ff">45</span>
</code></pre></div><p>우선 45 미만인 $\tau$들을 뽑습니다</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">lambda_1_given_tau_under_45 <span style="color:#f92672">=</span> lambda_1_samples[index]
</code></pre></div><p>$\lambda_1 | \tau &lt; 45$ 를 만듭시다</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">from</span> IPython.display <span style="color:#f92672">import</span> display, Markdown <span style="color:#75715e"># latex를 함수에서 출력하기 위한 라이브러리를 가져옵니다</span>
</code></pre></div><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">display(Markdown(rf<span style="color:#e6db74">&#34;$E[\lambda_1|</span><span style="color:#ae81ff">\t</span><span style="color:#e6db74">au &lt; 45] = {lambda_1_given_tau_under_45.numpy().mean()}$&#34;</span>))
</code></pre></div><p>$E[\lambda_1|\tau &lt; 45] = 17.76012420654297$</p>

		</div>
		<footer class="post__footer">
			
<div class="post__tags tags clearfix">
	<svg class="tags__badge icon icon-tag" width="16" height="16" viewBox="0 0 32 32"><path d="M32 19c0 1-1 2-1 2L21 31s-1 1-2 1-2-1-2-1L2 16c-1-1-1.4-2-1.4-2S0 12.5 0 11V3C0 1.5.8.8.8.8S1.5 0 3 0h8c1.5 0 3 .6 3 .6S15 1 16 2l15 15s1 1 1 2zM7 10a3 3 0 1 0 0-6 3 3 0 0 0 0 6z"/></svg>
	<ul class="tags__list">
		<li class="tags__item">
			<a class="tags__link btn" href="/tags/bayesian/" rel="tag">Bayesian</a>
		</li>
		<li class="tags__item">
			<a class="tags__link btn" href="/tags/tensorflow/" rel="tag">TensorFlow</a>
		</li>
		<li class="tags__item">
			<a class="tags__link btn" href="/tags/python/" rel="tag">Python</a>
		</li>
	</ul>
</div>
		</footer>
	</article>
</main>

<div class="authorbox clearfix">
	<div class="authorbox__header">
		<span class="authorbox__name"></span>
	</div>
</div>



			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2021 Tai Hwan Oh.
			<span class="footer__copyright-credits"></span>
		</div>
	</div>
</footer>
	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>