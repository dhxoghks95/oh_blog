<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<title>Bayesian Method with TensorFlow Chapter5 베이지안 손실함수 - 2. 베이지안 머신러닝 1 - Oh Data Science</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="Bayesian Method with TensorFlow Chapter5 베이지안 손실함수 - 2. 베이지안 머신러닝 1" />
<meta property="og:description" content="Bayesian Method with TensorFlow - Chapter5 베이지안 손실함수 #@title Imports and Global Variables (make sure to run this cell) { display-mode: &#34;form&#34; } try: # %tensorflow_version only exists in Colab. %tensorflow_version 2.x except Exception: pass from __future__ import absolute_import, division, print_function #@markdown This sets the warning status (default is `ignore`, since this notebook runs correctly) warning_status = &#34;ignore&#34; #@param [&#34;ignore&#34;, &#34;always&#34;, &#34;module&#34;, &#34;once&#34;, &#34;default&#34;, &#34;error&#34;] import warnings warnings.filterwarnings(warning_status) with warnings.catch_warnings(): warnings." />
<meta property="og:type" content="article" />
<meta property="og:url" content="http://example.org/bayesianml1/" />
<meta property="article:published_time" content="2020-09-20T15:29:43+09:00" />
<meta property="article:modified_time" content="2020-09-20T15:29:43+09:00" />

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="Oh Data Science" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">Oh Data Science</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Bayesian Method with TensorFlow Chapter5 베이지안 손실함수 - 2. 베이지안 머신러닝 1</h1>
			
		</header><div class="content post__content clearfix">
			<h1 id="bayesian-method-with-tensorflow---chapter5-베이지안-손실함수"><strong>Bayesian Method with TensorFlow - Chapter5 베이지안 손실함수</strong></h1>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e">#@title Imports and Global Variables (make sure to run this cell)  { display-mode: &#34;form&#34; }</span>

<span style="color:#66d9ef">try</span>:
  <span style="color:#75715e"># %tensorflow_version only exists in Colab.</span>
  <span style="color:#f92672">%</span>tensorflow_version <span style="color:#ae81ff">2.</span>x
<span style="color:#66d9ef">except</span> <span style="color:#a6e22e">Exception</span>:
  <span style="color:#66d9ef">pass</span>


<span style="color:#f92672">from</span> __future__ <span style="color:#f92672">import</span> absolute_import, division, print_function


<span style="color:#75715e">#@markdown This sets the warning status (default is `ignore`, since this notebook runs correctly)</span>
warning_status <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;ignore&#34;</span> <span style="color:#75715e">#@param [&#34;ignore&#34;, &#34;always&#34;, &#34;module&#34;, &#34;once&#34;, &#34;default&#34;, &#34;error&#34;]</span>
<span style="color:#f92672">import</span> warnings
warnings<span style="color:#f92672">.</span>filterwarnings(warning_status)
<span style="color:#66d9ef">with</span> warnings<span style="color:#f92672">.</span>catch_warnings():
    warnings<span style="color:#f92672">.</span>filterwarnings(warning_status, category<span style="color:#f92672">=</span><span style="color:#a6e22e">DeprecationWarning</span>)
    warnings<span style="color:#f92672">.</span>filterwarnings(warning_status, category<span style="color:#f92672">=</span><span style="color:#a6e22e">UserWarning</span>)

<span style="color:#f92672">import</span> numpy <span style="color:#f92672">as</span> np
<span style="color:#f92672">import</span> os
<span style="color:#75715e">#@markdown This sets the styles of the plotting (default is styled like plots from [FiveThirtyeight.com](https://fivethirtyeight.com/)</span>
matplotlib_style <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;fivethirtyeight&#39;</span> <span style="color:#75715e">#@param [&#39;fivethirtyeight&#39;, &#39;bmh&#39;, &#39;ggplot&#39;, &#39;seaborn&#39;, &#39;default&#39;, &#39;Solarize_Light2&#39;, &#39;classic&#39;, &#39;dark_background&#39;, &#39;seaborn-colorblind&#39;, &#39;seaborn-notebook&#39;]</span>
<span style="color:#f92672">import</span> matplotlib.pyplot <span style="color:#f92672">as</span> plt; plt<span style="color:#f92672">.</span>style<span style="color:#f92672">.</span>use(matplotlib_style)
<span style="color:#f92672">import</span> matplotlib.axes <span style="color:#f92672">as</span> axes;
<span style="color:#f92672">from</span> matplotlib.patches <span style="color:#f92672">import</span> Ellipse
<span style="color:#f92672">import</span> matplotlib <span style="color:#f92672">as</span> mpl
<span style="color:#75715e">#%matplotlib inline</span>
<span style="color:#f92672">import</span> seaborn <span style="color:#f92672">as</span> sns; sns<span style="color:#f92672">.</span>set_context(<span style="color:#e6db74">&#39;notebook&#39;</span>)
<span style="color:#f92672">from</span> IPython.core.pylabtools <span style="color:#f92672">import</span> figsize
<span style="color:#75715e">#@markdown This sets the resolution of the plot outputs (`retina` is the highest resolution)</span>
notebook_screen_res <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;retina&#39;</span> <span style="color:#75715e">#@param [&#39;retina&#39;, &#39;png&#39;, &#39;jpeg&#39;, &#39;svg&#39;, &#39;pdf&#39;]</span>
<span style="color:#75715e">#%config InlineBackend.figure_format = notebook_screen_res</span>

<span style="color:#f92672">import</span> tensorflow <span style="color:#f92672">as</span> tf

<span style="color:#f92672">import</span> tensorflow_probability <span style="color:#f92672">as</span> tfp
tfd <span style="color:#f92672">=</span> tfp<span style="color:#f92672">.</span>distributions
tfb <span style="color:#f92672">=</span> tfp<span style="color:#f92672">.</span>bijectors

<span style="color:#66d9ef">class</span> <span style="color:#a6e22e">_TFColor</span>(object):
    <span style="color:#e6db74">&#34;&#34;&#34;Enum of colors used in TF docs.&#34;&#34;&#34;</span>
    red <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;#F15854&#39;</span>
    blue <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;#5DA5DA&#39;</span>
    orange <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;#FAA43A&#39;</span>
    green <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;#60BD68&#39;</span>
    pink <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;#F17CB0&#39;</span>
    brown <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;#B2912F&#39;</span>
    purple <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;#B276B2&#39;</span>
    yellow <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;#DECF3F&#39;</span>
    gray <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;#4D4D4D&#39;</span>
    <span style="color:#66d9ef">def</span> __getitem__(self, i):
        <span style="color:#66d9ef">return</span> [
            self<span style="color:#f92672">.</span>red,
            self<span style="color:#f92672">.</span>orange,
            self<span style="color:#f92672">.</span>green,
            self<span style="color:#f92672">.</span>blue,
            self<span style="color:#f92672">.</span>pink,
            self<span style="color:#f92672">.</span>brown,
            self<span style="color:#f92672">.</span>purple,
            self<span style="color:#f92672">.</span>yellow,
            self<span style="color:#f92672">.</span>gray,
        ][i <span style="color:#f92672">%</span> <span style="color:#ae81ff">9</span>]
TFColor <span style="color:#f92672">=</span> _TFColor()

<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">session_options</span>(enable_gpu_ram_resizing<span style="color:#f92672">=</span>True, enable_xla<span style="color:#f92672">=</span>False):
    <span style="color:#e6db74">&#34;&#34;&#34;
</span><span style="color:#e6db74">    Allowing the notebook to make use of GPUs if they&#39;re available.
</span><span style="color:#e6db74">
</span><span style="color:#e6db74">    XLA (Accelerated Linear Algebra) is a domain-specific compiler for linear
</span><span style="color:#e6db74">    algebra that optimizes TensorFlow computations.
</span><span style="color:#e6db74">    &#34;&#34;&#34;</span>
    config <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>config
    gpu_devices <span style="color:#f92672">=</span> config<span style="color:#f92672">.</span>experimental<span style="color:#f92672">.</span>list_physical_devices(<span style="color:#e6db74">&#39;GPU&#39;</span>)
    <span style="color:#66d9ef">if</span> enable_gpu_ram_resizing:
        <span style="color:#66d9ef">for</span> device <span style="color:#f92672">in</span> gpu_devices:
           tf<span style="color:#f92672">.</span>config<span style="color:#f92672">.</span>experimental<span style="color:#f92672">.</span>set_memory_growth(device, True)
    <span style="color:#66d9ef">if</span> enable_xla:
        config<span style="color:#f92672">.</span>optimizer<span style="color:#f92672">.</span>set_jit(True)
    <span style="color:#66d9ef">return</span> config

session_options(enable_gpu_ram_resizing<span style="color:#f92672">=</span>True, enable_xla<span style="color:#f92672">=</span>True)

<span style="color:#960050;background-color:#1e0010">!</span>apt <span style="color:#f92672">-</span>qq <span style="color:#f92672">-</span>y install fonts<span style="color:#f92672">-</span>nanum
 
<span style="color:#f92672">import</span> matplotlib.font_manager <span style="color:#f92672">as</span> fm
fontpath <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;/usr/share/fonts/truetype/nanum/NanumBarunGothic.ttf&#39;</span>
font <span style="color:#f92672">=</span> fm<span style="color:#f92672">.</span>FontProperties(fname<span style="color:#f92672">=</span>fontpath, size<span style="color:#f92672">=</span><span style="color:#ae81ff">9</span>)
plt<span style="color:#f92672">.</span>rc(<span style="color:#e6db74">&#39;font&#39;</span>, family<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;NanumBarunGothic&#39;</span>) 
mpl<span style="color:#f92672">.</span>font_manager<span style="color:#f92672">.</span>_rebuild()
</code></pre></div><pre><code>fonts-nanum is already the newest version (20170925-1).
0 upgraded, 0 newly installed, 0 to remove and 11 not upgraded.
</code></pre>
<h1 id="2-베이지안-머신러닝-1"><strong>2. 베이지안 머신러닝 1</strong></h1>
<p>빈도론자의 방법들이 모든 가능한 모수들 중 최고로 정확한 값을 얻기 위해 노력하지만, 머신러닝에서는 가능한 모수들에서 최고의 예측값을 뽑아내려고 합니다. 당연히 정확한 예측값들을 찾는 한 방법은 정확한 예측값을 목표로 하는 것입니다. 그러나 종종 당신의 예측 평가 척도와 빈도론자들의 방법들이 최적화하는 것은 매우 다릅니다.</p>
<p>예를 들어, 최소 자승(least square) 선형 회귀분석은 가장 간단한 동적(active) 머신러닝 알고리즘입니다. 여기서 동적 러닝이란 표본 평균을 예측하는 것은 기술적으로 쉽지만, 아주 작은 부분만을 학습하는 것을 말합니다. 회귀 분석의 coefficient들을 결정하는 손실은 squared error 손실입니다. 즉 만일 당신의 예측 손실 함수가(또는 음의 손실인 score function이) squared error가 아니라 AUC, ROC, precision 등등과 같은 것이라면, 당신의 최소 자승법은 그 예측 손실 함수에 대해 최적의 방식이 아닐 것입니다. 이것으로는 최선의 예측 결과를 얻어내지 못할 수도 있습니다.</p>
<p>베이즈 action(최소 기대 손실)을 찾는 것은 모수의 정확도를 최적화하는 모수들을 찾는 것이 아니라 임의의 성능 측정 방식(우리가 성능을 정의하고 싶은 모든 방식이 가능합니다. 손실 함수, AUC, ROC, precision/recall 등등)을 최적화하는 모수를 찾는 것입니다.</p>
<p>다음의 두 예시들은 이러한 아이디어를 설명해줍니다. 첫 번째 예제는 최소 자승 손실을 사용해서 예측하거나 참신한 방식인 결과 민감 손실로 선형 회귀를 진행합니다.</p>
<p>두 번째 예제는 캐글 과학 프로젝트에서 가져온 것입니다. 우리의 예측과 관련된 손실 함수는 매우 복잡합니다.</p>
<p>##<strong>예제 : 금융 예측</strong></p>
<p>주식 가격의 미래 이익이 매우 작은 값인 0.01(또는 1%)라고 가정합시다. 우리는 주식의 미래 가격을 예측하는 모델을 가지고 있고 우리의 손익은 예측값에 따라 활동하는 우리와 직접적으로 관련되어있습니다. 어떻게 모델의 예측값과 관련된 손실과 후속되는 미래 예측값을 측정할 수 있을까요? Squared error 손실을 사용하면 부호가 다름에도 -0.01을 예측하는 것과 0.03을 예측하는 것에 서로 같은 패널티를 줄 것입니다.</p>
<p>$$ (0.01 - (-0.01))^2 = (0.01 - 0.03)^2 = 0.004$$</p>
<p>만일 당신의 모델 예측값에 기반해 주식을 구매한다면 0.03을 예측한 것 만큼 돈을 벌 것이고 -0.01을 예측한 만큼 돈을 잃을 것입니다. 그러나 우리의 Squared error 손실은 이것을 측정하지 못합니다. 우리는 실제 값과 예측 값의 부호를 고려하는 더 나은 손실이 필요합니다. 밑에서 금융에 적용하기 더 좋은 새로운 손실을 만들어보도록 하겠습니다.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e"># evaluate 함수 생성</span>
<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">evaluate</span>(tensors):
    <span style="color:#66d9ef">if</span> tf<span style="color:#f92672">.</span>executing_eagerly():
         <span style="color:#66d9ef">return</span> tf<span style="color:#f92672">.</span>nest<span style="color:#f92672">.</span>pack_sequence_as(
             tensors,
             [t<span style="color:#f92672">.</span>numpy() <span style="color:#66d9ef">if</span> tf<span style="color:#f92672">.</span>is_tensor(t) <span style="color:#66d9ef">else</span> t
             <span style="color:#66d9ef">for</span> t <span style="color:#f92672">in</span> tf<span style="color:#f92672">.</span>nest<span style="color:#f92672">.</span>flatten(tensors)])
    <span style="color:#66d9ef">with</span> tf<span style="color:#f92672">.</span>Session() <span style="color:#66d9ef">as</span> sess:
        <span style="color:#66d9ef">return</span> sess<span style="color:#f92672">.</span>run(tensors)

plt<span style="color:#f92672">.</span>figure(figsize(<span style="color:#ae81ff">12.5</span>, <span style="color:#ae81ff">6.5</span>))


<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">stock_loss</span>(true_return, yhat, alpha<span style="color:#f92672">=</span><span style="color:#ae81ff">100.</span>):
    <span style="color:#e6db74">&#34;&#34;&#34;
</span><span style="color:#e6db74">    주식 손실 함수
</span><span style="color:#e6db74">    
</span><span style="color:#e6db74">    Args:
</span><span style="color:#e6db74">      true_return: float32 Tensor 실제 주식 손익을 나타냅니다.
</span><span style="color:#e6db74">      yhat: float32
</span><span style="color:#e6db74">      alpha:float32
</span><span style="color:#e6db74">      
</span><span style="color:#e6db74">    Returns:
</span><span style="color:#e6db74">      float: 실제 손익과 yhat 사이의 절대값
</span><span style="color:#e6db74">    &#34;&#34;&#34;</span>
    <span style="color:#66d9ef">if</span> true_return <span style="color:#f92672">*</span> yhat <span style="color:#f92672">&lt;</span> <span style="color:#ae81ff">0</span>:
        <span style="color:#75715e"># 손실의 경우엔 음수를 붙입니다.</span>
        <span style="color:#66d9ef">return</span> alpha <span style="color:#f92672">*</span> yhat <span style="color:#f92672">**</span> <span style="color:#ae81ff">2</span> <span style="color:#f92672">-</span> tf<span style="color:#f92672">.</span>sign(true_return) <span style="color:#f92672">*</span> yhat \
            <span style="color:#f92672">+</span> tf<span style="color:#f92672">.</span>abs(true_return)
    <span style="color:#66d9ef">else</span>:
        <span style="color:#66d9ef">return</span> tf<span style="color:#f92672">.</span>abs(true_return <span style="color:#f92672">-</span> yhat)

<span style="color:#75715e"># 손익이 0.05, -0.02인 경우로 구합시다</span>
true_value_1_ <span style="color:#f92672">=</span> <span style="color:#f92672">.</span><span style="color:#ae81ff">05</span>
true_value_2_ <span style="color:#f92672">=</span> <span style="color:#f92672">-.</span><span style="color:#ae81ff">02</span>
pred_ <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>linspace(<span style="color:#f92672">-.</span><span style="color:#ae81ff">04</span>, <span style="color:#f92672">.</span><span style="color:#ae81ff">12</span>, <span style="color:#ae81ff">75</span>)

plt<span style="color:#f92672">.</span>plot(pred_, [evaluate(stock_loss(true_value_1_, p)) <span style="color:#66d9ef">for</span> p <span style="color:#f92672">in</span> pred_],
         label<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;실제 값이 0.05인 경우 예측과 관련된 손실&#34;</span>, lw<span style="color:#f92672">=</span><span style="color:#ae81ff">3</span>)
plt<span style="color:#f92672">.</span>vlines(<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">0</span>, <span style="color:#f92672">.</span><span style="color:#ae81ff">25</span>, linestyles<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;--&#34;</span>)
plt<span style="color:#f92672">.</span>xlabel(<span style="color:#e6db74">&#34;prediction&#34;</span>)
plt<span style="color:#f92672">.</span>ylabel(<span style="color:#e6db74">&#34;loss&#34;</span>)
plt<span style="color:#f92672">.</span>xlim(<span style="color:#f92672">-</span><span style="color:#ae81ff">0.04</span>, <span style="color:#f92672">.</span><span style="color:#ae81ff">12</span>)
plt<span style="color:#f92672">.</span>ylim(<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">0.25</span>)

true_value <span style="color:#f92672">=</span> <span style="color:#f92672">-.</span><span style="color:#ae81ff">02</span>
plt<span style="color:#f92672">.</span>plot(pred_, [evaluate(stock_loss(true_value_2_, p)) <span style="color:#66d9ef">for</span> p <span style="color:#f92672">in</span> pred_], alpha<span style="color:#f92672">=</span><span style="color:#ae81ff">0.6</span>,
         label<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;실제 값이 -0.02인 경우 예측과 관련된 손실&#34;</span>, lw<span style="color:#f92672">=</span><span style="color:#ae81ff">3</span>)
plt<span style="color:#f92672">.</span>legend()
plt<span style="color:#f92672">.</span>title(<span style="color:#e6db74">&#34;실제 값이 0.05 또는 -0.02인 경우의 주식 손익&#34;</span>);

</code></pre></div><p><img src="https://user-images.githubusercontent.com/57588650/93705221-72342280-fb56-11ea-9ba4-dfff66c54300.png" alt="output_6_0"></p>
<p>예측값이 0을 지날 때 모양이 바뀐다는 것에 주목합니다. 이 손실은 사용자들이 부호가 틀리면서 큰 오차가 나지 않기 원한다는 것을 반영합니다.</p>
<p>왜 사용자들이 틀리는 정도에 신경쓸까요? 왜 손실이 0이 아닌 값에서 맞는 부호를 예측할까요? 당연히, 만일 수익이 0.01이고 백만달러를 베팅했다면 우리는 여전히 아주 기쁠 것입니다.</p>
<p>금융 기관들은 과도하게 부정적인 방향으로 예측하는 하방 위험과 과도하게 긍정적인 방향으로 예측하는 상방 위험을 모두 다룹니다. 그 둘은 모두 위험한 행동으로 여겨지고 피해야하는 것입니다. 그렇기 때문에 우리의 예측 값이 실제 가격에서 멀리 떨어질 수록 손실을 높여야 합니다.(양수 쪽으로 예측할 때에는 덜 극단적인 손실을 줍니다.)</p>
<p>우리는 미래의 수익을 잘 예측할 것으로 믿어지는 매매 신호에 대해 회귀분석을 실시할 것입니다. 우리의 데이터셋은 인공적입니다. 실제로 금융 데이터는 전혀 선형적이지 않습니다. 밑에서 우리는 최소 자승 추세선과 함께 그래프를 그려보겠습니다.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e"># 인공적인 실험용 데이터를 만들기 위한 코드입니다.</span>
<span style="color:#75715e"># 이것은 실제 세계의 데이터에 모델을 적용하기 전에 우리의 모델을 실험하기 위한 </span>
<span style="color:#75715e"># 일반적인 전략입니다.</span>


num_data <span style="color:#f92672">=</span> <span style="color:#ae81ff">100</span> <span style="color:#75715e"># 100개 만듭시다.</span>
X_data <span style="color:#f92672">=</span> (<span style="color:#ae81ff">0.025</span> <span style="color:#f92672">*</span> tfd<span style="color:#f92672">.</span>Normal(loc<span style="color:#f92672">=</span><span style="color:#ae81ff">0.</span>,scale<span style="color:#f92672">=</span><span style="color:#ae81ff">1.</span>)<span style="color:#f92672">.</span>sample(sample_shape<span style="color:#f92672">=</span>num_data)) <span style="color:#75715e"># Normal(0,1)</span>
Y_data <span style="color:#f92672">=</span> (<span style="color:#ae81ff">0.5</span> <span style="color:#f92672">*</span> X_data <span style="color:#f92672">+</span> <span style="color:#ae81ff">0.01</span> <span style="color:#f92672">*</span> tfd<span style="color:#f92672">.</span>Normal(loc<span style="color:#f92672">=</span><span style="color:#ae81ff">0.</span>,scale<span style="color:#f92672">=</span><span style="color:#ae81ff">1.</span>)<span style="color:#f92672">.</span>sample(sample_shape<span style="color:#f92672">=</span>num_data)) 

tf_var_data <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>nn<span style="color:#f92672">.</span>moments(X_data, axes<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>)[<span style="color:#ae81ff">1</span>]
covar <span style="color:#f92672">=</span> tfp<span style="color:#f92672">.</span>stats<span style="color:#f92672">.</span>covariance(X_data,Y_data, sample_axis<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>, event_axis<span style="color:#f92672">=</span>None)
ls_coef <span style="color:#f92672">=</span> covar <span style="color:#f92672">/</span> tf_var_data

[
    X_data_, Y_data_, ls_coef_,
] <span style="color:#f92672">=</span> evaluate([
    X_data, Y_data, ls_coef,
])

ls_intercept_ <span style="color:#f92672">=</span> Y_data_<span style="color:#f92672">.</span>mean() <span style="color:#f92672">-</span> ls_coef_ <span style="color:#f92672">*</span> X_data_<span style="color:#f92672">.</span>mean()

plt<span style="color:#f92672">.</span>figure(figsize(<span style="color:#ae81ff">12.5</span>, <span style="color:#ae81ff">7</span>))
plt<span style="color:#f92672">.</span>scatter(X_data_, Y_data_, c<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;k&#34;</span>)
plt<span style="color:#f92672">.</span>xlabel(<span style="color:#e6db74">&#34;매매 신호&#34;</span>)
plt<span style="color:#f92672">.</span>ylabel(<span style="color:#e6db74">&#34;수익&#34;</span>)
plt<span style="color:#f92672">.</span>title(<span style="color:#e6db74">&#34;경험적인 수익 vs 매매 신호&#34;</span>)
plt<span style="color:#f92672">.</span>plot(X_data_, ls_coef_ <span style="color:#f92672">*</span> X_data_ <span style="color:#f92672">+</span> ls_intercept_, label<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;최소자승 추세선&#34;</span>)
plt<span style="color:#f92672">.</span>xlim(X_data_<span style="color:#f92672">.</span>min(), X_data_<span style="color:#f92672">.</span>max())
plt<span style="color:#f92672">.</span>ylim(Y_data_<span style="color:#f92672">.</span>min(), Y_data_<span style="color:#f92672">.</span>max())
plt<span style="color:#f92672">.</span>legend(loc<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;upper left&#34;</span>);

</code></pre></div><p><img src="https://user-images.githubusercontent.com/57588650/93705225-73654f80-fb56-11ea-82da-42687bb56c81.png" alt="output_8_0"></p>
<p>이 데이터셋에 간단한 베이지안 선형 회귀를 실시하도록 하겠습니다. 우리는 다음과 같은 모델을 만들어보겠습니다.</p>
<p>$$ R = \alpha + \beta x + \epsilon$$</p>
<p>여기서 $\alpha, \beta$는 우리가 구하고싶은 미지의 모수이고, $\epsilon$은 $\text{Normal}(0, 1/\tau)$를 따릅니다. $\beta$와 $\alpha$에 주는 가장 일반적인 사전 분포는 정규 사전 분포입니다. $\tau$에도 사전 분포를 주도록 하겠습니다. 즉 $\sigma = 1/\sqrt{\tau}$는 0부터 100 사이의 균등분포입니다.($\tau = 1/\text{Uniform}(0, 100)^2$ 과 같은 말입니다.)</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">obs_stdev <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>sqrt(
        tf<span style="color:#f92672">.</span>reduce_mean(tf<span style="color:#f92672">.</span>math<span style="color:#f92672">.</span>squared_difference(Y_data_, tf<span style="color:#f92672">.</span>reduce_mean(Y_data_, axis<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>)),
                      axis<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>))

<span style="color:#75715e"># 베이지안 회귀분석 함수의 로그 확률을 정의합시다.</span>
<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">finance_posterior_log_prob</span>(X_data_, Y_data_, alpha, beta, sigma):
    <span style="color:#e6db74">&#34;&#34;&#34;
</span><span style="color:#e6db74">    상태 함수로 표현된 우리의 사후 로그 확률입니다. 
</span><span style="color:#e6db74">    
</span><span style="color:#e6db74">    Args:
</span><span style="color:#e6db74">      alpha_: HMC의 상태에서 얻어진 스칼라
</span><span style="color:#e6db74">      beta_: HMC의 상태에서 얻어진 스칼라
</span><span style="color:#e6db74">      sigma_: HMC의 상태에서 얻어진 표준 편차의 스칼라
</span><span style="color:#e6db74">    Returns: 
</span><span style="color:#e6db74">      로그 확률의 합 스칼라
</span><span style="color:#e6db74">    Closure over: Y_data, X_data
</span><span style="color:#e6db74">    &#34;&#34;&#34;</span>
    rv_std <span style="color:#f92672">=</span> tfd<span style="color:#f92672">.</span>Uniform(name<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;표준 편차&#34;</span>, low<span style="color:#f92672">=</span><span style="color:#ae81ff">0.</span>, high<span style="color:#f92672">=</span><span style="color:#ae81ff">100.</span>)
    rv_beta <span style="color:#f92672">=</span> tfd<span style="color:#f92672">.</span>Normal(name<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;beta&#34;</span>, loc<span style="color:#f92672">=</span><span style="color:#ae81ff">0.</span>, scale<span style="color:#f92672">=</span><span style="color:#ae81ff">100.</span>)
    rv_alpha <span style="color:#f92672">=</span> tfd<span style="color:#f92672">.</span>Normal(name<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;alpha&#34;</span>, loc<span style="color:#f92672">=</span><span style="color:#ae81ff">0.</span>, scale<span style="color:#f92672">=</span><span style="color:#ae81ff">100.</span>)
    
    mean <span style="color:#f92672">=</span> alpha <span style="color:#f92672">+</span> beta <span style="color:#f92672">*</span> X_data_
    rv_observed <span style="color:#f92672">=</span> tfd<span style="color:#f92672">.</span>Normal(name<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;관찰값&#34;</span>, loc<span style="color:#f92672">=</span>mean, scale<span style="color:#f92672">=</span>sigma)
    
    <span style="color:#66d9ef">return</span> (
        rv_alpha<span style="color:#f92672">.</span>log_prob(alpha) 
        <span style="color:#f92672">+</span> rv_beta<span style="color:#f92672">.</span>log_prob(beta) 
        <span style="color:#f92672">+</span> rv_std<span style="color:#f92672">.</span>log_prob(sigma)
        <span style="color:#f92672">+</span> tf<span style="color:#f92672">.</span>reduce_sum(rv_observed<span style="color:#f92672">.</span>log_prob(Y_data_))
    )
</code></pre></div><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">number_of_steps <span style="color:#f92672">=</span> <span style="color:#ae81ff">30000</span>
burnin <span style="color:#f92672">=</span> <span style="color:#ae81ff">5000</span>

<span style="color:#75715e"># 체인의 시작점을 설정합니다.</span>
initial_chain_state <span style="color:#f92672">=</span> [
    tf<span style="color:#f92672">.</span>cast(<span style="color:#ae81ff">1.</span>,dtype<span style="color:#f92672">=</span>tf<span style="color:#f92672">.</span>float32) <span style="color:#f92672">*</span> tf<span style="color:#f92672">.</span>ones([], name<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;init_alpha&#39;</span>, dtype<span style="color:#f92672">=</span>tf<span style="color:#f92672">.</span>float32),
    tf<span style="color:#f92672">.</span>cast(<span style="color:#ae81ff">0.01</span>,dtype<span style="color:#f92672">=</span>tf<span style="color:#f92672">.</span>float32) <span style="color:#f92672">*</span> tf<span style="color:#f92672">.</span>ones([], name<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;init_beta&#39;</span>, dtype<span style="color:#f92672">=</span>tf<span style="color:#f92672">.</span>float32),
    tf<span style="color:#f92672">.</span>cast(obs_stdev,dtype<span style="color:#f92672">=</span>tf<span style="color:#f92672">.</span>float32) <span style="color:#f92672">*</span> tf<span style="color:#f92672">.</span>ones([], name<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;init_sigma&#39;</span>, dtype<span style="color:#f92672">=</span>tf<span style="color:#f92672">.</span>float32)
]

<span style="color:#75715e"># HMC가 과도하게 제한되지 않은 공간을 실행하기 때문에 </span>
<span style="color:#75715e"># 표본들이 현실적인 값이 나오도록 변환할 필요가 있습니다.</span>
<span style="color:#75715e"># Beta와 sigma가 각각 대략 alpha의 100배, 10배이기 때문에 Affine scalar bijector를 적용해</span>
<span style="color:#75715e"># Beta와 sigma에 100, 10을 곱해 문제의 공간으로 만들겠습니다.</span>
unconstraining_bijectors <span style="color:#f92672">=</span> [
    tfp<span style="color:#f92672">.</span>bijectors<span style="color:#f92672">.</span>Identity(), <span style="color:#75715e">#alpha</span>
    tfp<span style="color:#f92672">.</span>bijectors<span style="color:#f92672">.</span>AffineScalar(<span style="color:#ae81ff">100.</span>), <span style="color:#75715e">#beta</span>
    tfp<span style="color:#f92672">.</span>bijectors<span style="color:#f92672">.</span>AffineScalar(<span style="color:#ae81ff">10.</span>),  <span style="color:#75715e">#sigma</span>
]

<span style="color:#75715e"># 우리의 결합 로그 확률에 대해 클로져를 설정합니다.</span>
unnormalized_posterior_log_prob <span style="color:#f92672">=</span> <span style="color:#66d9ef">lambda</span> <span style="color:#f92672">*</span>args: finance_posterior_log_prob(X_data_, Y_data_, <span style="color:#f92672">*</span>args)


<span style="color:#75715e"># Defining the HMC</span>
kernel<span style="color:#f92672">=</span>tfp<span style="color:#f92672">.</span>mcmc<span style="color:#f92672">.</span>TransformedTransitionKernel(
    inner_kernel<span style="color:#f92672">=</span>tfp<span style="color:#f92672">.</span>mcmc<span style="color:#f92672">.</span>HamiltonianMonteCarlo(
        target_log_prob_fn<span style="color:#f92672">=</span>unnormalized_posterior_log_prob,
        num_leapfrog_steps<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>,
        step_size<span style="color:#f92672">=</span><span style="color:#ae81ff">0.5</span>,
        state_gradients_are_stopped<span style="color:#f92672">=</span>True),        
    bijector<span style="color:#f92672">=</span>unconstraining_bijectors)

kernel <span style="color:#f92672">=</span> tfp<span style="color:#f92672">.</span>mcmc<span style="color:#f92672">.</span>SimpleStepSizeAdaptation(
    inner_kernel<span style="color:#f92672">=</span>kernel, num_adaptation_steps<span style="color:#f92672">=</span>int(burnin <span style="color:#f92672">*</span> <span style="color:#ae81ff">0.8</span>))

<span style="color:#75715e"># Sampling from the chain.</span>
[
    alpha, 
    beta, 
    sigma
], kernel_results <span style="color:#f92672">=</span> tfp<span style="color:#f92672">.</span>mcmc<span style="color:#f92672">.</span>sample_chain(
    num_results <span style="color:#f92672">=</span> number_of_steps,
    num_burnin_steps <span style="color:#f92672">=</span> burnin,
    current_state<span style="color:#f92672">=</span>initial_chain_state,
    kernel<span style="color:#f92672">=</span>kernel,
    name<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;HMC_sampling&#39;</span>
) 

</code></pre></div><pre><code>WARNING:tensorflow:From &lt;ipython-input-7-52eb38d12624&gt;:17: AffineScalar.__init__ (from tensorflow_probability.python.bijectors.affine_scalar) is deprecated and will be removed after 2020-01-01.
Instructions for updating:
`AffineScalar` bijector is deprecated; please use `tfb.Shift(loc)(tfb.Scale(...))` instead.
</code></pre>
<p>좋습니다. 이제 결과를 실행시켜보고 우리의 예상과 맞는지를 봅시다.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">
<span style="color:#75715e"># 우리의 계산을 실행합시다.</span>
[
    alpha_,
    beta_,
    sigma_,
    kernel_results_
] <span style="color:#f92672">=</span> evaluate([
    alpha,
    beta,
    sigma,
    kernel_results
])
</code></pre></div><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e"># 사후 표본들의 수렴 과정을 그래프로 그려봅시다.</span>
plt<span style="color:#f92672">.</span>figure(figsize<span style="color:#f92672">=</span>(<span style="color:#ae81ff">15</span>,<span style="color:#ae81ff">3</span>))
plt<span style="color:#f92672">.</span>plot(np<span style="color:#f92672">.</span>arange(number_of_steps), sigma_, color<span style="color:#f92672">=</span>TFColor[<span style="color:#ae81ff">6</span>])
plt<span style="color:#f92672">.</span>title(<span style="color:#e6db74">&#39;HMC sigma (σ) 수렴 과정&#39;</span>, fontsize<span style="color:#f92672">=</span><span style="color:#ae81ff">14</span>)

plt<span style="color:#f92672">.</span>figure(figsize<span style="color:#f92672">=</span>(<span style="color:#ae81ff">15</span>,<span style="color:#ae81ff">3</span>))
plt<span style="color:#f92672">.</span>plot(np<span style="color:#f92672">.</span>arange(number_of_steps), beta_, color<span style="color:#f92672">=</span>TFColor[<span style="color:#ae81ff">0</span>])
plt<span style="color:#f92672">.</span>title(<span style="color:#e6db74">&#39;HMC beta (β) 수렴 과정&#39;</span>, fontsize<span style="color:#f92672">=</span><span style="color:#ae81ff">14</span>)

plt<span style="color:#f92672">.</span>figure(figsize<span style="color:#f92672">=</span>(<span style="color:#ae81ff">15</span>,<span style="color:#ae81ff">3</span>))
plt<span style="color:#f92672">.</span>plot(np<span style="color:#f92672">.</span>arange(number_of_steps), alpha_, color<span style="color:#f92672">=</span>TFColor[<span style="color:#ae81ff">3</span>])
plt<span style="color:#f92672">.</span>title(<span style="color:#e6db74">&#39;HMC alpha (α) 수렴 과정&#39;</span>, fontsize<span style="color:#f92672">=</span><span style="color:#ae81ff">14</span>)
</code></pre></div><pre><code>Text(0.5, 1.0, 'HMC alpha (α) 수렴 과정')
</code></pre>
<p><img src="https://user-images.githubusercontent.com/57588650/93705228-74967c80-fb56-11ea-8e08-27fc1e49ac01.png" alt="output_14_1"></p>
<p><img src="https://user-images.githubusercontent.com/57588650/93705230-75c7a980-fb56-11ea-8a0e-399691c14323.png" alt="output_14_2"></p>
<p><img src="https://user-images.githubusercontent.com/57588650/93705231-76f8d680-fb56-11ea-9e3c-8bf58b56c2f5.png" alt="output_14_3"></p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e"># 사후 표본들을 그래프로 그려봅시다.</span>

plt<span style="color:#f92672">.</span>figure(figsize<span style="color:#f92672">=</span>(<span style="color:#ae81ff">15</span>,<span style="color:#ae81ff">12</span>))
plt<span style="color:#f92672">.</span>subplot(<span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">1</span>)
plt<span style="color:#f92672">.</span>hist(sigma_, 
         bins<span style="color:#f92672">=</span><span style="color:#ae81ff">100</span>, color<span style="color:#f92672">=</span>TFColor[<span style="color:#ae81ff">6</span>], alpha<span style="color:#f92672">=</span><span style="color:#ae81ff">0.8</span>)
plt<span style="color:#f92672">.</span>ylabel(<span style="color:#e6db74">&#39;빈도&#39;</span>)
plt<span style="color:#f92672">.</span>title(<span style="color:#e6db74">&#39;사후 std (σ) 표본&#39;</span>, fontsize<span style="color:#f92672">=</span><span style="color:#ae81ff">14</span>)
plt<span style="color:#f92672">.</span>subplot(<span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">2</span>)
plt<span style="color:#f92672">.</span>plot(np<span style="color:#f92672">.</span>arange(number_of_steps), 
         sigma_, color<span style="color:#f92672">=</span>TFColor[<span style="color:#ae81ff">6</span>], alpha<span style="color:#f92672">=</span><span style="color:#ae81ff">0.8</span>)
plt<span style="color:#f92672">.</span>ylabel(<span style="color:#e6db74">&#39;표본 값&#39;</span>)
plt<span style="color:#f92672">.</span>title(<span style="color:#e6db74">&#39;사후 std (σ) 표본&#39;</span>, fontsize<span style="color:#f92672">=</span><span style="color:#ae81ff">14</span>)

plt<span style="color:#f92672">.</span>subplot(<span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">3</span>)
plt<span style="color:#f92672">.</span>hist(beta_, 
         bins<span style="color:#f92672">=</span><span style="color:#ae81ff">100</span>, color<span style="color:#f92672">=</span>TFColor[<span style="color:#ae81ff">0</span>], alpha<span style="color:#f92672">=</span><span style="color:#ae81ff">0.8</span>)
plt<span style="color:#f92672">.</span>ylabel(<span style="color:#e6db74">&#39;빈도&#39;</span>)
plt<span style="color:#f92672">.</span>title(<span style="color:#e6db74">&#39;사후 beta (β) 표본&#39;</span>, fontsize<span style="color:#f92672">=</span><span style="color:#ae81ff">14</span>)
plt<span style="color:#f92672">.</span>subplot(<span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">4</span>)
plt<span style="color:#f92672">.</span>plot(np<span style="color:#f92672">.</span>arange(number_of_steps), 
         beta_, color<span style="color:#f92672">=</span>TFColor[<span style="color:#ae81ff">0</span>], alpha<span style="color:#f92672">=</span><span style="color:#ae81ff">0.8</span>)
plt<span style="color:#f92672">.</span>ylabel(<span style="color:#e6db74">&#39;표본 값&#39;</span>)
plt<span style="color:#f92672">.</span>title(<span style="color:#e6db74">&#39;사후 beta (β) 표본&#39;</span>, fontsize<span style="color:#f92672">=</span><span style="color:#ae81ff">14</span>)

plt<span style="color:#f92672">.</span>subplot(<span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">5</span>)
plt<span style="color:#f92672">.</span>hist(alpha_, bins<span style="color:#f92672">=</span><span style="color:#ae81ff">100</span>, 
         color<span style="color:#f92672">=</span>TFColor[<span style="color:#ae81ff">3</span>], alpha<span style="color:#f92672">=</span><span style="color:#ae81ff">0.8</span>)
plt<span style="color:#f92672">.</span>ylabel(<span style="color:#e6db74">&#39;빈도&#39;</span>)
plt<span style="color:#f92672">.</span>title(<span style="color:#e6db74">&#39;사후 alpha (α) 표본&#39;</span>, fontsize<span style="color:#f92672">=</span><span style="color:#ae81ff">14</span>)
plt<span style="color:#f92672">.</span>subplot(<span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">6</span>)
plt<span style="color:#f92672">.</span>plot(np<span style="color:#f92672">.</span>arange(number_of_steps), alpha_, 
         color<span style="color:#f92672">=</span>TFColor[<span style="color:#ae81ff">3</span>], alpha<span style="color:#f92672">=</span><span style="color:#ae81ff">0.8</span>)
plt<span style="color:#f92672">.</span>ylabel(<span style="color:#e6db74">&#39;표본 값&#39;</span>)
plt<span style="color:#f92672">.</span>title(<span style="color:#e6db74">&#39;사후 alpha (α) 표본&#39;</span>, fontsize<span style="color:#f92672">=</span><span style="color:#ae81ff">14</span>)

<span style="color:#75715e">#KDE Plots</span>
warnings<span style="color:#f92672">.</span>filterwarnings(<span style="color:#e6db74">&#34;ignore&#34;</span>, category<span style="color:#f92672">=</span><span style="color:#a6e22e">DeprecationWarning</span>)
plt<span style="color:#f92672">.</span>figure(figsize<span style="color:#f92672">=</span>(<span style="color:#ae81ff">15</span>,<span style="color:#ae81ff">9</span>))
plt<span style="color:#f92672">.</span>subplot(<span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">1</span>)
ax1 <span style="color:#f92672">=</span> sns<span style="color:#f92672">.</span>kdeplot(sigma_, 
                  shade<span style="color:#f92672">=</span>True, color<span style="color:#f92672">=</span>TFColor[<span style="color:#ae81ff">6</span>], bw<span style="color:#f92672">=.</span><span style="color:#ae81ff">000075</span>)
plt<span style="color:#f92672">.</span>ylabel(<span style="color:#e6db74">&#39;확률 밀도&#39;</span>)
plt<span style="color:#f92672">.</span>title(<span style="color:#e6db74">&#39;KDE(Kernel Density Estimate) plot for std (σ)&#39;</span>, fontsize<span style="color:#f92672">=</span><span style="color:#ae81ff">14</span>)
plt<span style="color:#f92672">.</span>subplot(<span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">2</span>)
ax2 <span style="color:#f92672">=</span> sns<span style="color:#f92672">.</span>kdeplot(beta_, 
                  shade<span style="color:#f92672">=</span>True, color<span style="color:#f92672">=</span>TFColor[<span style="color:#ae81ff">0</span>], bw<span style="color:#f92672">=.</span><span style="color:#ae81ff">0030</span>)
plt<span style="color:#f92672">.</span>ylabel(<span style="color:#e6db74">&#39;확률 밀도&#39;</span>)
plt<span style="color:#f92672">.</span>title(<span style="color:#e6db74">&#39;KDE(Kernel Density Estimate) plot for beta (β) samples&#39;</span>, fontsize<span style="color:#f92672">=</span><span style="color:#ae81ff">14</span>)
plt<span style="color:#f92672">.</span>subplot(<span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">3</span>)
ax3 <span style="color:#f92672">=</span> sns<span style="color:#f92672">.</span>kdeplot(alpha_, 
                  shade<span style="color:#f92672">=</span>True, color<span style="color:#f92672">=</span>TFColor[<span style="color:#ae81ff">3</span>], bw<span style="color:#f92672">=.</span><span style="color:#ae81ff">0001</span>)
plt<span style="color:#f92672">.</span>ylabel(<span style="color:#e6db74">&#39;확률 밀도&#39;</span>)
plt<span style="color:#f92672">.</span>title(<span style="color:#e6db74">&#39;KDE(Kernel Density Estimate) plot for alpha (α) samples&#39;</span>, fontsize<span style="color:#f92672">=</span><span style="color:#ae81ff">14</span>)
</code></pre></div><pre><code>Text(0.5, 1.0, 'KDE(Kernel Density Estimate) plot for alpha (α) samples')
</code></pre>
<p><img src="https://user-images.githubusercontent.com/57588650/93705234-795b3080-fb56-11ea-999f-8a2d8cf8f6be.png" alt="output_15_1"></p>
<p><img src="https://user-images.githubusercontent.com/57588650/93705235-795b3080-fb56-11ea-95aa-b93009f10cb9.png" alt="output_15_2"></p>
<p>MCMC가 수렴한 것 처럼 보이기 때문에 계속 진행하도록 하겠습니다.</p>
<p>특정한 매매 신호를 $x$라고 부릅시다. 여기서 가능한 수익의 분포는 다음과 같은 형태를 가지고 있습니다.</p>
<p>$$R_i(x) =  \alpha_i + \beta_ix + \epsilon, \ \ \epsilon \sim \text{Normal}(0, 1/\tau_i)$$</p>
<p>여기서 $i$는 우리의 사후 표본들의 인덱스 입니다. 우리는 위에서 정의한 순실에 따라 다음과 같은 정답을 찾고자 합니다.</p>
<p>$$ \arg \min_{r} \ \ E_{R(x)}\left[ \ L(R(x), r) \ \right] $$</p>
<p>이 $r$이 바로 매매 신호 $x$에 대한 우리의 Bayes action입니다. 밑에서 우리는 다른 매매 신호에 대한 Bayes action을 그래프로 그려보겠습니다. 무엇을 알 수 있나요?</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">from</span> scipy.optimize <span style="color:#f92672">import</span> fmin

plt<span style="color:#f92672">.</span>figure(figsize(<span style="color:#ae81ff">12.5</span>, <span style="color:#ae81ff">6</span>))

<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">stock_loss</span>(price, pred, coef<span style="color:#f92672">=</span><span style="color:#ae81ff">500</span>):
    <span style="color:#e6db74">&#34;&#34;&#34;
</span><span style="color:#e6db74">    벡터화된 주식 손실 함수
</span><span style="color:#e6db74">    
</span><span style="color:#e6db74">    Args:
</span><span style="color:#e6db74">        price: A (&lt;number_of_steps&gt;,) 가격들의 텐서 (독립 변수)
</span><span style="color:#e6db74">        pred: A (1,) 가격에 기초한 예측값 텐서
</span><span style="color:#e6db74">        coef: Bayes action 함수의 coeficient를 나타내는 정수 텐서
</span><span style="color:#e6db74">    Returns:
</span><span style="color:#e6db74">        sol: A (&lt;number_of_steps&gt;,) 위이 식에서 구한 Bayes action 정답 r의 데이터 지점을 나타내는 array 텐서
</span><span style="color:#e6db74">    &#34;&#34;&#34;</span>
    sol <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>zeros_like(price)
    ix <span style="color:#f92672">=</span> price <span style="color:#f92672">*</span> pred <span style="color:#f92672">&lt;</span> <span style="color:#ae81ff">0</span>
    <span style="color:#75715e"># 음의 수익을 예측하면 더 큰 손실을, 양의 수익을 예측하면 덜 큰 손실을 준다</span>
    sol[ix] <span style="color:#f92672">=</span> coef <span style="color:#f92672">*</span> pred <span style="color:#f92672">**</span> <span style="color:#ae81ff">2</span> <span style="color:#f92672">-</span> np<span style="color:#f92672">.</span>sign(price[ix]) <span style="color:#f92672">*</span> pred <span style="color:#f92672">+</span> abs(price[ix])
    sol[<span style="color:#f92672">~</span>ix] <span style="color:#f92672">=</span> abs(price[<span style="color:#f92672">~</span>ix] <span style="color:#f92672">-</span> pred)
    <span style="color:#66d9ef">return</span> sol

N <span style="color:#f92672">=</span> sigma_<span style="color:#f92672">.</span>shape[<span style="color:#ae81ff">0</span>]
<span style="color:#75715e"># epsilon 정의</span>
noise <span style="color:#f92672">=</span> sigma_ <span style="color:#f92672">*</span> evaluate(tfd<span style="color:#f92672">.</span>Normal(loc<span style="color:#f92672">=</span><span style="color:#ae81ff">0.</span>, scale<span style="color:#f92672">=</span><span style="color:#ae81ff">1.</span>)<span style="color:#f92672">.</span>sample(N))

<span style="color:#75715e"># 예측 손익</span>
possible_outcomes <span style="color:#f92672">=</span> <span style="color:#66d9ef">lambda</span> signal: alpha_ <span style="color:#f92672">+</span> \
                                   beta_ <span style="color:#f92672">*</span> signal <span style="color:#f92672">+</span> \
                                   noise

<span style="color:#75715e"># 매매 신호 정의하고 그에 따른 예측 손익 구하기</span>
opt_predictions <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>zeros(<span style="color:#ae81ff">50</span>)
trading_signals <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>linspace(X_data_<span style="color:#f92672">.</span>min(), X_data_<span style="color:#f92672">.</span>max(), <span style="color:#ae81ff">50</span>)
<span style="color:#66d9ef">for</span> i, signal <span style="color:#f92672">in</span> enumerate(trading_signals):
    _possible_outcomes <span style="color:#f92672">=</span> possible_outcomes(signal)
    tomin <span style="color:#f92672">=</span> <span style="color:#66d9ef">lambda</span> pred: stock_loss(_possible_outcomes, pred)<span style="color:#f92672">.</span>mean()
    opt_predictions[i] <span style="color:#f92672">=</span> fmin(tomin, <span style="color:#ae81ff">0</span>, disp<span style="color:#f92672">=</span>False)

<span style="color:#75715e"># 그래프로 그리기   </span>
plt<span style="color:#f92672">.</span>xlabel(<span style="color:#e6db74">&#34;매매 신호&#34;</span>)
plt<span style="color:#f92672">.</span>ylabel(<span style="color:#e6db74">&#34;예측&#34;</span>)
plt<span style="color:#f92672">.</span>title(<span style="color:#e6db74">&#34;최소 자승 예측 vs. Bayes action 예측&#34;</span>)
plt<span style="color:#f92672">.</span>plot(X_data_, ls_coef_ <span style="color:#f92672">*</span> X_data_ <span style="color:#f92672">+</span> ls_intercept_, label<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;최소 자승 예측&#34;</span>)
plt<span style="color:#f92672">.</span>xlim(X_data_<span style="color:#f92672">.</span>min(), X_data_<span style="color:#f92672">.</span>max())
plt<span style="color:#f92672">.</span>plot(trading_signals, opt_predictions, label<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;Bayes action 예측&#34;</span>)
plt<span style="color:#f92672">.</span>legend(loc<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;upper left&#34;</span>);
</code></pre></div><p><img src="https://user-images.githubusercontent.com/57588650/93705237-7b24f400-fb56-11ea-9e54-a10e791e65a8.png" alt="output_17_0"></p>
<p>여기서 흥미로운 점은 매매 신호가 0 근처일 때, 많은 가능한 수익 산출값이 양수가 될 수도 음수가 될 수도 있다는 점입니다. 즉 손실의 측면에서 최선의 예측은 0과 가까이 예측하는 것입니다. 즉 아무런 매매도 하지 않는 것이죠. 오직 아주 확신할 때에만 매매를 합니다. 저는 이 스타일의 모델을 *sparse prediction(희소 예측)*이라고 부릅니다. 우리의 불확실성에 불편함을 느끼기 때문에 아무것도 하지 않기로 하는거죠.(아주 낮은 확률로 0의 값을 예측할 최소 자승법과 비교해보세요.)</p>
<p>신호가 점점 더 극단적으로 갈 수록 그리고 우리가 점점 더 수익의 부호에 자신감을 가질 수록 우리의 예측값이 점점 최소자승법 추세선으로 수렴해간다는 점에서 우리의 모델이 합리적이란 것을 체크할 수 있습니다.</p>
<p>희소 예측 모델은 데이터에 가장 잘 맞게 하려고 하지 않습니다.(fitting의 squared-error 손실에 따라). 그런 쪽으로 가려면 최소 자승법 모델이 더 낫습니다. 희소 예측 모델은 그것 대신에 우리가 정의한 손실인 <code>주식 손실(stock-loss)</code>의 측면으로 최선의 예측값을 찾습니다. 이 추론을 뒤집어서 생각해볼 수 있습니다. 예측값의 <code>stock-loss</code> 정의의 측면에서는 최소 자승법 모델은 최선의 값을 예측하지 않습니다. 이쪽에서는 희소 예측 모델이 더 낫습니다. 최소 자승법 모델은 squared error 손실의 측면에서 데이터에 가장 맞는 값을 찾으려고 하기 때문이죠.</p>

		</div>
		<footer class="post__footer">
			
<div class="post__tags tags clearfix">
	<svg class="tags__badge icon icon-tag" width="16" height="16" viewBox="0 0 32 32"><path d="M32 19c0 1-1 2-1 2L21 31s-1 1-2 1-2-1-2-1L2 16c-1-1-1.4-2-1.4-2S0 12.5 0 11V3C0 1.5.8.8.8.8S1.5 0 3 0h8c1.5 0 3 .6 3 .6S15 1 16 2l15 15s1 1 1 2zM7 10a3 3 0 1 0 0-6 3 3 0 0 0 0 6z"/></svg>
	<ul class="tags__list">
		<li class="tags__item">
			<a class="tags__link btn" href="/tags/bayesian/" rel="tag">Bayesian</a>
		</li>
		<li class="tags__item">
			<a class="tags__link btn" href="/tags/tensorflow/" rel="tag">TensorFlow</a>
		</li>
		<li class="tags__item">
			<a class="tags__link btn" href="/tags/python/" rel="tag">Python</a>
		</li>
	</ul>
</div>
		</footer>
	</article>
</main>

<div class="authorbox clearfix">
	<div class="authorbox__header">
		<span class="authorbox__name">About Tai Hwan Oh</span>
	</div>
</div>



			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2021 Tai Hwan Oh.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>