<!DOCTYPE html>
<html class="no-js" lang="en-us">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<title>Bayesian Method with TensorFlow Chapter 2. More on TensorFlow and TensorFlow Probability - 2. TFP Distributions - Oh Data Science</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="Bayesian Method with TensorFlow Chapter 2. More on TensorFlow and TensorFlow Probability - 2. TFP Distributions" />
<meta property="og:description" content="Bayesian Method with TensorFlow - Chapter2 More on TensorFlow and TensorFlow Probability #@title Imports and Global Variables (make sure to run this cell) { display-mode: &#34;form&#34; } try: # %tensorflow_version only exists in Colab. %tensorflow_version 2.x except Exception: pass from __future__ import absolute_import, division, print_function #@markdown This sets the warning status (default is `ignore`, since this notebook runs correctly) warning_status = &#34;ignore&#34; #@param [&#34;ignore&#34;, &#34;always&#34;, &#34;module&#34;, &#34;once&#34;, &#34;default&#34;, &#34;error&#34;] import warnings warnings." />
<meta property="og:type" content="article" />
<meta property="og:url" content="http://example.org/tfpdist/" />
<meta property="article:published_time" content="2020-09-01T00:00:00+00:00" />
<meta property="article:modified_time" content="2020-09-01T00:00:00+00:00" />

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="Oh Data Science" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">Oh Data Science</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Bayesian Method with TensorFlow Chapter 2. More on TensorFlow and TensorFlow Probability - 2. TFP Distributions</h1>
			
		</header><div class="content post__content clearfix">
			<h1 id="bayesian-method-with-tensorflow---chapter2-more-on-tensorflow-and-tensorflow-probability"><strong>Bayesian Method with TensorFlow - Chapter2 More on TensorFlow and TensorFlow Probability</strong></h1>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e">#@title Imports and Global Variables (make sure to run this cell)  { display-mode: &#34;form&#34; }</span>

<span style="color:#66d9ef">try</span>:
  <span style="color:#75715e"># %tensorflow_version only exists in Colab.</span>
  <span style="color:#f92672">%</span>tensorflow_version <span style="color:#ae81ff">2.</span>x
<span style="color:#66d9ef">except</span> <span style="color:#a6e22e">Exception</span>:
  <span style="color:#66d9ef">pass</span>


<span style="color:#f92672">from</span> __future__ <span style="color:#f92672">import</span> absolute_import, division, print_function


<span style="color:#75715e">#@markdown This sets the warning status (default is `ignore`, since this notebook runs correctly)</span>
warning_status <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;ignore&#34;</span> <span style="color:#75715e">#@param [&#34;ignore&#34;, &#34;always&#34;, &#34;module&#34;, &#34;once&#34;, &#34;default&#34;, &#34;error&#34;]</span>
<span style="color:#f92672">import</span> warnings
warnings<span style="color:#f92672">.</span>filterwarnings(warning_status)
<span style="color:#66d9ef">with</span> warnings<span style="color:#f92672">.</span>catch_warnings():
    warnings<span style="color:#f92672">.</span>filterwarnings(warning_status, category<span style="color:#f92672">=</span><span style="color:#a6e22e">DeprecationWarning</span>)
    warnings<span style="color:#f92672">.</span>filterwarnings(warning_status, category<span style="color:#f92672">=</span><span style="color:#a6e22e">UserWarning</span>)

<span style="color:#f92672">import</span> numpy <span style="color:#f92672">as</span> np
<span style="color:#f92672">import</span> os
<span style="color:#75715e">#@markdown This sets the styles of the plotting (default is styled like plots from [FiveThirtyeight.com](https://fivethirtyeight.com/)</span>
matplotlib_style <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;fivethirtyeight&#39;</span> <span style="color:#75715e">#@param [&#39;fivethirtyeight&#39;, &#39;bmh&#39;, &#39;ggplot&#39;, &#39;seaborn&#39;, &#39;default&#39;, &#39;Solarize_Light2&#39;, &#39;classic&#39;, &#39;dark_background&#39;, &#39;seaborn-colorblind&#39;, &#39;seaborn-notebook&#39;]</span>
<span style="color:#f92672">import</span> matplotlib.pyplot <span style="color:#f92672">as</span> plt; plt<span style="color:#f92672">.</span>style<span style="color:#f92672">.</span>use(matplotlib_style)
<span style="color:#f92672">import</span> matplotlib.axes <span style="color:#f92672">as</span> axes;
<span style="color:#f92672">from</span> matplotlib.patches <span style="color:#f92672">import</span> Ellipse
<span style="color:#f92672">import</span> matplotlib <span style="color:#f92672">as</span> mpl
<span style="color:#75715e">#%matplotlib inline</span>
<span style="color:#f92672">import</span> seaborn <span style="color:#f92672">as</span> sns; sns<span style="color:#f92672">.</span>set_context(<span style="color:#e6db74">&#39;notebook&#39;</span>)
<span style="color:#f92672">from</span> IPython.core.pylabtools <span style="color:#f92672">import</span> figsize
<span style="color:#75715e">#@markdown This sets the resolution of the plot outputs (`retina` is the highest resolution)</span>
notebook_screen_res <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;retina&#39;</span> <span style="color:#75715e">#@param [&#39;retina&#39;, &#39;png&#39;, &#39;jpeg&#39;, &#39;svg&#39;, &#39;pdf&#39;]</span>
<span style="color:#75715e">#%config InlineBackend.figure_format = notebook_screen_res</span>

<span style="color:#f92672">import</span> tensorflow <span style="color:#f92672">as</span> tf

<span style="color:#f92672">import</span> tensorflow_probability <span style="color:#f92672">as</span> tfp
tfd <span style="color:#f92672">=</span> tfp<span style="color:#f92672">.</span>distributions
tfb <span style="color:#f92672">=</span> tfp<span style="color:#f92672">.</span>bijectors

<span style="color:#66d9ef">class</span> <span style="color:#a6e22e">_TFColor</span>(object):
    <span style="color:#e6db74">&#34;&#34;&#34;Enum of colors used in TF docs.&#34;&#34;&#34;</span>
    red <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;#F15854&#39;</span>
    blue <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;#5DA5DA&#39;</span>
    orange <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;#FAA43A&#39;</span>
    green <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;#60BD68&#39;</span>
    pink <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;#F17CB0&#39;</span>
    brown <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;#B2912F&#39;</span>
    purple <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;#B276B2&#39;</span>
    yellow <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;#DECF3F&#39;</span>
    gray <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;#4D4D4D&#39;</span>
    <span style="color:#66d9ef">def</span> __getitem__(self, i):
        <span style="color:#66d9ef">return</span> [
            self<span style="color:#f92672">.</span>red,
            self<span style="color:#f92672">.</span>orange,
            self<span style="color:#f92672">.</span>green,
            self<span style="color:#f92672">.</span>blue,
            self<span style="color:#f92672">.</span>pink,
            self<span style="color:#f92672">.</span>brown,
            self<span style="color:#f92672">.</span>purple,
            self<span style="color:#f92672">.</span>yellow,
            self<span style="color:#f92672">.</span>gray,
        ][i <span style="color:#f92672">%</span> <span style="color:#ae81ff">9</span>]
TFColor <span style="color:#f92672">=</span> _TFColor()

<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">session_options</span>(enable_gpu_ram_resizing<span style="color:#f92672">=</span>True, enable_xla<span style="color:#f92672">=</span>False):
    <span style="color:#e6db74">&#34;&#34;&#34;
</span><span style="color:#e6db74">    Allowing the notebook to make use of GPUs if they&#39;re available.
</span><span style="color:#e6db74">
</span><span style="color:#e6db74">    XLA (Accelerated Linear Algebra) is a domain-specific compiler for linear
</span><span style="color:#e6db74">    algebra that optimizes TensorFlow computations.
</span><span style="color:#e6db74">    &#34;&#34;&#34;</span>
    config <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>config
    gpu_devices <span style="color:#f92672">=</span> config<span style="color:#f92672">.</span>experimental<span style="color:#f92672">.</span>list_physical_devices(<span style="color:#e6db74">&#39;GPU&#39;</span>)
    <span style="color:#66d9ef">if</span> enable_gpu_ram_resizing:
        <span style="color:#66d9ef">for</span> device <span style="color:#f92672">in</span> gpu_devices:
           tf<span style="color:#f92672">.</span>config<span style="color:#f92672">.</span>experimental<span style="color:#f92672">.</span>set_memory_growth(device, True)
    <span style="color:#66d9ef">if</span> enable_xla:
        config<span style="color:#f92672">.</span>optimizer<span style="color:#f92672">.</span>set_jit(True)
    <span style="color:#66d9ef">return</span> config

session_options(enable_gpu_ram_resizing<span style="color:#f92672">=</span>True, enable_xla<span style="color:#f92672">=</span>True)

<span style="color:#960050;background-color:#1e0010">!</span>apt <span style="color:#f92672">-</span>qq <span style="color:#f92672">-</span>y install fonts<span style="color:#f92672">-</span>nanum
 
<span style="color:#f92672">import</span> matplotlib.font_manager <span style="color:#f92672">as</span> fm
fontpath <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;/usr/share/fonts/truetype/nanum/NanumBarunGothic.ttf&#39;</span>
font <span style="color:#f92672">=</span> fm<span style="color:#f92672">.</span>FontProperties(fname<span style="color:#f92672">=</span>fontpath, size<span style="color:#f92672">=</span><span style="color:#ae81ff">9</span>)
plt<span style="color:#f92672">.</span>rc(<span style="color:#e6db74">&#39;font&#39;</span>, family<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;NanumBarunGothic&#39;</span>) 
mpl<span style="color:#f92672">.</span>font_manager<span style="color:#f92672">.</span>_rebuild()
</code></pre></div><pre><code>The following package was automatically installed and is no longer required:
  libnvidia-common-440
Use 'apt autoremove' to remove it.
The following NEW packages will be installed:
  fonts-nanum
0 upgraded, 1 newly installed, 0 to remove and 39 not upgraded.
Need to get 9,604 kB of archives.
After this operation, 29.5 MB of additional disk space will be used.
Selecting previously unselected package fonts-nanum.
(Reading database ... 144579 files and directories currently installed.)
Preparing to unpack .../fonts-nanum_20170925-1_all.deb ...
Unpacking fonts-nanum (20170925-1) ...
Setting up fonts-nanum (20170925-1) ...
Processing triggers for fontconfig (2.12.6-0ubuntu2) ...
</code></pre>
<h2 id="2-tfp-distributions"><strong>2. TFP Distributions</strong></h2>
<p>자 이제 <code>tfp.distributions</code>를 어떻게 사용하는지 알아봅시다</p>
<p>TFP는 확률론적인(stochastic) 확률 변수(random variable)을 표현하기 위해 서브클래스를 사용합니다. 당신이 변수들의 모수들과 요소들의 값을 모두 앎에도 불구하고 여전히 랜덤이라면 그 변수를 확률론적(stochastic)이라고 합니다. 이 분류 안에 들어간 것들이 <code>Poisson</code>, <code>Uniform</code>, <code>Exponential</code>과 같은 클래스들의 인스턴트들입니다.</p>
<p>확률론적인 변수들에서 랜덤 샘플들을 뽑을 수 있습니다. 샘플을 뽑으면, 그 샘플들은 <code>tensorflow.Tensors</code>가 되고 그 시점부터 결정론적으로 행동합니다. 무언가가 결정론적인지 아닌지를 판단하는 방법은 다음과 같은 질문을 스스로에게 던져보는 겁니다. <strong>&ldquo;만약 내가 모든 input들이 <code>foo</code>라는 변수를 만든다는 것을 안다면, 나는 <code>foo</code>의 값을 계산할 수 있을까?&quot;</strong> 당신은 밑에서 다룰 다양한 방식으로 텐서들을 더하고, 빼고, 조작할 수도 있습니다. 이러한 실행들은 거의 항상 결정론적입니다.</p>
<h3 id="분포-만들기"><strong>분포 만들기</strong></h3>
<p>확률론적(Stochastic) 또는 확률(Random) 변수를 만들기 위해서는 분포의 위치나 크기 같은 분포의 모양을 표현하는 각 분포별 모수들이 필요합니다. 예를 들면 다음과 같죠.</p>
<pre><code>some_distribution = tfd.Uniform(0., 4.)
</code></pre><p>하한이 0이고 상한이 4인 확률론적, 또는 확률 <code>Uniform</code> 분포를 만들었습니다. 여기에 <code>sample()</code> 함수를 넣으면 그 때 부터 결정론적으로 행동하는 텐서를 반환합니다.</p>
<pre><code>sampled_tensor = some_distribution.sample()
</code></pre><p>다음 예시는 &ldquo;분포는 확률론적이고(stochastic) 텐서들은 결정론적(deterministic)이다&rdquo; 라는 말이 무엇을 의미하는지 설명합니다.</p>
<pre><code>derived_tensor_1 = 1 + sampled_tensor
derived_tensor_2 = 1 + sampled_tensor  # equal to 1

derived_tensor_3 = 1 + some_distribution.sample()
derived_tensor_4 = 1 + some_distribution.sample()  # different from 3
</code></pre><p>위의 두 줄은 같은 값을 출력할 것입니다. 둘 모두 같은 &lsquo;표본 추출된&rsquo; 텐서이기 때문이죠. 하지만 밑의 두 줄은 다른 값을 반환할 확률이 높습니다. 왜냐하면 저 둘은 같은 분포에서 뽑아낸 &lsquo;독립된&rsquo; 표본들이기 때문이죠. 그래서 위의 tensor는 결정론적이고 밑의 분포는 확률론적이라고 하는 것입니다.</p>
<p>다변량 분포를 정의하기 위해서는 그냥 당신이 어떤 모양으로 출력하고 싶은지를 넣으면 됩니다. 예를 들면</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">betas <span style="color:#f92672">=</span> tfd<span style="color:#f92672">.</span>Uniform([<span style="color:#ae81ff">0.</span>, <span style="color:#ae81ff">0.</span>], [<span style="color:#ae81ff">1.</span>, <span style="color:#ae81ff">1.</span>])
</code></pre></div><p>이런 식으로요.</p>
<p>이렇게 하면 batch_shape가 (2,)인 분포를 만들 수 있습니다. 이제 <code>betas.sample()</code> 함수를 쓰면 하나가 아니라 두 개의 값을 출력할 것입니다. TFP의 모양에 대해서는 <a href="https://github.com/tensorflow/probability/blob/master/tensorflow_probability/examples/jupyter_notebooks/Understanding_TensorFlow_Distributions_Shapes.ipynb">TFP docs</a> 이곳에서 더 자세히 읽을 수 있습니다.</p>
<h3 id="결정론적-변수"><strong>결정론적 변수</strong></h3>
<p>우리는 확률론적 분포를 만드는 방법과 비슷하게 결정론적인 분포도 만들 수 있습니다. <code>Deterministic</code>이라는 클래스를 쓰는 것만으로 우리가 원하는 결정론적인 값을 얻을 수 있죠</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">deterministic_variable <span style="color:#f92672">=</span> tfd<span style="color:#f92672">.</span>Deterministic(name <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;deterministic_variable&#34;</span>, loc <span style="color:#f92672">=</span> some_function_of_variables)
</code></pre></div><p><code>tfd.Deterministic</code>함수를 쓰면 쉽게 항상 같은 값을 반환하는 분포를 만들 수 있습니다. 그러나 실제로는 TFP에서는 결정론적 변수들을 확률론적 분포에서 tensor나 표본들을 만들 때 씁니다.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">lambda_1 <span style="color:#f92672">=</span> tfd<span style="color:#f92672">.</span>Exponential(rate<span style="color:#f92672">=</span><span style="color:#ae81ff">1.</span>, name<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;lambda_1&#34;</span>) <span style="color:#75715e">#확률론적 변수</span>
lambda_2 <span style="color:#f92672">=</span> tfd<span style="color:#f92672">.</span>Exponential(rate<span style="color:#f92672">=</span><span style="color:#ae81ff">1.</span>, name<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;lambda_2&#34;</span>) <span style="color:#75715e">#확률론적 변수</span>
tau <span style="color:#f92672">=</span> tfd<span style="color:#f92672">.</span>Uniform(name<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;tau&#34;</span>, low<span style="color:#f92672">=</span><span style="color:#ae81ff">0.</span>, high<span style="color:#f92672">=</span><span style="color:#ae81ff">10.</span>) <span style="color:#75715e">#확률론적 변수</span>

<span style="color:#75715e"># 이미 lambda들을 표본 추출을 통해 뽑았으므로 결정론적인 변수가 됩니다    </span>
new_deterministic_variable <span style="color:#f92672">=</span> tfd<span style="color:#f92672">.</span>Deterministic(name<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;deterministic_variable&#34;</span>, 
                                               loc<span style="color:#f92672">=</span>(lambda_1<span style="color:#f92672">.</span>sample() <span style="color:#f92672">+</span> lambda_2<span style="color:#f92672">.</span>sample()))
</code></pre></div><p>우리가 앞장에서 공부한 문자 메시지 예제에서 결정론적인 변수는 다음과 같이 사용됩니다. $\lambda$의 모델은 다음과 같았습니다.</p>
<p>$$
\lambda =
\begin{cases}\lambda_1  &amp; \text{if } t \lt \tau \cr
\lambda_2 &amp; \text{if } t \ge \tau
\end{cases}
$$</p>
<p>그래고 TFP 코드에선 다음과 같습니다</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e"># 우선 앞장에서 본 evaluate 함수를 만듭니다</span>
<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">evaluate</span>(tensors):
    <span style="color:#66d9ef">if</span> tf<span style="color:#f92672">.</span>executing_eagerly():
         <span style="color:#66d9ef">return</span> tf<span style="color:#f92672">.</span>nest<span style="color:#f92672">.</span>pack_sequence_as(
             tensors,
             [t<span style="color:#f92672">.</span>numpy() <span style="color:#66d9ef">if</span> tf<span style="color:#f92672">.</span>is_tensor(t) <span style="color:#66d9ef">else</span> t
             <span style="color:#66d9ef">for</span> t <span style="color:#f92672">in</span> tf<span style="color:#f92672">.</span>nest<span style="color:#f92672">.</span>flatten(tensors)])
    <span style="color:#66d9ef">with</span> tf<span style="color:#f92672">.</span>Session() <span style="color:#66d9ef">as</span> sess:
        <span style="color:#66d9ef">return</span> sess<span style="color:#f92672">.</span>run(tensors)

<span style="color:#75715e"># 그래프를 만들어 봅시다</span>

<span style="color:#75715e"># 날짜</span>
n_data_points <span style="color:#f92672">=</span> <span style="color:#ae81ff">5</span>  <span style="color:#75715e"># Chapter1의 예제에서는 70일까지 있었지만, 간단하게 5일로 합시다</span>
idx <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>arange(n_data_points)
<span style="color:#75715e"># n_data_points에서 tau보다 이전이면 lambda_1을, 이후면 lambda_2을 선택합니다</span>
<span style="color:#75715e"># 여기서 lambda_1.sample(), lambda_2.sample(), tau.sample()은 확률론적인 변수가 되겠죠?</span>
rv_lambda_deterministic <span style="color:#f92672">=</span> tfd<span style="color:#f92672">.</span>Deterministic(tf<span style="color:#f92672">.</span>gather([lambda_1<span style="color:#f92672">.</span>sample(), lambda_2<span style="color:#f92672">.</span>sample()],
                    indices<span style="color:#f92672">=</span>tf<span style="color:#f92672">.</span>cast(
                        tau<span style="color:#f92672">.</span>sample() <span style="color:#f92672">&gt;=</span> idx, tf<span style="color:#f92672">.</span>int32)))
<span style="color:#75715e"># 결정론적인 분포에서 결정론적인 표본을 뽑아냅니다</span>
lambda_deterministic <span style="color:#f92672">=</span> rv_lambda_deterministic<span style="color:#f92672">.</span>sample()

<span style="color:#75715e"># 그래프를 실행합니다</span>
[lambda_deterministic_] <span style="color:#f92672">=</span> evaluate([lambda_deterministic])

<span style="color:#75715e"># 결과를 출력합니다</span>

<span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#34;{} samples from our deterministic lambda model: </span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#34;</span><span style="color:#f92672">.</span>format(n_data_points), lambda_deterministic_ )
</code></pre></div><pre><code>5 samples from our deterministic lambda model: 
 [0.12449716 0.12449716 0.12449716 0.12449716 0.12449716]
</code></pre>
<p>만일  $\tau, \lambda_1$ , $\lambda_2$를 이미 안다면, 당연히 $\lambda$도 완벽하게 알 수 있기 때문에 그것은 결정론적인 변수가 됩니다. 여기서 indices라는 argument를 넣는 것은 정확한 타이밍에 $\lambda_1$에서 $\lambda_2$로 바꾸기 위해섭니다</p>
<h3 id="모델에-관측치를-포함시키기"><strong>모델에 관측치를 포함시키기</strong></h3>
<p>이 장에서 그렇게 보이지 않을 수도 있지만 이미 완벽하게 우리의 사전 믿음을 결정했습니다. 예를 들면 우리는 &ldquo;우리의 $\lambda_1$에 대한 사전 분포가 어떻지?&ldquo;라는 질문을 물을 수도 있고 답할 수도 있습니다.</p>
<p>이것을 하기 위해선 우리는 분포에서 표본을 추출해야합니다. 그리고 <code>.sample()</code>명령어는 간단하게 주어진 분표에서 표본을 추출하는 역할을 합니다. 그리고 이것을 실행해서 NumPy array와 같은 형태의 tensor를 만들 수 있죠.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e"># 우리의 관측 표본을 정의합시다</span>
rv_lambda_1 <span style="color:#f92672">=</span> tfd<span style="color:#f92672">.</span>Exponential(rate<span style="color:#f92672">=</span><span style="color:#ae81ff">1.</span>, name<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;lambda_1&#34;</span>)
lambda_1 <span style="color:#f92672">=</span> rv_lambda_1<span style="color:#f92672">.</span>sample(sample_shape<span style="color:#f92672">=</span><span style="color:#ae81ff">20000</span>)
    
<span style="color:#75715e"># 그래프를 실행시켜서 TF를 NumPy로 변환합니다</span>
[ lambda_1_ ] <span style="color:#f92672">=</span> evaluate([ lambda_1 ])

<span style="color:#75715e"># 우리의 사전 분포를 시각화해봅시다</span>
plt<span style="color:#f92672">.</span>figure(figsize(<span style="color:#ae81ff">12.5</span>, <span style="color:#ae81ff">5</span>))
plt<span style="color:#f92672">.</span>hist(lambda_1_, bins<span style="color:#f92672">=</span><span style="color:#ae81ff">70</span>, density<span style="color:#f92672">=</span>True, histtype<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;stepfilled&#34;</span>)
plt<span style="color:#f92672">.</span>title(<span style="color:#e6db74">&#34;$\lambda_1$&#39;s Prior Distribution&#34;</span>)
plt<span style="color:#f92672">.</span>xlim(<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">8</span>);
</code></pre></div><p><img src="https://user-images.githubusercontent.com/57588650/91795997-19115700-ec5a-11ea-88fc-763b4db7388a.png" alt="output_22_0"></p>
<p>1장에서 배운 용어의 틀에서 보면 살짝 잘못 표현하는 것이지만 일단 우리는 $P(A)$를 만들었습니다. 이제 우리의 다음 목표는 데이터/증거/관측치로 불리는 $X$를 우리의 모델에 포함시키는겁니다</p>
<p>때때로 우리는 우리의 분포의 특성을 관측된 데이터의 특성에 맞추고 싶을 수 있습니다. 그렇기 위해서는 일단 우리의 데이터에서 모수들을 얻어내야 합니다. 이 예시에서 포아송 분포의 모수(평균 사건의 수)는 명시적으로 데이터의 평균의 역수로 설정합니다.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e"># 그래프 만들기</span>
data <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>constant([<span style="color:#ae81ff">10.</span>, <span style="color:#ae81ff">5.</span>], dtype<span style="color:#f92672">=</span>tf<span style="color:#f92672">.</span>float32)
rv_poisson <span style="color:#f92672">=</span> tfd<span style="color:#f92672">.</span>Poisson(rate<span style="color:#f92672">=</span><span style="color:#ae81ff">1.</span><span style="color:#f92672">/</span>tf<span style="color:#f92672">.</span>reduce_mean(data)) <span style="color:#75715e"># 데이터의 평균의 역수로 모수 설정</span>
poisson <span style="color:#f92672">=</span> rv_poisson<span style="color:#f92672">.</span>sample()

<span style="color:#75715e"># 그래프 실행</span>
[ data_, poisson_, ] <span style="color:#f92672">=</span> evaluate([ data, poisson ]) 

<span style="color:#75715e"># 결과 출력</span>
<span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#34;two predetermined data points: &#34;</span>, data_)
<span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#34;</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74"> mean of our data: &#34;</span>, np<span style="color:#f92672">.</span>mean(data_))
<span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#34;</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74"> random sample from poisson distribution </span><span style="color:#ae81ff">\n</span><span style="color:#e6db74"> with the mean as the poisson&#39;s rate: </span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#34;</span>, poisson_)
</code></pre></div><pre><code>two predetermined data points:  [10.  5.]

 mean of our data:  7.5

 random sample from poisson distribution 
 with the mean as the poisson's rate: 
 0.0
</code></pre>
<p>이렇게 두 포스트로 TensorFlow와 TensorFlow Probability의 사용법에 대해 간단하게 알아봤습니다. 다음 장 부터는 이들을 통해 실제 모델을 만들어 보도록 하겠습니다.</p>

		</div>
		<footer class="post__footer">
			
<div class="post__tags tags clearfix">
	<svg class="tags__badge icon icon-tag" width="16" height="16" viewBox="0 0 32 32"><path d="M32 19c0 1-1 2-1 2L21 31s-1 1-2 1-2-1-2-1L2 16c-1-1-1.4-2-1.4-2S0 12.5 0 11V3C0 1.5.8.8.8.8S1.5 0 3 0h8c1.5 0 3 .6 3 .6S15 1 16 2l15 15s1 1 1 2zM7 10a3 3 0 1 0 0-6 3 3 0 0 0 0 6z"/></svg>
	<ul class="tags__list">
		<li class="tags__item">
			<a class="tags__link btn" href="/tags/bayesian/" rel="tag">Bayesian</a>
		</li>
		<li class="tags__item">
			<a class="tags__link btn" href="/tags/tensorflow/" rel="tag">TensorFlow</a>
		</li>
		<li class="tags__item">
			<a class="tags__link btn" href="/tags/python/" rel="tag">Python</a>
		</li>
	</ul>
</div>
		</footer>
	</article>
</main>

<div class="authorbox clearfix">
	<div class="authorbox__header">
		<span class="authorbox__name"></span>
	</div>
</div>



			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2021 Tai Hwan Oh.
			<span class="footer__copyright-credits"></span>
		</div>
	</div>
</footer>
	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>