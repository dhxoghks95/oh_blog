<!DOCTYPE html>
<html class="no-js" lang="en-us">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<title>Bayesian Method with TensorFlow Chapter 1. Introduction - 4. TensorFlow Probability(TFP) - Oh Data Science</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="Bayesian Method with TensorFlow Chapter 1. Introduction - 4. TensorFlow Probability(TFP)" />
<meta property="og:description" content="Bayesian Method with TensorFlow - Chapter1 Introduction 4. TensorFlow Probability TensorFlow Probability(TFP)는 베이지안 분석을 프로그래밍 하기 위한 파이썬 라이브러리입니다. 이것은 데이터 사이언티스트들, 통계학자들, 머신 러닝 개발자들 그리고 과학자들을 위해 만들어졌습니다. 그리고 TensorFlow(TF)를 기반으로 만들어졌기에 베이지안 분석을 할 때 TF의 장점인 빠른 속도를 얻을 수 있습니다. 한 번의 코딩으로 여러 번 활용할 수 있고(당신이 개발한 모델로 제품을 만들 수 있습니다) 그리고 GPU, TPU와 같은 최첨단 하드웨어를 통해 더욱 빠르게 만들 수 있죠." />
<meta property="og:type" content="article" />
<meta property="og:url" content="http://example.org/tfp/" />
<meta property="article:published_time" content="2020-08-29T16:59:51+09:00" />
<meta property="article:modified_time" content="2020-08-29T16:59:51+09:00" />

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="Oh Data Science" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">Oh Data Science</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Bayesian Method with TensorFlow Chapter 1. Introduction - 4. TensorFlow Probability(TFP)</h1>
			
		</header><div class="content post__content clearfix">
			<h1 id="bayesian-method-with-tensorflow---chapter1-introduction"><strong>Bayesian Method with TensorFlow - Chapter1 Introduction</strong></h1>
<h1 id="4-tensorflow-probability">4. <strong>TensorFlow Probability</strong></h1>
<p>TensorFlow Probability(TFP)는 베이지안 분석을 프로그래밍 하기 위한 파이썬 라이브러리입니다. 이것은 데이터 사이언티스트들, 통계학자들, 머신 러닝 개발자들 그리고 과학자들을 위해 만들어졌습니다. 그리고 TensorFlow(TF)를 기반으로 만들어졌기에 베이지안 분석을 할 때 TF의 장점인 빠른 속도를 얻을 수 있습니다. 한 번의 코딩으로 여러 번 활용할 수 있고(당신이 개발한 모델로 제품을 만들 수 있습니다) 그리고 GPU, TPU와 같은 최첨단 하드웨어를 통해 더욱 빠르게 만들 수 있죠.</p>
<p>TFP가 상대적으로 최신 기술이기 때문에 TFP 커뮤니티는 개발자들 사이에서 활발하게 논의되고 있고, 특히 초심자와 숙련자 사이의 징검다리 역할을 하는 문서들과 예제들이 많이 배포되고 있습니다. 이 포스팅의 주요 목표는 그러한 예제들을 같이 풀어보고 왜 TFP가 펀하고 쿨하고 섹시한 툴인지를 알려주기 위함입니다.</p>
<p>같이 전 챕터에 나온 예제를 TFP를 통해 모델링해봅시다. 이러한 종류의 프로그래밍을 *확률론적 프로그래밍(Probabilistic Programming)*이라고 부릅니다. 근데 이름이 좀 맘에 안들긴 합니다. 확률론적 프로그래밍이라는 말을 들으면 뭔가 코드가 무작위로 생성될것 같은 느낌이라 혼란스럽고 겁먹은 사용자들이 이 분야에서 멀어질 수 있기 때문이죠. 코드는 무작위가 아닙니다. 모델의 구성 성분으로서 프로그래밍 변수들을 사용할 때 <strong>확률론적인 모델</strong>들을 만들기 때문에 확률론적이란거죠.</p>
<p>B.Cronin[1]은 확률론적 프로그래밍에 대해 아주 멋진 말을 했습니다.</p>
<blockquote>
<p>다르게 생각해봅시다. 오직 앞을 향해서만 나아가는 전통적인 프로그램과 달리, 확률론적인 프로그램은 앞뒤로 모두 실행됩니다. 그것이 가진 세계에 대한 가정(예를 들면 그것이 나타내는 모델 공간(the model space))의 결과를 계산하기 위해 앞으로 나아가고 가능한 설명들을 제한하기 위해 뒤로 돌아갑니다. 실무적으로, 많은 확률론적 프로그래밍 시스템들은 이러한 앞으로 나아가고 뒤로 돌아오는 과정들을 똑똑하게 활용하며 최상의 설명들을 효율적으로 파악합니다.</p>
</blockquote>
<p><em>확률론적 프로그래밍</em>이란 용어가 낳은 혼란 때문에, 이제 다르게 불러보도록 하겠습니다. 그냥 &ldquo;프로그래밍&quot;이라고 부르죠. 실제로도 그러니까요!</p>
<p>TFP 코드는 읽기 쉽습니다. 바로 참신한 문법 때문이죠. 간단하게 위의 문자메시지 예시에서 모델의 구성 성분이 $(\tau, \lambda_1, \lambda_2)$라는 것을 기억해봅시다.</p>
<h3 id="결합-로그-밀도joint-log-density를-만들어봅시다"><strong>결합 로그-밀도(joint log-density)를 만들어봅시다</strong></h3>
<p>우리의 데이터가 밑의 생성 모델(generative model)의 결과라고 가정하겠습니다.</p>
<p>$$
\begin{align*}
\lambda_{1}^{(0)} &amp;\sim \text{Exponential}(\text{rate}=\alpha)
\end{align*}
$$</p>
<p>$$
\begin{align*}
\lambda_{2}^{(0)} &amp;\sim \text{Exponential}(\text{rate}=\alpha)
\end{align*}
$$</p>
<p>$$
\begin{align*}
\tau &amp;\sim \text{Uniform}[\text{low}=0,\text{high}=1) \<br>
\text{for }  i &amp;= 1\ldots N:<br>
\end{align*}
$$</p>
<p>$$
\begin{align*}
\lambda_i &amp;= \begin{cases} \lambda_{1}^{(0)}, &amp; \tau &gt; i/N \ \lambda_{2}^{(0)}, &amp; \text{otherwise}\end{cases}\<br>
\end{align*}
$$</p>
<p>$$
\begin{align*}
X_i &amp;\sim \text{Poisson}(\text{rate}=\lambda_i)
\end{align*}
$$</p>
<p>행복하게도, 이 모델은 아주 쉽게 TensorFlow와 TFP의 분포들에 이식될 수 있습니다.</p>
<p>이 코드는 &lsquo;lambda_&lsquo;라는 새로운 함수를 만들지만, 실제로는 그냥 이것을 Random Variable이라고 생각하면 됩니다. 위에서 말한 Random Variable $\lambda$죠. <a href="https://www.tensorflow.org/api_docs/python/tf/gather">gather</a> 함수는 &lsquo;tau&rsquo;의 앞인지 뒤인지에 따라 &lsquo;lambda_1&rsquo;또는 &lsquo;lambda_2&rsquo;를 &lsquo;lambda_&lsquo;의 값으로 할당합니다. &lsquo;tau&rsquo; 전까지는 &lsquo;lambda_1&rsquo;을 할당하고 &lsquo;tau&rsquo; 이후에는 &lsquo;lambda_2&rsquo;를 할당하는거죠.</p>
<p>&lsquo;lambda_1&rsquo;, &lsquo;lambda_2&rsquo;, &lsquo;tau&rsquo;가 Random Variable이기 때문에 &lsquo;lambda_&lsquo;도 자연스럽게 Ramdom Variable입니다. 아직 어떠한 변수들도 고정하지 **않았습니다**.</p>
<p>TFP는 확률론적인 추론(Probabilistic Inference)를 joint_log_prob 함수를 이용해 모델의 모수들을 예측함으로서 행합니다.(Chapter 2에서 더 자세히 배워보도록 하겠습니다)</p>
<h3 id="코드를-위한-사전-설정">코드를 위한 사전 설정</h3>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e">#@title Imports and Global Variables (make sure to run this cell)  { display-mode: &#34;form&#34; }</span>

<span style="color:#66d9ef">try</span>:
  <span style="color:#75715e"># %tensorflow_version only exists in Colab.</span>
  <span style="color:#f92672">%</span>tensorflow_version <span style="color:#ae81ff">2.</span>x
<span style="color:#66d9ef">except</span> <span style="color:#a6e22e">Exception</span>:
  <span style="color:#66d9ef">pass</span>


<span style="color:#f92672">from</span> __future__ <span style="color:#f92672">import</span> absolute_import, division, print_function


<span style="color:#75715e">#@markdown This sets the warning status (default is `ignore`, since this notebook runs correctly)</span>
warning_status <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;ignore&#34;</span> <span style="color:#75715e">#@param [&#34;ignore&#34;, &#34;always&#34;, &#34;module&#34;, &#34;once&#34;, &#34;default&#34;, &#34;error&#34;]</span>
<span style="color:#f92672">import</span> warnings
warnings<span style="color:#f92672">.</span>filterwarnings(warning_status)
<span style="color:#66d9ef">with</span> warnings<span style="color:#f92672">.</span>catch_warnings():
    warnings<span style="color:#f92672">.</span>filterwarnings(warning_status, category<span style="color:#f92672">=</span><span style="color:#a6e22e">DeprecationWarning</span>)
    warnings<span style="color:#f92672">.</span>filterwarnings(warning_status, category<span style="color:#f92672">=</span><span style="color:#a6e22e">UserWarning</span>)

<span style="color:#f92672">import</span> numpy <span style="color:#f92672">as</span> np
<span style="color:#f92672">import</span> os
<span style="color:#75715e">#@markdown This sets the styles of the plotting (default is styled like plots from [FiveThirtyeight.com](https://fivethirtyeight.com/)</span>
matplotlib_style <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;fivethirtyeight&#39;</span> <span style="color:#75715e">#@param [&#39;fivethirtyeight&#39;, &#39;bmh&#39;, &#39;ggplot&#39;, &#39;seaborn&#39;, &#39;default&#39;, &#39;Solarize_Light2&#39;, &#39;classic&#39;, &#39;dark_background&#39;, &#39;seaborn-colorblind&#39;, &#39;seaborn-notebook&#39;]</span>
<span style="color:#f92672">import</span> matplotlib.pyplot <span style="color:#f92672">as</span> plt; plt<span style="color:#f92672">.</span>style<span style="color:#f92672">.</span>use(matplotlib_style)
<span style="color:#f92672">import</span> matplotlib.axes <span style="color:#f92672">as</span> axes;
<span style="color:#f92672">from</span> matplotlib.patches <span style="color:#f92672">import</span> Ellipse
<span style="color:#75715e">#%matplotlib inline</span>
<span style="color:#f92672">import</span> seaborn <span style="color:#f92672">as</span> sns; sns<span style="color:#f92672">.</span>set_context(<span style="color:#e6db74">&#39;notebook&#39;</span>)
<span style="color:#f92672">from</span> IPython.core.pylabtools <span style="color:#f92672">import</span> figsize
<span style="color:#75715e">#@markdown This sets the resolution of the plot outputs (`retina` is the highest resolution)</span>
notebook_screen_res <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;retina&#39;</span> <span style="color:#75715e">#@param [&#39;retina&#39;, &#39;png&#39;, &#39;jpeg&#39;, &#39;svg&#39;, &#39;pdf&#39;]</span>
<span style="color:#75715e">#%config InlineBackend.figure_format = notebook_screen_res</span>

<span style="color:#f92672">import</span> tensorflow <span style="color:#f92672">as</span> tf

<span style="color:#f92672">import</span> tensorflow_probability <span style="color:#f92672">as</span> tfp
tfd <span style="color:#f92672">=</span> tfp<span style="color:#f92672">.</span>distributions
tfb <span style="color:#f92672">=</span> tfp<span style="color:#f92672">.</span>bijectors

<span style="color:#66d9ef">class</span> <span style="color:#a6e22e">_TFColor</span>(object):
    <span style="color:#e6db74">&#34;&#34;&#34;Enum of colors used in TF docs.&#34;&#34;&#34;</span>
    red <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;#F15854&#39;</span>
    blue <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;#5DA5DA&#39;</span>
    orange <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;#FAA43A&#39;</span>
    green <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;#60BD68&#39;</span>
    pink <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;#F17CB0&#39;</span>
    brown <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;#B2912F&#39;</span>
    purple <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;#B276B2&#39;</span>
    yellow <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;#DECF3F&#39;</span>
    gray <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;#4D4D4D&#39;</span>
    <span style="color:#66d9ef">def</span> __getitem__(self, i):
        <span style="color:#66d9ef">return</span> [
            self<span style="color:#f92672">.</span>red,
            self<span style="color:#f92672">.</span>orange,
            self<span style="color:#f92672">.</span>green,
            self<span style="color:#f92672">.</span>blue,
            self<span style="color:#f92672">.</span>pink,
            self<span style="color:#f92672">.</span>brown,
            self<span style="color:#f92672">.</span>purple,
            self<span style="color:#f92672">.</span>yellow,
            self<span style="color:#f92672">.</span>gray,
        ][i <span style="color:#f92672">%</span> <span style="color:#ae81ff">9</span>]
TFColor <span style="color:#f92672">=</span> _TFColor()

<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">session_options</span>(enable_gpu_ram_resizing<span style="color:#f92672">=</span>True, enable_xla<span style="color:#f92672">=</span>False):
    <span style="color:#e6db74">&#34;&#34;&#34;
</span><span style="color:#e6db74">    Allowing the notebook to make use of GPUs if they&#39;re available.
</span><span style="color:#e6db74">
</span><span style="color:#e6db74">    XLA (Accelerated Linear Algebra) is a domain-specific compiler for linear
</span><span style="color:#e6db74">    algebra that optimizes TensorFlow computations.
</span><span style="color:#e6db74">    &#34;&#34;&#34;</span>
    config <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>config
    gpu_devices <span style="color:#f92672">=</span> config<span style="color:#f92672">.</span>experimental<span style="color:#f92672">.</span>list_physical_devices(<span style="color:#e6db74">&#39;GPU&#39;</span>)
    <span style="color:#66d9ef">if</span> enable_gpu_ram_resizing:
        <span style="color:#66d9ef">for</span> device <span style="color:#f92672">in</span> gpu_devices:
           tf<span style="color:#f92672">.</span>config<span style="color:#f92672">.</span>experimental<span style="color:#f92672">.</span>set_memory_growth(device, True)
    <span style="color:#66d9ef">if</span> enable_xla:
        config<span style="color:#f92672">.</span>optimizer<span style="color:#f92672">.</span>set_jit(True)
    <span style="color:#66d9ef">return</span> config

session_options(enable_gpu_ram_resizing<span style="color:#f92672">=</span>True, enable_xla<span style="color:#f92672">=</span>True)
</code></pre></div><pre><code>&lt;module 'tensorflow._api.v2.config' from '/usr/local/lib/python3.6/dist-packages/tensorflow/_api/v2/config/__init__.py'&gt;
</code></pre>
<p>자 이제 TFP로 이전에 보았던 문자 메시지 예제를 풀어봅시다</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e"># 데이터와 가정들을 반영하기</span>
count_data <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>constant([
    <span style="color:#ae81ff">13</span>,  <span style="color:#ae81ff">24</span>,   <span style="color:#ae81ff">8</span>,  <span style="color:#ae81ff">24</span>,   <span style="color:#ae81ff">7</span>,  <span style="color:#ae81ff">35</span>,  <span style="color:#ae81ff">14</span>,  <span style="color:#ae81ff">11</span>,  <span style="color:#ae81ff">15</span>,  <span style="color:#ae81ff">11</span>,  <span style="color:#ae81ff">22</span>,  <span style="color:#ae81ff">22</span>,  <span style="color:#ae81ff">11</span>,  <span style="color:#ae81ff">57</span>,  
    <span style="color:#ae81ff">11</span>,  <span style="color:#ae81ff">19</span>,  <span style="color:#ae81ff">29</span>,   <span style="color:#ae81ff">6</span>,  <span style="color:#ae81ff">19</span>,  <span style="color:#ae81ff">12</span>,  <span style="color:#ae81ff">22</span>,  <span style="color:#ae81ff">12</span>,  <span style="color:#ae81ff">18</span>,  <span style="color:#ae81ff">72</span>,  <span style="color:#ae81ff">32</span>,   <span style="color:#ae81ff">9</span>,   <span style="color:#ae81ff">7</span>,  <span style="color:#ae81ff">13</span>,  
    <span style="color:#ae81ff">19</span>,  <span style="color:#ae81ff">23</span>,  <span style="color:#ae81ff">27</span>,  <span style="color:#ae81ff">20</span>,   <span style="color:#ae81ff">6</span>,  <span style="color:#ae81ff">17</span>,  <span style="color:#ae81ff">13</span>,  <span style="color:#ae81ff">10</span>,  <span style="color:#ae81ff">14</span>,   <span style="color:#ae81ff">6</span>,  <span style="color:#ae81ff">16</span>,  <span style="color:#ae81ff">15</span>,   <span style="color:#ae81ff">7</span>,   <span style="color:#ae81ff">2</span>,  
    <span style="color:#ae81ff">15</span>,  <span style="color:#ae81ff">15</span>,  <span style="color:#ae81ff">19</span>,  <span style="color:#ae81ff">70</span>,  <span style="color:#ae81ff">49</span>,   <span style="color:#ae81ff">7</span>,  <span style="color:#ae81ff">53</span>,  <span style="color:#ae81ff">22</span>,  <span style="color:#ae81ff">21</span>,  <span style="color:#ae81ff">31</span>,  <span style="color:#ae81ff">19</span>,  <span style="color:#ae81ff">11</span>,  <span style="color:#ae81ff">18</span>,  <span style="color:#ae81ff">20</span>,  
    <span style="color:#ae81ff">12</span>,  <span style="color:#ae81ff">35</span>,  <span style="color:#ae81ff">17</span>,  <span style="color:#ae81ff">23</span>,  <span style="color:#ae81ff">17</span>,   <span style="color:#ae81ff">4</span>,   <span style="color:#ae81ff">2</span>,  <span style="color:#ae81ff">31</span>,  <span style="color:#ae81ff">30</span>,  <span style="color:#ae81ff">13</span>,  <span style="color:#ae81ff">27</span>,   <span style="color:#ae81ff">0</span>,  <span style="color:#ae81ff">39</span>,  <span style="color:#ae81ff">37</span>,   
    <span style="color:#ae81ff">5</span>,  <span style="color:#ae81ff">14</span>,  <span style="color:#ae81ff">13</span>,  <span style="color:#ae81ff">22</span>,
], dtype<span style="color:#f92672">=</span>tf<span style="color:#f92672">.</span>float32)
n_count_data <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>shape(count_data)
days <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>range(n_count_data[<span style="color:#ae81ff">0</span>],dtype<span style="color:#f92672">=</span>tf<span style="color:#f92672">.</span>int32)
</code></pre></div><p>우선 데이터를 다시 만들고, joint_log_prob 함수를 만들어봅시다</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">joint_log_prob</span>(count_data, lambda_1, lambda_2, tau):
    tfd <span style="color:#f92672">=</span> tfp<span style="color:#f92672">.</span>distributions
 
    alpha <span style="color:#f92672">=</span> (<span style="color:#ae81ff">1.</span> <span style="color:#f92672">/</span> tf<span style="color:#f92672">.</span>reduce_mean(count_data))
    <span style="color:#75715e"># alpha는 지수 분포에서 데이터의 평균의 역수라고 앞에서 배웠습니다</span>
    rv_lambda_1 <span style="color:#f92672">=</span> tfd<span style="color:#f92672">.</span>Exponential(rate<span style="color:#f92672">=</span>alpha)
    rv_lambda_2 <span style="color:#f92672">=</span> tfd<span style="color:#f92672">.</span>Exponential(rate<span style="color:#f92672">=</span>alpha)
 
    rv_tau <span style="color:#f92672">=</span> tfd<span style="color:#f92672">.</span>Uniform()
    <span style="color:#75715e">#  tau 는 DescreteUniform 분포를 따릅니다</span>
 
    lambda_ <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>gather(
         [lambda_1, lambda_2],
         indices<span style="color:#f92672">=</span>tf<span style="color:#f92672">.</span>cast(tau <span style="color:#f92672">*</span> tf<span style="color:#f92672">.</span>cast(tf<span style="color:#f92672">.</span>size(count_data), dtype<span style="color:#f92672">=</span>tf<span style="color:#f92672">.</span>float32) <span style="color:#f92672">&lt;=</span> tf<span style="color:#f92672">.</span>cast(tf<span style="color:#f92672">.</span>range(tf<span style="color:#f92672">.</span>size(count_data)), dtype<span style="color:#f92672">=</span>tf<span style="color:#f92672">.</span>float32), dtype<span style="color:#f92672">=</span>tf<span style="color:#f92672">.</span>int32))
    <span style="color:#75715e"># lambda_1과 lambda_2에 gather 함수를 통해 tau 전후 값을 배정하는 것입니다.</span>
    rv_observation <span style="color:#f92672">=</span> tfd<span style="color:#f92672">.</span>Poisson(rate<span style="color:#f92672">=</span>lambda_)
 
    <span style="color:#66d9ef">return</span> (
         rv_lambda_1<span style="color:#f92672">.</span>log_prob(lambda_1)
         <span style="color:#f92672">+</span> rv_lambda_2<span style="color:#f92672">.</span>log_prob(lambda_2)
         <span style="color:#f92672">+</span> rv_tau<span style="color:#f92672">.</span>log_prob(tau)
         <span style="color:#f92672">+</span> tf<span style="color:#f92672">.</span>reduce_sum(rv_observation<span style="color:#f92672">.</span>log_prob(count_data))
    )


<span style="color:#75715e"># 우리의 joint_log_prob 함수의 &#39;클로저&#39;를 정의하자(현재 상태를 기억하고 변경된 최신 상태를 유지하는 것이라고 이해합시다)</span>
<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">unnormalized_log_posterior</span>(lambda1, lambda2, tau):
    <span style="color:#66d9ef">return</span> joint_log_prob(count_data, lambda1, lambda2, tau)

</code></pre></div><p>위의 tf.gather, tf.cast 함수는 <a href="https://tensorflowkorea.gitbooks.io/tensorflow-kr/content/g3doc/api_docs/python/array_ops.html">텐서변환</a> 문서에 잘 설명되어 있습니다.</p>
<p>이러한 코드로의 이식이 수학적 모델을 거의 1:1로 변환한 것이란 것에 주목합시다. 단 하나 다른 점은 단지 우리가 확률론적 모델을 만들었을 때, log_prob들의 합을 출력한다는 점이죠.(return ~ + ~ + &hellip; 에서 볼 수 있듯이)</p>
<h2 id="사후-샘플러를-만들어봅시다"><strong>사후 샘플러를 만들어봅시다</strong></h2>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e"># 속도를 향상시키기 위해 mcmc 샘플링을 @tf.function으로 감쌉시다.</span>
<span style="color:#a6e22e">@tf.function</span>(autograph<span style="color:#f92672">=</span>False)
<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">graph_sample_chain</span>(<span style="color:#f92672">*</span>args, <span style="color:#f92672">**</span>kwargs):
  <span style="color:#66d9ef">return</span> tfp<span style="color:#f92672">.</span>mcmc<span style="color:#f92672">.</span>sample_chain(<span style="color:#f92672">*</span>args, <span style="color:#f92672">**</span>kwargs)

num_burnin_steps <span style="color:#f92672">=</span> <span style="color:#ae81ff">5000</span>
num_results <span style="color:#f92672">=</span> <span style="color:#ae81ff">20000</span>


<span style="color:#75715e"># 체인의 시작점을 설정합시다</span>
initial_chain_state <span style="color:#f92672">=</span> [
    tf<span style="color:#f92672">.</span>cast(tf<span style="color:#f92672">.</span>reduce_mean(count_data), tf<span style="color:#f92672">.</span>float32) <span style="color:#f92672">*</span> tf<span style="color:#f92672">.</span>ones([], dtype<span style="color:#f92672">=</span>tf<span style="color:#f92672">.</span>float32, name<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;init_lambda1&#34;</span>),
    tf<span style="color:#f92672">.</span>cast(tf<span style="color:#f92672">.</span>reduce_mean(count_data), tf<span style="color:#f92672">.</span>float32) <span style="color:#f92672">*</span> tf<span style="color:#f92672">.</span>ones([], dtype<span style="color:#f92672">=</span>tf<span style="color:#f92672">.</span>float32, name<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;init_lambda2&#34;</span>),
    <span style="color:#ae81ff">0.5</span> <span style="color:#f92672">*</span> tf<span style="color:#f92672">.</span>ones([], dtype<span style="color:#f92672">=</span>tf<span style="color:#f92672">.</span>float32, name<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;init_tau&#34;</span>),
]


<span style="color:#75715e"># HMC(Hamiltonian Monte Carlo)가 과도하게 아무런 제약도 없는 공간을 만들기 때문에</span>
<span style="color:#75715e"># 우리는 샘플들을 실제 세계의 것으로 변환할 필요가 있습니다.</span>
unconstraining_bijectors <span style="color:#f92672">=</span> [
    tfp<span style="color:#f92672">.</span>bijectors<span style="color:#f92672">.</span>Exp(),       <span style="color:#75715e"># 결과를 양수로만 나오게 합니다</span>
    tfp<span style="color:#f92672">.</span>bijectors<span style="color:#f92672">.</span>Exp(),       <span style="color:#75715e"># 결과를 양수로만 나오게 합니다</span>
    tfp<span style="color:#f92672">.</span>bijectors<span style="color:#f92672">.</span>Sigmoid(),   <span style="color:#75715e"># 결과가 0, 1 사이에 있게 합니다</span>
]

step_size <span style="color:#f92672">=</span> <span style="color:#ae81ff">0.2</span>

kernel<span style="color:#f92672">=</span>tfp<span style="color:#f92672">.</span>mcmc<span style="color:#f92672">.</span>TransformedTransitionKernel(
        inner_kernel<span style="color:#f92672">=</span>tfp<span style="color:#f92672">.</span>mcmc<span style="color:#f92672">.</span>HamiltonianMonteCarlo(
            target_log_prob_fn<span style="color:#f92672">=</span>unnormalized_log_posterior,
            num_leapfrog_steps<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>,
            step_size<span style="color:#f92672">=</span>step_size,
            state_gradients_are_stopped<span style="color:#f92672">=</span>True),
        bijector<span style="color:#f92672">=</span>unconstraining_bijectors)

kernel <span style="color:#f92672">=</span> tfp<span style="color:#f92672">.</span>mcmc<span style="color:#f92672">.</span>SimpleStepSizeAdaptation(
    inner_kernel<span style="color:#f92672">=</span>kernel, num_adaptation_steps<span style="color:#f92672">=</span>int(num_burnin_steps <span style="color:#f92672">*</span> <span style="color:#ae81ff">0.8</span>))


<span style="color:#75715e"># 샘플링 합시다</span>
[
    lambda_1_samples,
    lambda_2_samples,
    posterior_tau,
], kernel_results <span style="color:#f92672">=</span> graph_sample_chain(
    num_results<span style="color:#f92672">=</span>num_results,
    num_burnin_steps<span style="color:#f92672">=</span>num_burnin_steps,
    current_state<span style="color:#f92672">=</span>initial_chain_state,
    kernel <span style="color:#f92672">=</span> kernel)
    
tau_samples <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>floor(posterior_tau <span style="color:#f92672">*</span> tf<span style="color:#f92672">.</span>cast(tf<span style="color:#f92672">.</span>size(count_data),dtype<span style="color:#f92672">=</span>tf<span style="color:#f92672">.</span>float32))
</code></pre></div><p>NOTE)
<a href="https://www.tensorflow.org/probability/api_docs/python/tfp/mcmc">tfp.mcmc 함수들에 대한 설명</a></p>
<p>Hamiltonian Monte Carlo에 대해서는 <a href="http://www.secmem.org/blog/2019/02/11/fmmc/">빠르게 수렴하는 MCMC 만들기</a>블로그를 참고하시면 됩니다.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#34;acceptance rate: {}&#34;</span><span style="color:#f92672">.</span>format(
    tf<span style="color:#f92672">.</span>reduce_mean(tf<span style="color:#f92672">.</span>cast(kernel_results<span style="color:#f92672">.</span>inner_results<span style="color:#f92672">.</span>inner_results<span style="color:#f92672">.</span>is_accepted,dtype<span style="color:#f92672">=</span>tf<span style="color:#f92672">.</span>float32))))
<span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#34;final step size: {}&#34;</span><span style="color:#f92672">.</span>format(
    tf<span style="color:#f92672">.</span>reduce_mean(kernel_results<span style="color:#f92672">.</span>inner_results<span style="color:#f92672">.</span>inner_results<span style="color:#f92672">.</span>accepted_results<span style="color:#f92672">.</span>step_size[<span style="color:#f92672">-</span><span style="color:#ae81ff">100</span>:])))

</code></pre></div><pre><code>acceptance rate: 0.6118999719619751
final step size: 0.027337361127138138
</code></pre>
<h3 id="결과를-그래프로-그립시다"><strong>결과를 그래프로 그립시다</strong></h3>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">plt<span style="color:#f92672">.</span>figure(figsize<span style="color:#f92672">=</span>(<span style="color:#ae81ff">12.5</span>, <span style="color:#ae81ff">15</span>))
<span style="color:#75715e"># 샘플들의 히스토그램 그리기</span>

<span style="color:#75715e"># lambda_1</span>
ax <span style="color:#f92672">=</span> plt<span style="color:#f92672">.</span>subplot(<span style="color:#ae81ff">311</span>)
ax<span style="color:#f92672">.</span>set_autoscaley_on(False)

plt<span style="color:#f92672">.</span>hist(lambda_1_samples, histtype<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;stepfilled&#39;</span>, bins<span style="color:#f92672">=</span><span style="color:#ae81ff">30</span>, alpha<span style="color:#f92672">=</span><span style="color:#ae81ff">0.85</span>,
         label<span style="color:#f92672">=</span><span style="color:#e6db74">r</span><span style="color:#e6db74">&#34;posterior of $\lambda_1$&#34;</span>, color<span style="color:#f92672">=</span>TFColor[<span style="color:#ae81ff">0</span>], density<span style="color:#f92672">=</span>True)
plt<span style="color:#f92672">.</span>legend(loc<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;upper left&#34;</span>)
plt<span style="color:#f92672">.</span>title(<span style="color:#e6db74">r</span><span style="color:#e6db74">&#34;&#34;&#34;Posterior distributions of the variables $\lambda_1,\;\lambda_2,\;\tau$&#34;&#34;&#34;</span>)
plt<span style="color:#f92672">.</span>xlim([<span style="color:#ae81ff">15</span>, <span style="color:#ae81ff">30</span>])
plt<span style="color:#f92672">.</span>xlabel(<span style="color:#e6db74">r</span><span style="color:#e6db74">&#34;$\lambda_1$ value&#34;</span>)

<span style="color:#75715e"># lambda_2</span>
ax <span style="color:#f92672">=</span> plt<span style="color:#f92672">.</span>subplot(<span style="color:#ae81ff">312</span>)
ax<span style="color:#f92672">.</span>set_autoscaley_on(False)
plt<span style="color:#f92672">.</span>hist(lambda_2_samples, histtype<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;stepfilled&#39;</span>, bins<span style="color:#f92672">=</span><span style="color:#ae81ff">30</span>, alpha<span style="color:#f92672">=</span><span style="color:#ae81ff">0.85</span>,
         label<span style="color:#f92672">=</span><span style="color:#e6db74">r</span><span style="color:#e6db74">&#34;posterior of $\lambda_2$&#34;</span>, color<span style="color:#f92672">=</span>TFColor[<span style="color:#ae81ff">6</span>], density<span style="color:#f92672">=</span>True)
plt<span style="color:#f92672">.</span>legend(loc<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;upper left&#34;</span>)
plt<span style="color:#f92672">.</span>xlim([<span style="color:#ae81ff">15</span>, <span style="color:#ae81ff">30</span>])
plt<span style="color:#f92672">.</span>xlabel(<span style="color:#e6db74">r</span><span style="color:#e6db74">&#34;$\lambda_2$ value&#34;</span>)

<span style="color:#75715e"># tau</span>
plt<span style="color:#f92672">.</span>subplot(<span style="color:#ae81ff">313</span>)
w <span style="color:#f92672">=</span> <span style="color:#ae81ff">1.0</span> <span style="color:#f92672">/</span> tau_samples<span style="color:#f92672">.</span>shape[<span style="color:#ae81ff">0</span>] <span style="color:#f92672">*</span> np<span style="color:#f92672">.</span>ones_like(tau_samples)
plt<span style="color:#f92672">.</span>hist(tau_samples, bins<span style="color:#f92672">=</span>n_count_data[<span style="color:#ae81ff">0</span>], alpha<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>,
         label<span style="color:#f92672">=</span><span style="color:#e6db74">r</span><span style="color:#e6db74">&#34;posterior of $\tau$&#34;</span>,
         color<span style="color:#f92672">=</span>TFColor[<span style="color:#ae81ff">2</span>], weights<span style="color:#f92672">=</span>w, rwidth<span style="color:#f92672">=</span><span style="color:#ae81ff">2.</span>)
plt<span style="color:#f92672">.</span>xticks(np<span style="color:#f92672">.</span>arange(n_count_data[<span style="color:#ae81ff">0</span>]))

plt<span style="color:#f92672">.</span>legend(loc<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;upper left&#34;</span>)
plt<span style="color:#f92672">.</span>ylim([<span style="color:#ae81ff">0</span>, <span style="color:#f92672">.</span><span style="color:#ae81ff">75</span>])
plt<span style="color:#f92672">.</span>xlim([<span style="color:#ae81ff">35</span>, len(count_data)<span style="color:#f92672">-</span><span style="color:#ae81ff">20</span>])
plt<span style="color:#f92672">.</span>xlabel(<span style="color:#e6db74">r</span><span style="color:#e6db74">&#34;$\tau$ (in days)&#34;</span>)
plt<span style="color:#f92672">.</span>ylabel(<span style="color:#e6db74">r</span><span style="color:#e6db74">&#34;probability&#34;</span>);
</code></pre></div><p><img src="https://user-images.githubusercontent.com/57588650/91632083-5e931180-ea19-11ea-82df-721ab8d2d26d.png" alt="output_22_0"></p>
<h3 id="결과-해석"><strong>결과 해석</strong></h3>
<p>베이지안 방법론이 <em>분포</em>를 반환한다는 것을 기억해봅시다. 그렇기 떄문에 이제 우리는 $\lambda$와 $\tau$를 설명하는 분포를 알게 되었습니다. 그럼 우리가 무엇을 얻은걸까요? 일단 우리는 우리의 추정의 물확실성을 볼 수 있습니다. 분포가 더 넓게 퍼져있을수록, 우리의 사후 믿음은 더욱 불확실합니다. 우리는 또한 모수들에 대한 그럴듯한 값들을 알아냈습니다. $\lambda_1$는 18 근처고 $\lambda_2$는 23 근처죠. 두 $\lambda$들의 분포는 눈에 띄게 구분됩니다. 즉 사용자의 문자 메시지 사용 패턴이 바뀌었을 가능성이 높다는 것을 드러내죠.</p>
<p>어떤 다른 것을 더 뽑아낼 수 있을까요? 다시 한 번 원본 데이터를 봤을 때 이러한 결과물이 합리적으로 보이나요?</p>
<p>또 주목해야할 것은 $\lambda$의 사후분포가 사전 믿음으로 이러한 변수가 지수 분포를 따른다고 가정했음에도 지수 분포를 따르지 않는 것으로 보인다는 점입니다. 사실 사후 분포는 우리가 본래의 모델에서 인식했던 그 어떠한 모양도 아닙니다. 근데 괜찮습니다! 이것이 Computational 관점의 장점이죠. 만약 우리가 이 방법 대신에 수학적인 접근 방식을 채택했다면, 분석적인 측면에서 다루기 힘든(그리고 복잡한) 분포에 막혀있었을 것입니다. Computational 접근 방식은 우리를 &lsquo;수학적으로 접근 가능한가?&lsquo;라는 질문을 신경쓰지 않아도 되게 만듭니다.</p>
<p>우리의 분석은 $\tau$의 분포 또한 출력합니다. 다른 두 모수($\lambda_1, \lambda_2 $의 분포와는 달라보이는데, 그건 $\tau$가 이산적인 Random Variable이기 때문입니다. 그렇기 때문에 구간에 확률을 할당하지 않는거죠. 우리는 45번째 날짜 근처에서 50%의 확률로 문자 메시지 사용 패턴이 바뀐다는 것을 볼 수 있습니다. 만일 변화가 없거나 시간에 따라 점점 변해갔다면 $\tau$의 사후 분포는 넓게 퍼져있었을겁니다. $\tau$가 될 수 있는 날들이 많아지는 것을 반영하는거죠. 하지만 우리의 모델이 출력한 결과에서는 오직 3~4일 정도가 잠재적인 *교차점(transition point)*가 된다는 것을 볼 수 있습니다.</p>
<h3 id="어쨌든-왜-내가-사후-분포에서-샘플들을-원할까요"><strong>어쨌든 왜 내가 사후 분포에서 샘플들을 원할까요?</strong></h3>
<p>이 포스트의 남은 내용은 이 질문에 대해 다룰 것입니다. 그리고 &ldquo;이것이 우리를 놀라운 결과로 이끌거야!&ldquo;라는 말은 과소평가가 될 것입니다. 훨씬 대단하죠. 이번 챕터를 예시를 하나 더 들면서 마치도록 하겠습니다.</p>
<p>&quot; $t$번째 날($ 0 \le t \le 70$)에 몇 개의 메시지가 있을거라고 추정할 수 있나요?&rdquo; 라는 질문에 답하기 위해 사후 샘플들을 활용하도록 하겠습니다. 자 앞에서 포아송 분포의 기댓값은 그것의 모수 $\lambda$와 같다고 배웠습니다. 따라서 이 질문은 &ldquo;$t$번째 날의 $\lambda$의 기댓값은 무엇인가요?&ldquo;와 같아집니다.</p>
<p>밑의 코드에서, $i$가 사후 분포에서 나온 샘플들의 인덱스라고 합시다. $t$라는 날짜가 주어졌을 때, 만일 $t &lt; \tau_i$라면(즉 변화가 아직 일어나지 않았다면) 우리는 $\lambda_i = \lambda_{1,i}$를 사용해 특정 날짜 $t$에 가능한 모든 $\lambda_i$의 평균을 구할 것입니다. 변화가 일어난 후에는 $\lambda_i = \lambda_{2,i}$를 사용하죠.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e"># 위에서 구한 tau_samples, lambda_1_samples, lambda_2_samples 들이 포함되어 있습니다</span>
<span style="color:#75715e"># 다음의 사후 분포에는 N개의 샘플들이 있습니다</span>

N_ <span style="color:#f92672">=</span> tau_samples<span style="color:#f92672">.</span>shape[<span style="color:#ae81ff">0</span>]
expected_texts_per_day <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>zeros(N_,n_count_data<span style="color:#f92672">.</span>shape[<span style="color:#ae81ff">0</span>]) <span style="color:#75715e">#(10000,74)</span>

plt<span style="color:#f92672">.</span>figure(figsize<span style="color:#f92672">=</span>(<span style="color:#ae81ff">12.5</span>, <span style="color:#ae81ff">9</span>))

day_range <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>range(<span style="color:#ae81ff">0</span>,n_count_data[<span style="color:#ae81ff">0</span>],delta<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>,dtype <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>int32)

<span style="color:#75715e"># 74개 날짜의 차원을 (10000, 74)로 확장합시다</span>
day_range <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>expand_dims(day_range,<span style="color:#ae81ff">0</span>)
day_range <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>tile(day_range,tf<span style="color:#f92672">.</span>constant([N_,<span style="color:#ae81ff">1</span>]))

<span style="color:#75715e"># 10000개의 샘플들을 (10000, 74)로 확장합시다</span>
tau_samples_per_day <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>expand_dims(tau_samples,<span style="color:#ae81ff">0</span>)
tau_samples_per_day <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>transpose(tf<span style="color:#f92672">.</span>tile(tau_samples_per_day,tf<span style="color:#f92672">.</span>constant([day_range<span style="color:#f92672">.</span>shape[<span style="color:#ae81ff">1</span>],<span style="color:#ae81ff">1</span>])))

tau_samples_per_day <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>cast(tau_samples_per_day,dtype<span style="color:#f92672">=</span>tf<span style="color:#f92672">.</span>int32)
<span style="color:#75715e"># ix_day 는 (10000,74) tensor입니다.  axis=0 은 샘플의 갯수를 의미하고, axis=1은 날짜를 의미합니다. </span>
<span style="color:#75715e"># 모든 값들이 참인 것과  sampleXday value가  tau_sample value 보다 작다는 것은 필요충분조건입니다.</span>
ix_day <span style="color:#f92672">=</span> day_range <span style="color:#f92672">&lt;</span> tau_samples_per_day

lambda_1_samples_per_day <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>expand_dims(lambda_1_samples,<span style="color:#ae81ff">0</span>)
lambda_1_samples_per_day <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>transpose(tf<span style="color:#f92672">.</span>tile(lambda_1_samples_per_day,tf<span style="color:#f92672">.</span>constant([day_range<span style="color:#f92672">.</span>shape[<span style="color:#ae81ff">1</span>],<span style="color:#ae81ff">1</span>])))
lambda_2_samples_per_day <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>expand_dims(lambda_2_samples,<span style="color:#ae81ff">0</span>)
lambda_2_samples_per_day <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>transpose(tf<span style="color:#f92672">.</span>tile(lambda_2_samples_per_day,tf<span style="color:#f92672">.</span>constant([day_range<span style="color:#f92672">.</span>shape[<span style="color:#ae81ff">1</span>],<span style="color:#ae81ff">1</span>])))

expected_texts_per_day <span style="color:#f92672">=</span> ((tf<span style="color:#f92672">.</span>reduce_sum(lambda_1_samples_per_day<span style="color:#f92672">*</span>tf<span style="color:#f92672">.</span>cast(ix_day,dtype<span style="color:#f92672">=</span>tf<span style="color:#f92672">.</span>float32),axis<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>) <span style="color:#f92672">+</span> tf<span style="color:#f92672">.</span>reduce_sum(lambda_2_samples_per_day<span style="color:#f92672">*</span>tf<span style="color:#f92672">.</span>cast(<span style="color:#f92672">~</span>ix_day,dtype<span style="color:#f92672">=</span>tf<span style="color:#f92672">.</span>float32),axis<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>))<span style="color:#f92672">/</span>N_)

plt<span style="color:#f92672">.</span>plot(range(n_count_data[<span style="color:#ae81ff">0</span>]), expected_texts_per_day, lw<span style="color:#f92672">=</span><span style="color:#ae81ff">4</span>, color<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;#E24A33&#34;</span>,
         label<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;expected number of text-messages received&#34;</span>)
plt<span style="color:#f92672">.</span>xlim(<span style="color:#ae81ff">0</span>, n_count_data<span style="color:#f92672">.</span>numpy()[<span style="color:#ae81ff">0</span>])
plt<span style="color:#f92672">.</span>xlabel(<span style="color:#e6db74">&#34;Day&#34;</span>)
plt<span style="color:#f92672">.</span>ylabel(<span style="color:#e6db74">&#34;Expected # text-messages&#34;</span>)
plt<span style="color:#f92672">.</span>title(<span style="color:#e6db74">&#34;Expected number of text-messages received&#34;</span>)
plt<span style="color:#f92672">.</span>ylim(<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">60</span>)
plt<span style="color:#f92672">.</span>bar(np<span style="color:#f92672">.</span>arange(len(count_data)), count_data, color<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;#5DA5DA&#34;</span>, alpha<span style="color:#f92672">=</span><span style="color:#ae81ff">0.65</span>,
        label<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;observed texts per day&#34;</span>)

plt<span style="color:#f92672">.</span>legend(loc<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;upper left&#34;</span>);
</code></pre></div><p><img src="https://user-images.githubusercontent.com/57588650/91632095-6b176a00-ea19-11ea-9d15-2e9c3fb554a7.png" alt="output_28_0"></p>
<p>우리의 분석은 사용자의 행동 패턴이 바뀌었다는 가설을 강력하게 지지합니다($\lambda_1$과 $\lambda_2$가 거의 비슷한 값을 가진다면 이것은 사실이 아닐 것입니다).또한 변화는 점진적인 것이 아니라 갑작스럽게 벌어집니다($\tau$의 사후 분포가 매우 뾰족하게 나왔다는 점에서 알 수 있죠). 왜 이러한 일이 왜 일어났는지에 대해 궁금할 수 있습니다. 문자 메시지 요금이 저렴해졌을 수도 있고, 날씨를 문자로 알려주는 서비스를 구독했을 수도 있고 아마 새로운 친구가 생겼을 수도 있죠(실제로는 45번째 날이 크리스마스였고, 그 다음 달에 여자친구를 남겨둔 채 토론토로 이사를 갔습니다)</p>
<h1 id="여러분이-풀어볼-예제"><strong>여러분이 풀어볼 예제</strong></h1>
<ol>
<li>
<p><code>lambda_1_samples</code>와 <code>lambda_2_samples</code>를 사용해서 $\lambda_1$ 과 $\lambda_2$의 사후 분포의 평균을 구해보세요</p>
</li>
<li>
<p>문자 메시지 사용률이 몇 % 증가했는지의 기댓값을 구해보세요(힌트 : <code>lambda_1_samples/lambda_2_samples</code>의 평균을 구해보세요. 그리고 <code>lambda_1_samples.mean()/lambda_2_samples.mean()</code>의 값과는 매우 다른 결과가 나온다는 점에 주목해보세요)</p>
</li>
<li>
<p>$\tau$가 45 미만이라는 사실이 주어지면 $\lambda_1$의 평균은 무엇일까요? 즉 우리에게 행동 패턴의 변화가 45번째 날 이전에 이루어진다는 정보가 주어졌다고 가정합시다. 이제 $\lambda_1$의 기댓값은 뭘까요?(코딩을 다시 할 필요는 없습니다. 그냥 &lsquo;tau_samples &lt; 45&rsquo;인 상태들을 모두 고려해보세요)</p>
</li>
</ol>
<h2 id="references">References</h2>
<p>[1] Cronin, Beau. &ldquo;Why Probabilistic Programming Matters.&rdquo; 24 Mar 2013. Google, Online Posting to Google . Web. 24 Mar. 2013. <a href="https://plus.google.com/u/0/107971134877020469960/posts/KpeRdJKR6Z1">https://plus.google.com/u/0/107971134877020469960/posts/KpeRdJKR6Z1</a>.</p>

		</div>
		<footer class="post__footer">
			
<div class="post__tags tags clearfix">
	<svg class="tags__badge icon icon-tag" width="16" height="16" viewBox="0 0 32 32"><path d="M32 19c0 1-1 2-1 2L21 31s-1 1-2 1-2-1-2-1L2 16c-1-1-1.4-2-1.4-2S0 12.5 0 11V3C0 1.5.8.8.8.8S1.5 0 3 0h8c1.5 0 3 .6 3 .6S15 1 16 2l15 15s1 1 1 2zM7 10a3 3 0 1 0 0-6 3 3 0 0 0 0 6z"/></svg>
	<ul class="tags__list">
		<li class="tags__item">
			<a class="tags__link btn" href="/tags/bayesian/" rel="tag">Bayesian</a>
		</li>
		<li class="tags__item">
			<a class="tags__link btn" href="/tags/tensorflow/" rel="tag">TensorFlow</a>
		</li>
		<li class="tags__item">
			<a class="tags__link btn" href="/tags/python/" rel="tag">Python</a>
		</li>
	</ul>
</div>
		</footer>
	</article>
</main>

<div class="authorbox clearfix">
	<div class="authorbox__header">
		<span class="authorbox__name"></span>
	</div>
</div>



			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2021 Tai Hwan Oh.
			<span class="footer__copyright-credits"></span>
		</div>
	</div>
</footer>
	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>