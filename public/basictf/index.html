<!DOCTYPE html>
<html class="no-js" lang="en-us">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<title>Bayesian Method with TensorFlow Chapter 2. More on TensorFlow and TensorFlow Probability - 1. Basic of TensorFlow - Oh Data Science</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="Bayesian Method with TensorFlow Chapter 2. More on TensorFlow and TensorFlow Probability - 1. Basic of TensorFlow" />
<meta property="og:description" content="Bayesian Method with TensorFlow - Chapter2 More on TensorFlow and TensorFlow Probability - 1. Basic of TensorFlow Chapter 1의 TensorFlow 코드들을 보면서 많은 분들이 어떻게 하는거지? 라는 의문을 가지셨을겁니다. 저도 그랬으니까요. 자 이제부터는 TensorFlow와 TensorFlow Probability(TFP)에 대해 예제들을 통해 더 자세히 알아봅시다.
기본 설정 #@title Imports and Global Variables (make sure to run this cell) { display-mode: &#34;form&#34; } try: # %tensorflow_version only exists in Colab. %tensorflow_version 2.x except Exception: pass from __future__ import absolute_import, division, print_function #@markdown This sets the warning status (default is `ignore`, since this notebook runs correctly) warning_status = &#34;ignore&#34; #@param [&#34;ignore&#34;, &#34;always&#34;, &#34;module&#34;, &#34;once&#34;, &#34;default&#34;, &#34;error&#34;] import warnings warnings." />
<meta property="og:type" content="article" />
<meta property="og:url" content="http://example.org/basictf/" />
<meta property="article:published_time" content="2020-08-31T13:56:56+09:00" />
<meta property="article:modified_time" content="2020-08-31T13:56:56+09:00" />

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="Oh Data Science" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">Oh Data Science</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Bayesian Method with TensorFlow Chapter 2. More on TensorFlow and TensorFlow Probability - 1. Basic of TensorFlow</h1>
			
		</header><div class="content post__content clearfix">
			<h1 id="bayesian-method-with-tensorflow---chapter2-more-on-tensorflow-and-tensorflow-probability---1-basic-of-tensorflow"><strong>Bayesian Method with TensorFlow - Chapter2 More on TensorFlow and TensorFlow Probability - 1. Basic of TensorFlow</strong></h1>
<p>Chapter 1의 TensorFlow 코드들을 보면서 많은 분들이 어떻게 하는거지? 라는 의문을 가지셨을겁니다. 저도 그랬으니까요. 자 이제부터는 TensorFlow와 TensorFlow Probability(TFP)에 대해 예제들을 통해 더 자세히 알아봅시다.</p>
<h2 id="기본-설정">기본 설정</h2>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e">#@title Imports and Global Variables (make sure to run this cell)  { display-mode: &#34;form&#34; }</span>

<span style="color:#66d9ef">try</span>:
  <span style="color:#75715e"># %tensorflow_version only exists in Colab.</span>
  <span style="color:#f92672">%</span>tensorflow_version <span style="color:#ae81ff">2.</span>x
<span style="color:#66d9ef">except</span> <span style="color:#a6e22e">Exception</span>:
  <span style="color:#66d9ef">pass</span>


<span style="color:#f92672">from</span> __future__ <span style="color:#f92672">import</span> absolute_import, division, print_function


<span style="color:#75715e">#@markdown This sets the warning status (default is `ignore`, since this notebook runs correctly)</span>
warning_status <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;ignore&#34;</span> <span style="color:#75715e">#@param [&#34;ignore&#34;, &#34;always&#34;, &#34;module&#34;, &#34;once&#34;, &#34;default&#34;, &#34;error&#34;]</span>
<span style="color:#f92672">import</span> warnings
warnings<span style="color:#f92672">.</span>filterwarnings(warning_status)
<span style="color:#66d9ef">with</span> warnings<span style="color:#f92672">.</span>catch_warnings():
    warnings<span style="color:#f92672">.</span>filterwarnings(warning_status, category<span style="color:#f92672">=</span><span style="color:#a6e22e">DeprecationWarning</span>)
    warnings<span style="color:#f92672">.</span>filterwarnings(warning_status, category<span style="color:#f92672">=</span><span style="color:#a6e22e">UserWarning</span>)

<span style="color:#f92672">import</span> numpy <span style="color:#f92672">as</span> np
<span style="color:#f92672">import</span> os
<span style="color:#75715e">#@markdown This sets the styles of the plotting (default is styled like plots from [FiveThirtyeight.com](https://fivethirtyeight.com/)</span>
matplotlib_style <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;fivethirtyeight&#39;</span> <span style="color:#75715e">#@param [&#39;fivethirtyeight&#39;, &#39;bmh&#39;, &#39;ggplot&#39;, &#39;seaborn&#39;, &#39;default&#39;, &#39;Solarize_Light2&#39;, &#39;classic&#39;, &#39;dark_background&#39;, &#39;seaborn-colorblind&#39;, &#39;seaborn-notebook&#39;]</span>
<span style="color:#f92672">import</span> matplotlib.pyplot <span style="color:#f92672">as</span> plt; plt<span style="color:#f92672">.</span>style<span style="color:#f92672">.</span>use(matplotlib_style)
<span style="color:#f92672">import</span> matplotlib.axes <span style="color:#f92672">as</span> axes;
<span style="color:#f92672">from</span> matplotlib.patches <span style="color:#f92672">import</span> Ellipse
<span style="color:#f92672">import</span> matplotlib <span style="color:#f92672">as</span> mpl
<span style="color:#75715e">#%matplotlib inline</span>
<span style="color:#f92672">import</span> seaborn <span style="color:#f92672">as</span> sns; sns<span style="color:#f92672">.</span>set_context(<span style="color:#e6db74">&#39;notebook&#39;</span>)
<span style="color:#f92672">from</span> IPython.core.pylabtools <span style="color:#f92672">import</span> figsize
<span style="color:#75715e">#@markdown This sets the resolution of the plot outputs (`retina` is the highest resolution)</span>
notebook_screen_res <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;retina&#39;</span> <span style="color:#75715e">#@param [&#39;retina&#39;, &#39;png&#39;, &#39;jpeg&#39;, &#39;svg&#39;, &#39;pdf&#39;]</span>
<span style="color:#75715e">#%config InlineBackend.figure_format = notebook_screen_res</span>

<span style="color:#f92672">import</span> tensorflow <span style="color:#f92672">as</span> tf

<span style="color:#f92672">import</span> tensorflow_probability <span style="color:#f92672">as</span> tfp
tfd <span style="color:#f92672">=</span> tfp<span style="color:#f92672">.</span>distributions
tfb <span style="color:#f92672">=</span> tfp<span style="color:#f92672">.</span>bijectors

<span style="color:#66d9ef">class</span> <span style="color:#a6e22e">_TFColor</span>(object):
    <span style="color:#e6db74">&#34;&#34;&#34;Enum of colors used in TF docs.&#34;&#34;&#34;</span>
    red <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;#F15854&#39;</span>
    blue <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;#5DA5DA&#39;</span>
    orange <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;#FAA43A&#39;</span>
    green <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;#60BD68&#39;</span>
    pink <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;#F17CB0&#39;</span>
    brown <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;#B2912F&#39;</span>
    purple <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;#B276B2&#39;</span>
    yellow <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;#DECF3F&#39;</span>
    gray <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;#4D4D4D&#39;</span>
    <span style="color:#66d9ef">def</span> __getitem__(self, i):
        <span style="color:#66d9ef">return</span> [
            self<span style="color:#f92672">.</span>red,
            self<span style="color:#f92672">.</span>orange,
            self<span style="color:#f92672">.</span>green,
            self<span style="color:#f92672">.</span>blue,
            self<span style="color:#f92672">.</span>pink,
            self<span style="color:#f92672">.</span>brown,
            self<span style="color:#f92672">.</span>purple,
            self<span style="color:#f92672">.</span>yellow,
            self<span style="color:#f92672">.</span>gray,
        ][i <span style="color:#f92672">%</span> <span style="color:#ae81ff">9</span>]
TFColor <span style="color:#f92672">=</span> _TFColor()

<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">session_options</span>(enable_gpu_ram_resizing<span style="color:#f92672">=</span>True, enable_xla<span style="color:#f92672">=</span>False):
    <span style="color:#e6db74">&#34;&#34;&#34;
</span><span style="color:#e6db74">    Allowing the notebook to make use of GPUs if they&#39;re available.
</span><span style="color:#e6db74">
</span><span style="color:#e6db74">    XLA (Accelerated Linear Algebra) is a domain-specific compiler for linear
</span><span style="color:#e6db74">    algebra that optimizes TensorFlow computations.
</span><span style="color:#e6db74">    &#34;&#34;&#34;</span>
    config <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>config
    gpu_devices <span style="color:#f92672">=</span> config<span style="color:#f92672">.</span>experimental<span style="color:#f92672">.</span>list_physical_devices(<span style="color:#e6db74">&#39;GPU&#39;</span>)
    <span style="color:#66d9ef">if</span> enable_gpu_ram_resizing:
        <span style="color:#66d9ef">for</span> device <span style="color:#f92672">in</span> gpu_devices:
           tf<span style="color:#f92672">.</span>config<span style="color:#f92672">.</span>experimental<span style="color:#f92672">.</span>set_memory_growth(device, True)
    <span style="color:#66d9ef">if</span> enable_xla:
        config<span style="color:#f92672">.</span>optimizer<span style="color:#f92672">.</span>set_jit(True)
    <span style="color:#66d9ef">return</span> config

session_options(enable_gpu_ram_resizing<span style="color:#f92672">=</span>True, enable_xla<span style="color:#f92672">=</span>True)

<span style="color:#960050;background-color:#1e0010">!</span>apt <span style="color:#f92672">-</span>qq <span style="color:#f92672">-</span>y install fonts<span style="color:#f92672">-</span>nanum
 
<span style="color:#f92672">import</span> matplotlib.font_manager <span style="color:#f92672">as</span> fm
fontpath <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;/usr/share/fonts/truetype/nanum/NanumBarunGothic.ttf&#39;</span>
font <span style="color:#f92672">=</span> fm<span style="color:#f92672">.</span>FontProperties(fname<span style="color:#f92672">=</span>fontpath, size<span style="color:#f92672">=</span><span style="color:#ae81ff">9</span>)
plt<span style="color:#f92672">.</span>rc(<span style="color:#e6db74">&#39;font&#39;</span>, family<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;NanumBarunGothic&#39;</span>) 
mpl<span style="color:#f92672">.</span>font_manager<span style="color:#f92672">.</span>_rebuild()
</code></pre></div><pre><code>The following package was automatically installed and is no longer required:
  libnvidia-common-440
Use 'apt autoremove' to remove it.
The following NEW packages will be installed:
  fonts-nanum
0 upgraded, 1 newly installed, 0 to remove and 39 not upgraded.
Need to get 9,604 kB of archives.
After this operation, 29.5 MB of additional disk space will be used.
Selecting previously unselected package fonts-nanum.
(Reading database ... 144579 files and directories currently installed.)
Preparing to unpack .../fonts-nanum_20170925-1_all.deb ...
Unpacking fonts-nanum (20170925-1) ...
Setting up fonts-nanum (20170925-1) ...
Processing triggers for fontconfig (2.12.6-0ubuntu2) ...
</code></pre>
<h1 id="1-basic-tensorflow">1. Basic TensorFlow</h1>
<p>TFP에 대해 설명하기 앞서, TensorFlow tensor의 여러가지 기능에 대해서 살펴보려고 합니다. 여기에서는 TensorFlow Graphs의 개념에 대해 소개하고 tensor를 다루는 과정을 더 빠르고 더 우아하게 만드는 코딩 패턴들에 대해 배우게 될 것입니다!</p>
<h3 id="tensorflow-graph와-즉시실행eager-모드"><strong>TensorFlow Graph와 즉시실행(Eager) 모드</strong></h3>
<p>TFP가 하는 어려운 일들은 대부분 <code>tensorflow</code> 라이브러리를 통해 행해집니다. <code>tensorflow</code>라이브러리는 여러분들에게 익숙한 <code>NumPy</code>와 비슷한 여러가지 도구들을 가지고 있고 비슷한 이름들로 사용됩니다. <code>NumPy</code>가 직접적으로 계산을 실행하는 반면(a+b를 실행하는 것과 같이) <code>tensorflow</code>의 <strong>그래프 모드</strong>는 대신 당신이 a와 b라는 원소들에 대해 +라는 연산을 실행하고 싶다는 과정을 추적하는 &ldquo;계산 그래프(compute graph)&ldquo;라는 것을 만듭니다. 오직 당신이 <code>tensorflow</code> 표현식을 실행할 때만 계산이 이루어집니다. 즉 <code>tensorflow</code>는 바로 실행되는 것이 아니라 지연 실행된다고 할 수 있죠. 간단하게 예를 들어봅시다.</p>
<blockquote>
<p>당신은 이등병입니다. 병장이 당신에게 일을 시킵니다. &ldquo;창고 가서 삽 하나 가져와!&rdquo; 삽을 가져옵니다. 갔다 왔는데 또 일을 시킵니다 &ldquo;창고 가서 빗자루도 하나 가져와!&rdquo; 당신은 또 창고에 가서 빗자루를 가져옵니다. 가져왔는데 또 일을 시킵니다. &ldquo;창고 가서 쓰레받기도 가져와!&rdquo; 당신은 또 쓰레받기를 가져옵니다. 자 이제 당신은 짜증이 났습니다. 다음날 병장이 또 일을 시킵니다. &ldquo;창고 가서 걸레 하나 가져와&rdquo; 이번엔 바로 창고에 가지 않습니다. 얼마 뒤 또 일을 시킵니다 &ldquo;창고 가서 락스 한 통 가져와&rdquo; 이번에도 일단 가지 않습니다. 자 이제 병장이 말을 합니다. &ldquo;얘들아 이제 청소하자!&rdquo; 이제서야 당신은 창고에 가서 걸레와 락스를 가지고 옵니다.</p>
</blockquote>
<p>이것이 바로 <code>tensorflow</code>의 그래프 모드라고 생각하면 됩니다. 창고에 가서 무엇을 가져오라는 명령문이 작성되었을 때는 그저 저장만 해놨다가 청소하자는 실행문이 작성되었을 때 그제서야 앞의 명령문들을 실행하는거죠. <code>NumPy</code>가 아니라 <code>TensorFlow</code>를 사용하는 장점은 바로 이 방식이 수학적인 최적화(예를 들면 단순화)를 가능하게 한다는 점이죠. 빠르게 전체 그래프를 미분해 기울기(gradient)를 계산할 수 있고, 그것을 GPU나 TPU같은 기기에서 병렬 처리할 수도 있습니다.</p>
<p>즉 기본적으로 <code>tensorflow</code>는 계산을 할 때 이러한 그래프들을 사용합니다. 그래프란 계산을 각각 따로 하는 것이 아니라 개별 연산자들을 묶어서 표현하는거죠. Tensorflow 그래프를 프로그래밍하는 방식은 처음으로 데이터 흐름 그래프를 정의한 다음 그래프의 일부를 TensorFlow Session을 만듦으로써 실행하는겁니다. TensorFlow의 <code>tf.Session()</code> 객체는 우리가 모델에 원하는 변수들을 얻기 위해 그래프를 실행시킵니다. 밑에 있는 예시에서, 우리는 전역(global) session 객체인 <code>sess</code>를 사용합니다. 바로 맨 처음에 있는 &lsquo;기본 설정&rsquo; 셀에서 만들었던거죠.</p>
<p>가끔 발생할 수 있는 지연실행의 헷갈리는 것들을 피하기 위해 TensorFlow의 즉시 실행(eager) 모드는 <code>NumPy</code>가 하는 것과 비슷하게 즉시 결과물을 내놓습니다. TensorFlow 즉시실행 모드에서는 명시적인 그래프를 만들지 않고 즉시 연산을 실행할 수 있습니다. 연산이 나중에 실행될 그래프를 만드는게 아니라 즉시 값을 반환하는거죠. 즉시 실행 모드에서는 바로 <code>NumPy array</code>와 동일한 것으로 변환할 수 있는 tensor들을 반환합니다. 즉시 실행 모드를 통해 쉽게 TensorFlow를 시작할 수 있고 모델들을 디버깅할 수 있는 것이죠.</p>
<p>TFP는 본질적으로 이렇습니다</p>
<ul>
<li>
<p>다양한 확률 분포를 표현하기 위한 tensorflow의 표현 기호들의 모임이 하나의 큰 컴퓨팅 그래프에 합쳐진 것</p>
</li>
<li>
<p>그러한 그래프를 활용해 확률들과 기울기를 구하는 추론 알고리즘의 모임</p>
</li>
</ul>
<p>실용적인 목적, 즉 특정한 모델을 만들기 위해서는 가끔 기본 TensorFlow를 사용해야 할 때가 있습니다. 밑의 포아용 샘플링 예시는 어떻게 우리가 그래프와 즉시실행 모드 둘 다 실행하는지를 알려줍니다.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">parameter <span style="color:#f92672">=</span> tfd<span style="color:#f92672">.</span>Exponential(rate<span style="color:#f92672">=</span><span style="color:#ae81ff">1.</span>, name<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;poisson_param&#34;</span>)<span style="color:#f92672">.</span>sample() 
<span style="color:#75715e"># lambda가 1인 지수 분포에서 샘플을 뽑습니다. 이걸 포아송 분포의 파라미터들로 쓸 것입니다.</span>
rv_data_generator <span style="color:#f92672">=</span> tfd<span style="color:#f92672">.</span>Poisson(parameter, name<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;data_generator&#34;</span>)
<span style="color:#75715e"># 위에서 뽑은 샘플들을 파라미터로 사용해 포아송 분포를 정의합니다</span>
data_generator <span style="color:#f92672">=</span> rv_data_generator<span style="color:#f92672">.</span>sample()
<span style="color:#75715e"># 위에서 정의한 포아송 분포에서 랜덤 변수를 뽑습니다</span>

<span style="color:#66d9ef">if</span> tf<span style="color:#f92672">.</span>executing_eagerly():
    data_generator_ <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>nest<span style="color:#f92672">.</span>pack_sequence_as(
        data_generator,
        [t<span style="color:#f92672">.</span>numpy() <span style="color:#66d9ef">if</span> tf<span style="color:#f92672">.</span>is_tensor(t) <span style="color:#66d9ef">else</span> t
         <span style="color:#66d9ef">for</span> t <span style="color:#f92672">in</span> tf<span style="color:#f92672">.</span>nest<span style="color:#f92672">.</span>flatten(data_generator)])
    <span style="color:#75715e"># eager mode의 경우에는 data_generator에서 뽑은 원소들을 넘파이로 변환해 출력합니다</span>
<span style="color:#66d9ef">else</span>:
    data_generator_ <span style="color:#f92672">=</span> sess<span style="color:#f92672">.</span>run(data_generator)
    <span style="color:#75715e"># graph mode의 경우에는 sess.run을 통해 session을 실행시킵니다</span>
<span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#34;Value of sample from data generator random variable:&#34;</span>, data_generator_)
</code></pre></div><pre><code>Value of sample from data generator random variable: 1.0
</code></pre>
<p>그래프 모드에서 TensorFlow는 자동적으로 어떤 변수를 그래프에 할당합니다. 그것들은 세션에서 실행되거나 즉시 실행 모드로 사용 가능하게 만들 수 있죠. 만약 당신이 세션이 이미 닫혔거나 끝난 상태에서 변수를 정의하려고 한다면 에러가 발생할 것입니다. 위의 기본 설정 셀에서 우리는 특정한 타입의 세션을 정의했습니다. 그 중 전역(global)<code>InteractiveSession</code> 함수는 우리를 셸이나 주피터 노트북을 통해 사용자와 프로그램이 상호 대화식으로 우리의 세션 변수들에 접근하게 할 수 있습니다.</p>
<p>전역 세션의 패턴을 사용하면, 우리는 그래프를 점점 쌓아나갈 수 있고 결과를 구하기 위해 그것의 부분만을 실행시킬 수 있습니다.</p>
<p>즉시 실행은 세션 함수를 명시적으로 불러올 필요가 없어서 우리의 코드를 더욱 간단하게 합니다. 실제로 당신이 즉시 실행 모드로 그래프 모드를 실행하려고 하면 다음과 같은 에러가 발생할 것입니다.</p>
<pre><code>AttributeError: Tensor.graph is meaningless when eager execution is enabled.
</code></pre><p>이전 챕터에서 언급한 것과 같이 우리는 그래프 모드와 즉시 실행 모드를 둘 다 사용 가능한 코드를 만들 수 있게 하는 멋진 도구를 가지고 있습니다. 믿에서 만든 <code>evaluate</code>함수는 우리가 TensorFlow 그래프로 실행시키든 즉시 실행 모드로 실행시키든 텐서를 실행할 수 있게 해줍니다. 위에서 만든 포아송 샘플링 코드를 일반화 하면 이렇게 쓸 수 있죠</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">evaluate</span>(tensors):
    <span style="color:#66d9ef">if</span> tf<span style="color:#f92672">.</span>executing_eagerly():
         <span style="color:#66d9ef">return</span> tf<span style="color:#f92672">.</span>nest<span style="color:#f92672">.</span>pack_sequence_as(
             tensors,
             [t<span style="color:#f92672">.</span>numpy() <span style="color:#66d9ef">if</span> tf<span style="color:#f92672">.</span>is_tensor(t) <span style="color:#66d9ef">else</span> t
             <span style="color:#66d9ef">for</span> t <span style="color:#f92672">in</span> tf<span style="color:#f92672">.</span>nest<span style="color:#f92672">.</span>flatten(tensors)])
    <span style="color:#66d9ef">with</span> tf<span style="color:#f92672">.</span>Session() <span style="color:#66d9ef">as</span> sess:
        <span style="color:#66d9ef">return</span> sess<span style="color:#f92672">.</span>run(tensors)
</code></pre></div><p>각각의 텐서들은 NumPy같은 결과물에 대응합니다. 텐서들과 그들의 Numpy같은 대응품을 구별하기 위해서 우리는 전통적으로 _를 뒤에 붙입니다. 이건 NumPy array 같이 쓸 수 있는 버전의 텐서라는 뜻이죠(위의 포아송 샘플링 예제에서의 <code>data_generator_</code>). 다른 말로 하면, <code>evaluate</code>함수의 결과물은 <code>variable + _ = variable_</code>과 같이 이름붙여지게 됩니다. 자 이제 위의 포아송 샘플링을 <code>evaluate()</code>함수와 _붙이기 방식을 사용해 다시 코딩해봅시다.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e"># 가정(포아송 분포의 모수가 지수함수에서 랜덤으로 뽑힌 것이다)을 정의하고</span>
parameter <span style="color:#f92672">=</span> tfd<span style="color:#f92672">.</span>Exponential(rate<span style="color:#f92672">=</span><span style="color:#ae81ff">1.</span>, name<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;poisson_param&#34;</span>)<span style="color:#f92672">.</span>sample()

<span style="color:#75715e"># TensorFlow를 Numpy로 변환합니다</span>
[ parameter_ ] <span style="color:#f92672">=</span> evaluate([ parameter ])

<span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#34;실행 전의 지수분포 샘플 : &#34;</span>, parameter)
<span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#34;샐행 후의 지수분포 샘플 : &#34;</span>, parameter_)
</code></pre></div><pre><code>실행 전의 지수분포 샘플 :  tf.Tensor(1.6882404, shape=(), dtype=float32)
샐행 후의 지수분포 샘플 :  1.6882404
</code></pre>
<p>실행 전과 실행 전의 출력물의 차이가 보이시나요?</p>
<p>더 일반화하자면 <code>evalutate()</code>함수를 통해 TensorFlow <code>tensor</code>자료 구조와 우리가 계산을 실행할 수 있는 구조(NumPy array같은 구조)사이를 왔다갔다 할 수 있습니다.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">[ 
    parameter_,
    data_generator_,
] <span style="color:#f92672">=</span> evaluate([ 
    parameter, 
    data_generator,
])

<span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#34;&#39;parameter_&#39; evaluated Tensor :&#34;</span>, parameter_)
<span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#34;&#39;data_generator_&#39; sample evaluated Tensor :&#34;</span>, data_generator_)
</code></pre></div><pre><code>'parameter_' evaluated Tensor : 1.6882404
'data_generator_' sample evaluated Tensor : 1.0
</code></pre>
<p>TensorFlow 프로그래밍을 할 때 꼭 기억해야 하는 것은 NumPy 함수에서 지원되는 계산들을 해야 한다면, TensorFlow <code>tensor</code>를 그들과 같게 만들어야 한다는 것입니다.(그래서 이전 장에서 예제를 풀 때, tensor.numpy().mean()과 같은 방식으로 넘파이로 변환해 평균 함수를 쓴 것입니다) 이 연습은 매우 중요합니다. NumPy는 오직 고정된 값 하나를 출력할 수 있지만, TensorFlow의 <code>tensor</code>는 컴퓨테이션 그래프의 동적인 한 부분이기 때문이죠. 그래서 이 두 가지를 잘못된 방식으로 섞으려 한다면, 두 자료구조의 타입이 다르기 때문에 보통 에러를 출력받게 될 것입니다.</p>

		</div>
		<footer class="post__footer">
			
<div class="post__tags tags clearfix">
	<svg class="tags__badge icon icon-tag" width="16" height="16" viewBox="0 0 32 32"><path d="M32 19c0 1-1 2-1 2L21 31s-1 1-2 1-2-1-2-1L2 16c-1-1-1.4-2-1.4-2S0 12.5 0 11V3C0 1.5.8.8.8.8S1.5 0 3 0h8c1.5 0 3 .6 3 .6S15 1 16 2l15 15s1 1 1 2zM7 10a3 3 0 1 0 0-6 3 3 0 0 0 0 6z"/></svg>
	<ul class="tags__list">
		<li class="tags__item">
			<a class="tags__link btn" href="/tags/bayesian/" rel="tag">Bayesian</a>
		</li>
		<li class="tags__item">
			<a class="tags__link btn" href="/tags/tensorflow/" rel="tag">TensorFlow</a>
		</li>
		<li class="tags__item">
			<a class="tags__link btn" href="/tags/python/" rel="tag">Python</a>
		</li>
	</ul>
</div>
		</footer>
	</article>
</main>

<div class="authorbox clearfix">
	<div class="authorbox__header">
		<span class="authorbox__name"></span>
	</div>
</div>



			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2021 Tai Hwan Oh.
			<span class="footer__copyright-credits"></span>
		</div>
	</div>
</footer>
	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>