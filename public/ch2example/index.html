<!DOCTYPE html>
<html class="no-js" lang="en-us">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<title>Bayesian Method with TensorFlow Chapter 2. 연습문제 풀이 - Oh Data Science</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="Bayesian Method with TensorFlow Chapter 2. 연습문제 풀이" />
<meta property="og:description" content="Bayesian Method with TensorFlow - Chapter2 More on TensorFlow and TensorFlow Probability 연습문제 풀이 기본 설정 #@title Imports and Global Variables (make sure to run this cell) { display-mode: &#34;form&#34; } try: # %tensorflow_version only exists in Colab. %tensorflow_version 2.x except Exception: pass from __future__ import absolute_import, division, print_function #@markdown This sets the warning status (default is `ignore`, since this notebook runs correctly) warning_status = &#34;ignore&#34; #@param [&#34;ignore&#34;, &#34;always&#34;, &#34;module&#34;, &#34;once&#34;, &#34;default&#34;, &#34;error&#34;] import warnings warnings." />
<meta property="og:type" content="article" />
<meta property="og:url" content="http://example.org/ch2example/" />
<meta property="article:published_time" content="2020-09-08T18:56:54+09:00" />
<meta property="article:modified_time" content="2020-09-08T18:56:54+09:00" />

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="Oh Data Science" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">Oh Data Science</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Bayesian Method with TensorFlow Chapter 2. 연습문제 풀이</h1>
			
		</header><div class="content post__content clearfix">
			<h1 id="bayesian-method-with-tensorflow---chapter2-more-on-tensorflow-and-tensorflow-probability"><strong>Bayesian Method with TensorFlow - Chapter2 More on TensorFlow and TensorFlow Probability</strong></h1>
<h2 id="연습문제-풀이"><strong>연습문제 풀이</strong></h2>
<h3 id="기본-설정">기본 설정</h3>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e">#@title Imports and Global Variables (make sure to run this cell)  { display-mode: &#34;form&#34; }</span>

<span style="color:#66d9ef">try</span>:
  <span style="color:#75715e"># %tensorflow_version only exists in Colab.</span>
  <span style="color:#f92672">%</span>tensorflow_version <span style="color:#ae81ff">2.</span>x
<span style="color:#66d9ef">except</span> <span style="color:#a6e22e">Exception</span>:
  <span style="color:#66d9ef">pass</span>


<span style="color:#f92672">from</span> __future__ <span style="color:#f92672">import</span> absolute_import, division, print_function


<span style="color:#75715e">#@markdown This sets the warning status (default is `ignore`, since this notebook runs correctly)</span>
warning_status <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;ignore&#34;</span> <span style="color:#75715e">#@param [&#34;ignore&#34;, &#34;always&#34;, &#34;module&#34;, &#34;once&#34;, &#34;default&#34;, &#34;error&#34;]</span>
<span style="color:#f92672">import</span> warnings
warnings<span style="color:#f92672">.</span>filterwarnings(warning_status)
<span style="color:#66d9ef">with</span> warnings<span style="color:#f92672">.</span>catch_warnings():
    warnings<span style="color:#f92672">.</span>filterwarnings(warning_status, category<span style="color:#f92672">=</span><span style="color:#a6e22e">DeprecationWarning</span>)
    warnings<span style="color:#f92672">.</span>filterwarnings(warning_status, category<span style="color:#f92672">=</span><span style="color:#a6e22e">UserWarning</span>)

<span style="color:#f92672">import</span> numpy <span style="color:#f92672">as</span> np
<span style="color:#f92672">import</span> os
<span style="color:#75715e">#@markdown This sets the styles of the plotting (default is styled like plots from [FiveThirtyeight.com](https://fivethirtyeight.com/)</span>
matplotlib_style <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;fivethirtyeight&#39;</span> <span style="color:#75715e">#@param [&#39;fivethirtyeight&#39;, &#39;bmh&#39;, &#39;ggplot&#39;, &#39;seaborn&#39;, &#39;default&#39;, &#39;Solarize_Light2&#39;, &#39;classic&#39;, &#39;dark_background&#39;, &#39;seaborn-colorblind&#39;, &#39;seaborn-notebook&#39;]</span>
<span style="color:#f92672">import</span> matplotlib.pyplot <span style="color:#f92672">as</span> plt; plt<span style="color:#f92672">.</span>style<span style="color:#f92672">.</span>use(matplotlib_style)
<span style="color:#f92672">import</span> matplotlib.axes <span style="color:#f92672">as</span> axes;
<span style="color:#f92672">from</span> matplotlib.patches <span style="color:#f92672">import</span> Ellipse
<span style="color:#f92672">import</span> matplotlib <span style="color:#f92672">as</span> mpl
<span style="color:#75715e">#%matplotlib inline</span>
<span style="color:#f92672">import</span> seaborn <span style="color:#f92672">as</span> sns; sns<span style="color:#f92672">.</span>set_context(<span style="color:#e6db74">&#39;notebook&#39;</span>)
<span style="color:#f92672">from</span> IPython.core.pylabtools <span style="color:#f92672">import</span> figsize
<span style="color:#75715e">#@markdown This sets the resolution of the plot outputs (`retina` is the highest resolution)</span>
notebook_screen_res <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;retina&#39;</span> <span style="color:#75715e">#@param [&#39;retina&#39;, &#39;png&#39;, &#39;jpeg&#39;, &#39;svg&#39;, &#39;pdf&#39;]</span>
<span style="color:#75715e">#%config InlineBackend.figure_format = notebook_screen_res</span>

<span style="color:#f92672">import</span> tensorflow <span style="color:#f92672">as</span> tf

<span style="color:#f92672">import</span> tensorflow_probability <span style="color:#f92672">as</span> tfp
tfd <span style="color:#f92672">=</span> tfp<span style="color:#f92672">.</span>distributions
tfb <span style="color:#f92672">=</span> tfp<span style="color:#f92672">.</span>bijectors

<span style="color:#66d9ef">class</span> <span style="color:#a6e22e">_TFColor</span>(object):
    <span style="color:#e6db74">&#34;&#34;&#34;Enum of colors used in TF docs.&#34;&#34;&#34;</span>
    red <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;#F15854&#39;</span>
    blue <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;#5DA5DA&#39;</span>
    orange <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;#FAA43A&#39;</span>
    green <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;#60BD68&#39;</span>
    pink <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;#F17CB0&#39;</span>
    brown <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;#B2912F&#39;</span>
    purple <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;#B276B2&#39;</span>
    yellow <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;#DECF3F&#39;</span>
    gray <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;#4D4D4D&#39;</span>
    <span style="color:#66d9ef">def</span> __getitem__(self, i):
        <span style="color:#66d9ef">return</span> [
            self<span style="color:#f92672">.</span>red,
            self<span style="color:#f92672">.</span>orange,
            self<span style="color:#f92672">.</span>green,
            self<span style="color:#f92672">.</span>blue,
            self<span style="color:#f92672">.</span>pink,
            self<span style="color:#f92672">.</span>brown,
            self<span style="color:#f92672">.</span>purple,
            self<span style="color:#f92672">.</span>yellow,
            self<span style="color:#f92672">.</span>gray,
        ][i <span style="color:#f92672">%</span> <span style="color:#ae81ff">9</span>]
TFColor <span style="color:#f92672">=</span> _TFColor()

<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">session_options</span>(enable_gpu_ram_resizing<span style="color:#f92672">=</span>True, enable_xla<span style="color:#f92672">=</span>False):
    <span style="color:#e6db74">&#34;&#34;&#34;
</span><span style="color:#e6db74">    Allowing the notebook to make use of GPUs if they&#39;re available.
</span><span style="color:#e6db74">
</span><span style="color:#e6db74">    XLA (Accelerated Linear Algebra) is a domain-specific compiler for linear
</span><span style="color:#e6db74">    algebra that optimizes TensorFlow computations.
</span><span style="color:#e6db74">    &#34;&#34;&#34;</span>
    config <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>config
    gpu_devices <span style="color:#f92672">=</span> config<span style="color:#f92672">.</span>experimental<span style="color:#f92672">.</span>list_physical_devices(<span style="color:#e6db74">&#39;GPU&#39;</span>)
    <span style="color:#66d9ef">if</span> enable_gpu_ram_resizing:
        <span style="color:#66d9ef">for</span> device <span style="color:#f92672">in</span> gpu_devices:
           tf<span style="color:#f92672">.</span>config<span style="color:#f92672">.</span>experimental<span style="color:#f92672">.</span>set_memory_growth(device, True)
    <span style="color:#66d9ef">if</span> enable_xla:
        config<span style="color:#f92672">.</span>optimizer<span style="color:#f92672">.</span>set_jit(True)
    <span style="color:#66d9ef">return</span> config

session_options(enable_gpu_ram_resizing<span style="color:#f92672">=</span>True, enable_xla<span style="color:#f92672">=</span>True)

<span style="color:#960050;background-color:#1e0010">!</span>apt <span style="color:#f92672">-</span>qq <span style="color:#f92672">-</span>y install fonts<span style="color:#f92672">-</span>nanum
 
<span style="color:#f92672">import</span> matplotlib.font_manager <span style="color:#f92672">as</span> fm
fontpath <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;/usr/share/fonts/truetype/nanum/NanumBarunGothic.ttf&#39;</span>
font <span style="color:#f92672">=</span> fm<span style="color:#f92672">.</span>FontProperties(fname<span style="color:#f92672">=</span>fontpath, size<span style="color:#f92672">=</span><span style="color:#ae81ff">9</span>)
plt<span style="color:#f92672">.</span>rc(<span style="color:#e6db74">&#39;font&#39;</span>, family<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;NanumBarunGothic&#39;</span>) 
mpl<span style="color:#f92672">.</span>font_manager<span style="color:#f92672">.</span>_rebuild()
</code></pre></div><pre><code>The following package was automatically installed and is no longer required:
  libnvidia-common-440
Use 'apt autoremove' to remove it.
The following NEW packages will be installed:
  fonts-nanum
0 upgraded, 1 newly installed, 0 to remove and 39 not upgraded.
Need to get 9,604 kB of archives.
After this operation, 29.5 MB of additional disk space will be used.
Selecting previously unselected package fonts-nanum.
(Reading database ... 144579 files and directories currently installed.)
Preparing to unpack .../fonts-nanum_20170925-1_all.deb ...
Unpacking fonts-nanum (20170925-1) ...
Setting up fonts-nanum (20170925-1) ...
Processing triggers for fontconfig (2.12.6-0ubuntu2) ...
</code></pre>
<h3 id="1-치팅-예제에서-우리의-관찰값이-극단적인-값을-가진다고-가정합시다-만일-치팅을-했다는-대답을-25번-10번-50번-받았다면-어떻게-될까요"><strong>1. 치팅 예제에서 우리의 관찰값이 극단적인 값을 가진다고 가정합시다. 만일 치팅을 했다는 대답을 25번, 10번, 50번 받았다면 어떻게 될까요?</strong></h3>
<p>1-1) Prior Probability 만들기</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e"># evaluate 함수 생성</span>
<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">evaluate</span>(tensors):
    <span style="color:#66d9ef">if</span> tf<span style="color:#f92672">.</span>executing_eagerly():
         <span style="color:#66d9ef">return</span> tf<span style="color:#f92672">.</span>nest<span style="color:#f92672">.</span>pack_sequence_as(
             tensors,
             [t<span style="color:#f92672">.</span>numpy() <span style="color:#66d9ef">if</span> tf<span style="color:#f92672">.</span>is_tensor(t) <span style="color:#66d9ef">else</span> t
             <span style="color:#66d9ef">for</span> t <span style="color:#f92672">in</span> tf<span style="color:#f92672">.</span>nest<span style="color:#f92672">.</span>flatten(tensors)])
    <span style="color:#66d9ef">with</span> tf<span style="color:#f92672">.</span>Session() <span style="color:#66d9ef">as</span> sess:
        <span style="color:#66d9ef">return</span> sess<span style="color:#f92672">.</span>run(tensors)
</code></pre></div><p>Uniform(0,1)로 가정</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">N <span style="color:#f92672">=</span> <span style="color:#ae81ff">100</span>
rv_p <span style="color:#f92672">=</span> tfd<span style="color:#f92672">.</span>Uniform(name<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;freq_cheating&#34;</span>, low<span style="color:#f92672">=</span><span style="color:#ae81ff">0.</span>, high<span style="color:#f92672">=</span><span style="color:#ae81ff">1.</span>)
</code></pre></div><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e"># Uniform(0,1)에서 샘플링한 rv_p를 모수로 하는 베르누이 분포를 만듭니다(이것은 실제 p의 분포를 뜻합니다)</span>
true_answers <span style="color:#f92672">=</span> tfd<span style="color:#f92672">.</span>Bernoulli(name<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;truths&#34;</span>, 
                             probs<span style="color:#f92672">=</span>rv_p<span style="color:#f92672">.</span>sample())<span style="color:#f92672">.</span>sample(sample_shape<span style="color:#f92672">=</span>N, 
                                                      seed<span style="color:#f92672">=</span><span style="color:#ae81ff">5</span>)
<span style="color:#75715e"># 그래프를 실행합시다</span>
[
    true_answers_,
] <span style="color:#f92672">=</span> evaluate([
    true_answers,
])

<span style="color:#66d9ef">print</span>(true_answers_)
<span style="color:#66d9ef">print</span>(true_answers_<span style="color:#f92672">.</span>sum())
</code></pre></div><pre><code>[1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 0 0 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1
 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 0
 1 0 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1]
83
</code></pre>
<p>첫 번째 동전 던지기</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">N <span style="color:#f92672">=</span> <span style="color:#ae81ff">100</span>
first_coin_flips <span style="color:#f92672">=</span> tfd<span style="color:#f92672">.</span>Bernoulli(name<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;first_flips&#34;</span>, 
                                 probs<span style="color:#f92672">=</span><span style="color:#ae81ff">0.5</span>)<span style="color:#f92672">.</span>sample(sample_shape<span style="color:#f92672">=</span>N, 
                                                   seed<span style="color:#f92672">=</span><span style="color:#ae81ff">5</span>)
<span style="color:#75715e"># 그래프 실행</span>
[
    first_coin_flips_,
] <span style="color:#f92672">=</span> evaluate([
    first_coin_flips,
])

<span style="color:#66d9ef">print</span>(first_coin_flips_)
</code></pre></div><pre><code>[1 1 1 0 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 1 1 1 0 1 1 1 0 0 0 0 0 0 0 1 1
 1 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 1 1 1 0 1 1 1 0 1 1 1 1 0 0 1 0 0 1 1 1 1
 0 1 0 0 0 0 0 0 0 0 1 0 1 1 0 1 0 1 0 1 1 1 0 0 0 1]
</code></pre>
<p>두 번째 동전 던지기</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">N <span style="color:#f92672">=</span> <span style="color:#ae81ff">100</span>
second_coin_flips <span style="color:#f92672">=</span> tfd<span style="color:#f92672">.</span>Bernoulli(name <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;second_flips&#39;</span>, probs<span style="color:#f92672">=</span><span style="color:#ae81ff">0.5</span>)<span style="color:#f92672">.</span>sample(sample_shape <span style="color:#f92672">=</span> N, seed <span style="color:#f92672">=</span> <span style="color:#ae81ff">5</span>)
[
 second_coin_flips_
] <span style="color:#f92672">=</span> evaluate([
    second_coin_flips
])
<span style="color:#66d9ef">print</span>(second_coin_flips_)
</code></pre></div><pre><code>[1 1 1 0 1 1 0 0 0 0 0 1 1 1 1 0 0 1 1 1 1 1 0 0 1 0 1 0 1 1 1 1 0 0 0 0 1
 0 0 0 1 1 1 1 0 1 1 1 0 1 1 1 1 1 0 1 1 0 0 0 1 0 0 0 1 0 1 0 0 1 0 0 0 1
 0 1 0 0 0 1 1 1 0 0 1 1 1 0 0 0 1 1 0 1 0 0 1 0 1 1]
</code></pre>
<p>&ldquo;예&quot;라고 답하는 비율 만들기</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">observed_proportion_calc</span>(t_a <span style="color:#f92672">=</span> true_answers, 
                             fc <span style="color:#f92672">=</span> first_coin_flips,
                             sc <span style="color:#f92672">=</span> second_coin_flips):
    <span style="color:#e6db74">&#34;&#34;&#34;
</span><span style="color:#e6db74">    정규화되지 않은 로그 사후 분포 함수
</span><span style="color:#e6db74">        
</span><span style="color:#e6db74">    Args:
</span><span style="color:#e6db74">      t_a: 사실대로 대답하는 것을 나타내는 이항 변수 array
</span><span style="color:#e6db74">      fc: 첫 번째 동전 던지기를 나타내는 이항 변수 array
</span><span style="color:#e6db74">      sc: 두 번째 동전 던지기를 나타내는 이항 변수 array
</span><span style="color:#e6db74">    Returns: 
</span><span style="color:#e6db74">      동전 던지기의 관측 비율
</span><span style="color:#e6db74">    Closure over: N
</span><span style="color:#e6db74">    &#34;&#34;&#34;</span>
    observed <span style="color:#f92672">=</span> fc <span style="color:#f92672">*</span> t_a <span style="color:#f92672">+</span> (<span style="color:#ae81ff">1</span> <span style="color:#f92672">-</span> fc) <span style="color:#f92672">*</span> sc
    observed_proportion <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>cast(tf<span style="color:#f92672">.</span>reduce_sum(observed), tf<span style="color:#f92672">.</span>float32) <span style="color:#f92672">/</span> tf<span style="color:#f92672">.</span>cast(N, tf<span style="color:#f92672">.</span>float32)
    
    <span style="color:#66d9ef">return</span> tf<span style="color:#f92672">.</span>cast(observed_proportion, tf<span style="color:#f92672">.</span>float32)
</code></pre></div><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">observed_proportion_val <span style="color:#f92672">=</span> observed_proportion_calc(t_a<span style="color:#f92672">=</span>true_answers_,
                                                   fc<span style="color:#f92672">=</span>first_coin_flips_,
                                                   sc<span style="color:#f92672">=</span>second_coin_flips_)
<span style="color:#75715e"># 그래프를 실행합니다</span>
[
    observed_proportion_val_,
] <span style="color:#f92672">=</span> evaluate([
    observed_proportion_val,
])

<span style="color:#66d9ef">print</span>(observed_proportion_val_)
</code></pre></div><pre><code>0.66
</code></pre>
<p>1-2) 데이터셋 만들기</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">total_count <span style="color:#f92672">=</span> <span style="color:#ae81ff">100</span>
total_yeses <span style="color:#f92672">=</span> [<span style="color:#ae81ff">25</span>, <span style="color:#ae81ff">10</span>, <span style="color:#ae81ff">50</span>]
</code></pre></div><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">coin_joint_log_prob</span>(total_yes, total_count, lies_prob):
    <span style="color:#e6db74">&#34;&#34;&#34;
</span><span style="color:#e6db74">    결합 로그 확률 최적화 함수
</span><span style="color:#e6db74">
</span><span style="color:#e6db74">    Args:
</span><span style="color:#e6db74">      headsflips: 총 동전 앞면의 갯수(정수)
</span><span style="color:#e6db74">      N: 총 동전 던진 횟수(정수)
</span><span style="color:#e6db74">      lies_prob: 이항분포에서 한 번 동전을 던졌을 때 앞면이 나올 확률
</span><span style="color:#e6db74">    Returns: 
</span><span style="color:#e6db74">      Joint log probability optimization function.
</span><span style="color:#e6db74">    &#34;&#34;&#34;</span>
  
    rv_lies_prob <span style="color:#f92672">=</span> tfd<span style="color:#f92672">.</span>Uniform(name<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;rv_lies_prob&#34;</span>,low<span style="color:#f92672">=</span><span style="color:#ae81ff">0.</span>, high<span style="color:#f92672">=</span><span style="color:#ae81ff">1.</span>)

    cheated <span style="color:#f92672">=</span> tfd<span style="color:#f92672">.</span>Bernoulli(probs<span style="color:#f92672">=</span>tf<span style="color:#f92672">.</span>cast(lies_prob, tf<span style="color:#f92672">.</span>float32))<span style="color:#f92672">.</span>sample(total_count)
    first_flips <span style="color:#f92672">=</span> tfd<span style="color:#f92672">.</span>Bernoulli(probs<span style="color:#f92672">=</span><span style="color:#ae81ff">0.5</span>)<span style="color:#f92672">.</span>sample(total_count)
    second_flips <span style="color:#f92672">=</span> tfd<span style="color:#f92672">.</span>Bernoulli(probs<span style="color:#f92672">=</span><span style="color:#ae81ff">0.5</span>)<span style="color:#f92672">.</span>sample(total_count)
    observed_probability <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>reduce_sum(tf<span style="color:#f92672">.</span>cast(
        cheated <span style="color:#f92672">*</span> first_flips <span style="color:#f92672">+</span> (<span style="color:#ae81ff">1</span> <span style="color:#f92672">-</span> first_flips) <span style="color:#f92672">*</span> second_flips, tf<span style="color:#f92672">.</span>float32)) <span style="color:#f92672">/</span> total_count

    rv_yeses <span style="color:#f92672">=</span> tfd<span style="color:#f92672">.</span>Binomial(name<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;rv_yeses&#34;</span>,
                total_count<span style="color:#f92672">=</span>float(total_count),
                probs<span style="color:#f92672">=</span>observed_probability)
    
    <span style="color:#66d9ef">return</span> (
        rv_lies_prob<span style="color:#f92672">.</span>log_prob(lies_prob)
        <span style="color:#f92672">+</span> tf<span style="color:#f92672">.</span>reduce_sum(rv_yeses<span style="color:#f92672">.</span>log_prob(tf<span style="color:#f92672">.</span>cast(total_yes, tf<span style="color:#f92672">.</span>float32)))
        )
</code></pre></div><p>1-3) Metropolis Hastings Modeling</p>
<p>a) total_yes = 25</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">burnin <span style="color:#f92672">=</span> <span style="color:#ae81ff">15000</span>
num_of_steps <span style="color:#f92672">=</span> <span style="color:#ae81ff">40000</span>
total_count<span style="color:#f92672">=</span><span style="color:#ae81ff">100</span>
total_yes <span style="color:#f92672">=</span> total_yeses[<span style="color:#ae81ff">0</span>]

<span style="color:#75715e"># Set the chain&#39;s start state.</span>
initial_chain_state <span style="color:#f92672">=</span> [
    <span style="color:#ae81ff">0.4</span> <span style="color:#f92672">*</span> tf<span style="color:#f92672">.</span>ones([], dtype<span style="color:#f92672">=</span>tf<span style="color:#f92672">.</span>float32, name<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;init_prob&#34;</span>)
]

<span style="color:#75715e"># Define a closure over our joint_log_prob.</span>
unnormalized_posterior_log_prob <span style="color:#f92672">=</span> <span style="color:#66d9ef">lambda</span> <span style="color:#f92672">*</span>args: coin_joint_log_prob(total_yes, total_count,  <span style="color:#f92672">*</span>args)

<span style="color:#75715e"># Defining the Metropolis-Hastings</span>
<span style="color:#75715e"># We use a Metropolis-Hastings method here instead of Hamiltonian method</span>
<span style="color:#75715e"># because the coin flips in the above example are non-differentiable and cannot</span>
<span style="color:#75715e"># be used with HMC.</span>
metropolis<span style="color:#f92672">=</span>tfp<span style="color:#f92672">.</span>mcmc<span style="color:#f92672">.</span>RandomWalkMetropolis(
    target_log_prob_fn<span style="color:#f92672">=</span>unnormalized_posterior_log_prob,
    seed<span style="color:#f92672">=</span><span style="color:#ae81ff">54</span>)

<span style="color:#75715e"># Sample from the chain.</span>
[
    posterior_p_25
], kernel_results_25 <span style="color:#f92672">=</span> tfp<span style="color:#f92672">.</span>mcmc<span style="color:#f92672">.</span>sample_chain(
    num_results<span style="color:#f92672">=</span>num_of_steps,
    num_burnin_steps<span style="color:#f92672">=</span>burnin,
    current_state<span style="color:#f92672">=</span>initial_chain_state,
    kernel<span style="color:#f92672">=</span>metropolis,
    parallel_iterations<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>,
    name<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;Metropolis-Hastings_coin-flips&#39;</span>)
</code></pre></div><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e"># 주의 : 그래프 모드에서는 이걸 실행하는데 5분 이상 걸릴 수 있습니다</span>
[
    posterior_p_25_,
    kernel_results_25_
] <span style="color:#f92672">=</span> evaluate([
    posterior_p_25,
    kernel_results_25,
])
 
<span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#34;acceptance rate: {}&#34;</span><span style="color:#f92672">.</span>format(
    kernel_results_25_<span style="color:#f92672">.</span>is_accepted<span style="color:#f92672">.</span>mean()))
<span style="color:#75715e"># print(&#34;prob_p trace: &#34;, posterior_p_)</span>
<span style="color:#75715e"># print(&#34;prob_p burned trace: &#34;, posterior_p_[burnin:])</span>
burned_cheating_freq_samples_25_ <span style="color:#f92672">=</span> posterior_p_25_[burnin:]
</code></pre></div><pre><code>acceptance rate: 0.058675
</code></pre>
<p>b) total_yes = 10</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">burnin <span style="color:#f92672">=</span> <span style="color:#ae81ff">15000</span>
num_of_steps <span style="color:#f92672">=</span> <span style="color:#ae81ff">40000</span>
total_count<span style="color:#f92672">=</span><span style="color:#ae81ff">100</span>
total_yes <span style="color:#f92672">=</span> total_yeses[<span style="color:#ae81ff">1</span>]

<span style="color:#75715e"># Set the chain&#39;s start state.</span>
initial_chain_state <span style="color:#f92672">=</span> [
    <span style="color:#ae81ff">0.4</span> <span style="color:#f92672">*</span> tf<span style="color:#f92672">.</span>ones([], dtype<span style="color:#f92672">=</span>tf<span style="color:#f92672">.</span>float32, name<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;init_prob&#34;</span>)
]

<span style="color:#75715e"># Define a closure over our joint_log_prob.</span>
unnormalized_posterior_log_prob <span style="color:#f92672">=</span> <span style="color:#66d9ef">lambda</span> <span style="color:#f92672">*</span>args: coin_joint_log_prob(total_yes, total_count,  <span style="color:#f92672">*</span>args)

<span style="color:#75715e"># Defining the Metropolis-Hastings</span>
<span style="color:#75715e"># We use a Metropolis-Hastings method here instead of Hamiltonian method</span>
<span style="color:#75715e"># because the coin flips in the above example are non-differentiable and cannot</span>
<span style="color:#75715e"># be used with HMC.</span>
metropolis<span style="color:#f92672">=</span>tfp<span style="color:#f92672">.</span>mcmc<span style="color:#f92672">.</span>RandomWalkMetropolis(
    target_log_prob_fn<span style="color:#f92672">=</span>unnormalized_posterior_log_prob,
    seed<span style="color:#f92672">=</span><span style="color:#ae81ff">54</span>)

<span style="color:#75715e"># Sample from the chain.</span>
[
    posterior_p_10
], kernel_results_10 <span style="color:#f92672">=</span> tfp<span style="color:#f92672">.</span>mcmc<span style="color:#f92672">.</span>sample_chain(
    num_results<span style="color:#f92672">=</span>num_of_steps,
    num_burnin_steps<span style="color:#f92672">=</span>burnin,
    current_state<span style="color:#f92672">=</span>initial_chain_state,
    kernel<span style="color:#f92672">=</span>metropolis,
    parallel_iterations<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>,
    name<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;Metropolis-Hastings_coin-flips&#39;</span>)
</code></pre></div><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e"># 주의 : 그래프 모드에서는 이걸 실행하는데 5분 이상 걸릴 수 있습니다</span>
[
    posterior_p_10_,
    kernel_results_10_
] <span style="color:#f92672">=</span> evaluate([
    posterior_p_10,
    kernel_results_10,
])
 
<span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#34;acceptance rate: {}&#34;</span><span style="color:#f92672">.</span>format(
    kernel_results_10_<span style="color:#f92672">.</span>is_accepted<span style="color:#f92672">.</span>mean()))
<span style="color:#75715e"># print(&#34;prob_p trace: &#34;, posterior_p_)</span>
<span style="color:#75715e"># print(&#34;prob_p burned trace: &#34;, posterior_p_[burnin:])</span>
burned_cheating_freq_samples_10_ <span style="color:#f92672">=</span> posterior_p_10_[burnin:]
</code></pre></div><pre><code>acceptance rate: 0.003425
</code></pre>
<p>c) total_yes = 50</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">burnin <span style="color:#f92672">=</span> <span style="color:#ae81ff">15000</span>
num_of_steps <span style="color:#f92672">=</span> <span style="color:#ae81ff">40000</span>
total_count<span style="color:#f92672">=</span><span style="color:#ae81ff">100</span>
total_yes <span style="color:#f92672">=</span> total_yeses[<span style="color:#ae81ff">2</span>]

<span style="color:#75715e"># Set the chain&#39;s start state.</span>
initial_chain_state <span style="color:#f92672">=</span> [
    <span style="color:#ae81ff">0.4</span> <span style="color:#f92672">*</span> tf<span style="color:#f92672">.</span>ones([], dtype<span style="color:#f92672">=</span>tf<span style="color:#f92672">.</span>float32, name<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;init_prob&#34;</span>)
]

<span style="color:#75715e"># Define a closure over our joint_log_prob.</span>
unnormalized_posterior_log_prob <span style="color:#f92672">=</span> <span style="color:#66d9ef">lambda</span> <span style="color:#f92672">*</span>args: coin_joint_log_prob(total_yes, total_count,  <span style="color:#f92672">*</span>args)

<span style="color:#75715e"># Defining the Metropolis-Hastings</span>
<span style="color:#75715e"># We use a Metropolis-Hastings method here instead of Hamiltonian method</span>
<span style="color:#75715e"># because the coin flips in the above example are non-differentiable and cannot</span>
<span style="color:#75715e"># be used with HMC.</span>
metropolis<span style="color:#f92672">=</span>tfp<span style="color:#f92672">.</span>mcmc<span style="color:#f92672">.</span>RandomWalkMetropolis(
    target_log_prob_fn<span style="color:#f92672">=</span>unnormalized_posterior_log_prob,
    seed<span style="color:#f92672">=</span><span style="color:#ae81ff">54</span>)

<span style="color:#75715e"># Sample from the chain.</span>
[
    posterior_p_50
], kernel_results_50 <span style="color:#f92672">=</span> tfp<span style="color:#f92672">.</span>mcmc<span style="color:#f92672">.</span>sample_chain(
    num_results<span style="color:#f92672">=</span>num_of_steps,
    num_burnin_steps<span style="color:#f92672">=</span>burnin,
    current_state<span style="color:#f92672">=</span>initial_chain_state,
    kernel<span style="color:#f92672">=</span>metropolis,
    parallel_iterations<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>,
    name<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;Metropolis-Hastings_coin-flips&#39;</span>)
</code></pre></div><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e"># 주의 : 그래프 모드에서는 이걸 실행하는데 5분 이상 걸릴 수 있습니다</span>
[
    posterior_p_50_,
    kernel_results_50_
] <span style="color:#f92672">=</span> evaluate([
    posterior_p_50,
    kernel_results_50,
])
 
<span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#34;acceptance rate: {}&#34;</span><span style="color:#f92672">.</span>format(
    kernel_results_50_<span style="color:#f92672">.</span>is_accepted<span style="color:#f92672">.</span>mean()))
<span style="color:#75715e"># print(&#34;prob_p trace: &#34;, posterior_p_)</span>
<span style="color:#75715e"># print(&#34;prob_p burned trace: &#34;, posterior_p_[burnin:])</span>
burned_cheating_freq_samples_50_ <span style="color:#f92672">=</span> posterior_p_50_[burnin:]
</code></pre></div><pre><code>acceptance rate: 0.1211
</code></pre>
<p>1-4) Drawing Plots</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">plt<span style="color:#f92672">.</span>figure(figsize(<span style="color:#ae81ff">12.5</span>, <span style="color:#ae81ff">12</span>))

ax <span style="color:#f92672">=</span> plt<span style="color:#f92672">.</span>subplot(<span style="color:#ae81ff">3</span>,<span style="color:#ae81ff">1</span>,<span style="color:#ae81ff">1</span>)
p_trace_ <span style="color:#f92672">=</span> burned_cheating_freq_samples_25_
plt<span style="color:#f92672">.</span>hist(p_trace_, histtype<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;stepfilled&#34;</span>, density<span style="color:#f92672">=</span>True, alpha<span style="color:#f92672">=</span><span style="color:#ae81ff">0.85</span>, bins<span style="color:#f92672">=</span><span style="color:#ae81ff">30</span>, 
         label<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;Posterior Dist&#34;</span>, color<span style="color:#f92672">=</span>TFColor[<span style="color:#ae81ff">3</span>])
plt<span style="color:#f92672">.</span>vlines([<span style="color:#f92672">.</span><span style="color:#ae81ff">1</span>, <span style="color:#f92672">.</span><span style="color:#ae81ff">40</span>], [<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">0</span>], [<span style="color:#ae81ff">5</span>, <span style="color:#ae81ff">5</span>], alpha<span style="color:#f92672">=</span><span style="color:#ae81ff">0.3</span>)
plt<span style="color:#f92672">.</span>xlim(<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">1</span>)
plt<span style="color:#f92672">.</span>title(<span style="color:#e6db74">&#34;total_yes = 25&#34;</span>)
plt<span style="color:#f92672">.</span>legend();

ax <span style="color:#f92672">=</span> plt<span style="color:#f92672">.</span>subplot(<span style="color:#ae81ff">3</span>,<span style="color:#ae81ff">1</span>,<span style="color:#ae81ff">2</span>)
p_trace_ <span style="color:#f92672">=</span> burned_cheating_freq_samples_10_
plt<span style="color:#f92672">.</span>hist(p_trace_, histtype<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;stepfilled&#34;</span>, density<span style="color:#f92672">=</span>True, alpha<span style="color:#f92672">=</span><span style="color:#ae81ff">0.85</span>, bins<span style="color:#f92672">=</span><span style="color:#ae81ff">30</span>, 
         label<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;Posterior Dist&#34;</span>, color<span style="color:#f92672">=</span>TFColor[<span style="color:#ae81ff">3</span>])
plt<span style="color:#f92672">.</span>vlines([<span style="color:#f92672">.</span><span style="color:#ae81ff">1</span>, <span style="color:#f92672">.</span><span style="color:#ae81ff">40</span>], [<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">0</span>], [<span style="color:#ae81ff">5</span>, <span style="color:#ae81ff">5</span>], alpha<span style="color:#f92672">=</span><span style="color:#ae81ff">0.3</span>)
plt<span style="color:#f92672">.</span>xlim(<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">1</span>)
plt<span style="color:#f92672">.</span>title(<span style="color:#e6db74">&#34;total_yes = 10&#34;</span>)
plt<span style="color:#f92672">.</span>legend();

ax <span style="color:#f92672">=</span> plt<span style="color:#f92672">.</span>subplot(<span style="color:#ae81ff">3</span>,<span style="color:#ae81ff">1</span>,<span style="color:#ae81ff">3</span>)
p_trace_ <span style="color:#f92672">=</span> burned_cheating_freq_samples_50_
plt<span style="color:#f92672">.</span>hist(p_trace_, histtype<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;stepfilled&#34;</span>, density<span style="color:#f92672">=</span>True, alpha<span style="color:#f92672">=</span><span style="color:#ae81ff">0.85</span>, bins<span style="color:#f92672">=</span><span style="color:#ae81ff">30</span>, 
         label<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;Posterior Dist&#34;</span>, color<span style="color:#f92672">=</span>TFColor[<span style="color:#ae81ff">3</span>])
plt<span style="color:#f92672">.</span>vlines([<span style="color:#f92672">.</span><span style="color:#ae81ff">1</span>, <span style="color:#f92672">.</span><span style="color:#ae81ff">40</span>], [<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">0</span>], [<span style="color:#ae81ff">5</span>, <span style="color:#ae81ff">5</span>], alpha<span style="color:#f92672">=</span><span style="color:#ae81ff">0.3</span>)
plt<span style="color:#f92672">.</span>xlim(<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">1</span>)
plt<span style="color:#f92672">.</span>title(<span style="color:#e6db74">&#34;total_yes = 50&#34;</span>)

plt<span style="color:#f92672">.</span>legend();
</code></pre></div><p><img src="https://user-images.githubusercontent.com/57588650/92462289-43888480-f205-11ea-8959-661573da6c10.png" alt="output_30_0"></p>
<p>&ldquo;예&quot;라고 답한 비율에 따라 사후 분포가 결정된다는 사실을 알 수 있습니다. 특히 total_yes = 10인 경우에는 치터가 있을 확률이 거의 0입니다.</p>
<p>또한 total_yes의 수가 더욱 극단적일 수록 accpetance rate가 낮아지는 것을 알 수 있습니다.</p>
<h3 id="2-챌린저-호-예제에서-alpha의-표본과-beta의-표본을-뽑아서-그래프를-그려보고-대조해봅시다-왜-결과-그래프가-이렇게-나올까요"><strong>2. 챌린저 호 예제에서 $\alpha$의 표본과 $\beta$의 표본을 뽑아서 그래프를 그려보고 대조해봅시다. 왜 결과 그래프가 이렇게 나올까요?</strong></h3>
<p>2-0) 데이터 가져오기</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e">#pip install wget</span>
<span style="color:#f92672">import</span> wget
url <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;https://raw.githubusercontent.com/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/master/Chapter2_MorePyMC/data/challenger_data.csv&#39;</span>
filename <span style="color:#f92672">=</span> wget<span style="color:#f92672">.</span>download(url)
filename
</code></pre></div><pre><code>'challenger_data.csv'
</code></pre>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">challenger_data_ <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>genfromtxt(<span style="color:#e6db74">&#34;challenger_data.csv&#34;</span>, skip_header<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>,
                                usecols<span style="color:#f92672">=</span>[<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">2</span>], missing_values<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;NA&#34;</span>,
                                delimiter<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;,&#34;</span>)
<span style="color:#75715e">#drop the NA values</span>
challenger_data_ <span style="color:#f92672">=</span> challenger_data_[<span style="color:#f92672">~</span>np<span style="color:#f92672">.</span>isnan(challenger_data_[:, <span style="color:#ae81ff">1</span>])]
</code></pre></div><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#34;기온 (F), O-ring이 실패했는가?&#34;</span>)
<span style="color:#66d9ef">print</span>(challenger_data_)
</code></pre></div><pre><code>기온 (F), O-ring이 실패했는가?
[[66.  0.]
 [70.  1.]
 [69.  0.]
 [68.  0.]
 [67.  0.]
 [72.  0.]
 [73.  0.]
 [70.  0.]
 [57.  1.]
 [63.  1.]
 [70.  1.]
 [78.  0.]
 [67.  0.]
 [53.  1.]
 [67.  0.]
 [75.  0.]
 [70.  0.]
 [81.  0.]
 [76.  0.]
 [79.  0.]
 [75.  1.]
 [76.  0.]
 [58.  1.]]
</code></pre>
<p>2-1) Prior Distributuion to $\alpha, \beta$ (Normal Dist)</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e"># evaluate 함수 생성</span>
<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">evaluate</span>(tensors):
    <span style="color:#66d9ef">if</span> tf<span style="color:#f92672">.</span>executing_eagerly():
         <span style="color:#66d9ef">return</span> tf<span style="color:#f92672">.</span>nest<span style="color:#f92672">.</span>pack_sequence_as(
             tensors,
             [t<span style="color:#f92672">.</span>numpy() <span style="color:#66d9ef">if</span> tf<span style="color:#f92672">.</span>is_tensor(t) <span style="color:#66d9ef">else</span> t
             <span style="color:#66d9ef">for</span> t <span style="color:#f92672">in</span> tf<span style="color:#f92672">.</span>nest<span style="color:#f92672">.</span>flatten(tensors)])
    <span style="color:#66d9ef">with</span> tf<span style="color:#f92672">.</span>Session() <span style="color:#66d9ef">as</span> sess:
        <span style="color:#66d9ef">return</span> sess<span style="color:#f92672">.</span>run(tensors)

<span style="color:#75715e"># 외부 기온을 텐서로 만들기</span>
temperature_ <span style="color:#f92672">=</span> challenger_data_[:, <span style="color:#ae81ff">0</span>]
temperature <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>convert_to_tensor(temperature_, dtype<span style="color:#f92672">=</span>tf<span style="color:#f92672">.</span>float32)

<span style="color:#75715e"># 손상 여부를 텐서로 만들기</span>
D_ <span style="color:#f92672">=</span> challenger_data_[:, <span style="color:#ae81ff">1</span>]                <span style="color:#75715e"># defect or not?</span>
D <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>convert_to_tensor(D_, dtype<span style="color:#f92672">=</span>tf<span style="color:#f92672">.</span>float32)

<span style="color:#75715e"># beta와 alpha를 Normal 분포에서 샘플링</span>
beta <span style="color:#f92672">=</span> tfd<span style="color:#f92672">.</span>Normal(name<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;beta&#34;</span>, loc<span style="color:#f92672">=</span><span style="color:#ae81ff">0.3</span>, scale<span style="color:#f92672">=</span><span style="color:#ae81ff">1000.</span>)<span style="color:#f92672">.</span>sample()
alpha <span style="color:#f92672">=</span> tfd<span style="color:#f92672">.</span>Normal(name<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;alpha&#34;</span>, loc<span style="color:#f92672">=-</span><span style="color:#ae81ff">15.</span>, scale<span style="color:#f92672">=</span><span style="color:#ae81ff">1000.</span>)<span style="color:#f92672">.</span>sample()

<span style="color:#75715e"># beta와 온도, alpha를 로지스틱 함수로 합쳐서 결정론적인 확률 만들기</span>
p_deterministic <span style="color:#f92672">=</span> tfd<span style="color:#f92672">.</span>Deterministic(name<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;p&#34;</span>, loc<span style="color:#f92672">=</span><span style="color:#ae81ff">1.0</span><span style="color:#f92672">/</span>(<span style="color:#ae81ff">1.</span> <span style="color:#f92672">+</span> tf<span style="color:#f92672">.</span>exp(beta <span style="color:#f92672">*</span> temperature_ <span style="color:#f92672">+</span> alpha)))<span style="color:#f92672">.</span>sample()

<span style="color:#75715e"># 그래프 실행하기</span>
[
    prior_alpha_,
    prior_beta_,
    p_deterministic_,
    D_,
] <span style="color:#f92672">=</span> evaluate([
    alpha,
    beta,
    p_deterministic,
    D,
])
</code></pre></div><p>2-2) joint_log_prob 함수를 만듭시다</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">
<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">challenger_joint_log_prob</span>(D, temperature_, alpha, beta):
    <span style="color:#e6db74">&#34;&#34;&#34;
</span><span style="color:#e6db74">    결합 로그 확률 최적화 함수
</span><span style="color:#e6db74">        
</span><span style="color:#e6db74">    Args:
</span><span style="color:#e6db74">      D: 결함이 나타났는지 안나타났는지를 보여주는 챌린저 참사 데이터
</span><span style="color:#e6db74">      temperature_: 결함이 나타났을 때 또는 나타나지 않았을 때의 기온을 나타내는 챌린저 참사 데이터
</span><span style="color:#e6db74">      alpha: HMC에 넣을 투입값 중 하나
</span><span style="color:#e6db74">      beta: HMC에 넣을 투입값 중 하나
</span><span style="color:#e6db74">    Returns: 
</span><span style="color:#e6db74">      결합 로그 확률 최적화 함수
</span><span style="color:#e6db74">    &#34;&#34;&#34;</span>

    <span style="color:#75715e"># N(0, 1000) 으로 시작합시다</span>
    rv_alpha <span style="color:#f92672">=</span> tfd<span style="color:#f92672">.</span>Normal(loc<span style="color:#f92672">=</span><span style="color:#ae81ff">0.</span>, scale<span style="color:#f92672">=</span><span style="color:#ae81ff">1000.</span>)
    rv_beta <span style="color:#f92672">=</span> tfd<span style="color:#f92672">.</span>Normal(loc<span style="color:#f92672">=</span><span style="color:#ae81ff">0.</span>, scale<span style="color:#f92672">=</span><span style="color:#ae81ff">1000.</span>)

    <span style="color:#75715e"># 이것을 로지스틱 함수로 변환합시다</span>
    logistic_p <span style="color:#f92672">=</span> <span style="color:#ae81ff">1.0</span><span style="color:#f92672">/</span>(<span style="color:#ae81ff">1.</span> <span style="color:#f92672">+</span> tf<span style="color:#f92672">.</span>exp(beta <span style="color:#f92672">*</span> tf<span style="color:#f92672">.</span>cast(temperature_, tf<span style="color:#f92672">.</span>float32) <span style="color:#f92672">+</span> alpha))
    rv_observed <span style="color:#f92672">=</span> tfd<span style="color:#f92672">.</span>Bernoulli(probs<span style="color:#f92672">=</span>logistic_p)
    
    <span style="color:#66d9ef">return</span> (
        rv_alpha<span style="color:#f92672">.</span>log_prob(alpha)
        <span style="color:#f92672">+</span> rv_beta<span style="color:#f92672">.</span>log_prob(beta)
        <span style="color:#f92672">+</span> tf<span style="color:#f92672">.</span>reduce_sum(rv_observed<span style="color:#f92672">.</span>log_prob(D))
    )
</code></pre></div><p>2-3) HMC Modeling</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">number_of_steps <span style="color:#f92672">=</span> <span style="color:#ae81ff">10000</span> 
burnin <span style="color:#f92672">=</span> <span style="color:#ae81ff">2000</span> 

<span style="color:#75715e"># 체인의 시작점을 alpha = 0, beta = 0으로 설정합시다</span>
initial_chain_state <span style="color:#f92672">=</span> [
    <span style="color:#ae81ff">0.</span> <span style="color:#f92672">*</span> tf<span style="color:#f92672">.</span>ones([], dtype<span style="color:#f92672">=</span>tf<span style="color:#f92672">.</span>float32, name<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;init_alpha&#34;</span>),
    <span style="color:#ae81ff">0.</span> <span style="color:#f92672">*</span> tf<span style="color:#f92672">.</span>ones([], dtype<span style="color:#f92672">=</span>tf<span style="color:#f92672">.</span>float32, name<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;init_beta&#34;</span>)
]

<span style="color:#75715e"># HMC가 과도하게 제약이 없으므로 실제 값으로 나오게 하기 위해 변환합니다</span>
<span style="color:#75715e"># 챌린저호 문제에서 대략 alpha가 beta의 100배이기 때문에 그것을 AffineScalar bijctor를 통해 반영합니다</span>

unconstraining_bijectors <span style="color:#f92672">=</span> [
    tfp<span style="color:#f92672">.</span>bijectors<span style="color:#f92672">.</span>AffineScalar(<span style="color:#ae81ff">100.</span>),
    tfp<span style="color:#f92672">.</span>bijectors<span style="color:#f92672">.</span>Identity()
]

<span style="color:#75715e"># 우리의 joint_log_prob에 대해 클로저를 정의합니다</span>
unnormalized_posterior_log_prob <span style="color:#f92672">=</span> <span style="color:#66d9ef">lambda</span> <span style="color:#f92672">*</span>args: challenger_joint_log_prob(D, temperature_, <span style="color:#f92672">*</span>args)

<span style="color:#75715e"># step_size를 정의합니다.</span>
step_size <span style="color:#f92672">=</span> <span style="color:#ae81ff">0.01</span>

<span style="color:#75715e"># HMC를 정의합니다</span>
hmc<span style="color:#f92672">=</span>tfp<span style="color:#f92672">.</span>mcmc<span style="color:#f92672">.</span>SimpleStepSizeAdaptation(
    tfp<span style="color:#f92672">.</span>mcmc<span style="color:#f92672">.</span>TransformedTransitionKernel(
    inner_kernel<span style="color:#f92672">=</span>tfp<span style="color:#f92672">.</span>mcmc<span style="color:#f92672">.</span>HamiltonianMonteCarlo(
        target_log_prob_fn<span style="color:#f92672">=</span>unnormalized_posterior_log_prob,
        num_leapfrog_steps<span style="color:#f92672">=</span><span style="color:#ae81ff">40</span>, <span style="color:#75715e">#to improve convergence</span>
        step_size<span style="color:#f92672">=</span>step_size,
        state_gradients_are_stopped<span style="color:#f92672">=</span>True),
    bijector<span style="color:#f92672">=</span>unconstraining_bijectors),
    num_adaptation_steps<span style="color:#f92672">=</span>int(burnin <span style="color:#f92672">*</span> <span style="color:#ae81ff">0.8</span>))



<span style="color:#75715e"># Sampling from the chain.</span>
[
    posterior_alpha,
    posterior_beta
], kernel_results <span style="color:#f92672">=</span> tfp<span style="color:#f92672">.</span>mcmc<span style="color:#f92672">.</span>sample_chain(
    num_results <span style="color:#f92672">=</span> number_of_steps,
    num_burnin_steps <span style="color:#f92672">=</span> burnin,
    current_state<span style="color:#f92672">=</span>initial_chain_state,
    kernel<span style="color:#f92672">=</span>hmc)
</code></pre></div><pre><code>WARNING:tensorflow:From &lt;ipython-input-35-90a8c36ea8e0&gt;:14: AffineScalar.__init__ (from tensorflow_probability.python.bijectors.affine_scalar) is deprecated and will be removed after 2020-01-01.
Instructions for updating:
`AffineScalar` bijector is deprecated; please use `tfb.Shift(loc)(tfb.Scale(...))` instead.
</code></pre>
<p>2-4) 만들어진 모델 실행</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">%%</span>time
<span style="color:#75715e"># 그래프 모드에서 이것은 15분 이상 걸릴 수도 있습니다.</span>

[
    posterior_alpha_,
    posterior_beta_,
    kernel_results_
] <span style="color:#f92672">=</span> evaluate([
    posterior_alpha,
    posterior_beta,
    kernel_results
])
</code></pre></div><pre><code>CPU times: user 1.8 ms, sys: 905 µs, total: 2.7 ms
Wall time: 4.34 ms
</code></pre>
<p>2-5) $\alpha$와 $\beta$의 scatter plot그리기</p>
<p>샘플 뽑기</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">alpha_samples_ <span style="color:#f92672">=</span> posterior_alpha_[:, None]
beta_samples_ <span style="color:#f92672">=</span> posterior_beta_[:, None]
</code></pre></div><p>그래프 그리기</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">plt<span style="color:#f92672">.</span>figure(figsize(<span style="color:#ae81ff">12.5</span>, <span style="color:#ae81ff">4</span>))
 
plt<span style="color:#f92672">.</span>scatter(alpha_samples_, beta_samples_, alpha<span style="color:#f92672">=</span><span style="color:#ae81ff">0.1</span>)
plt<span style="color:#f92672">.</span>title(<span style="color:#e6db74">&#34;Why does the plot look like this?&#34;</span>)
plt<span style="color:#f92672">.</span>xlabel(<span style="color:#e6db74">r</span><span style="color:#e6db74">&#34;$\alpha$&#34;</span>)
plt<span style="color:#f92672">.</span>ylabel(<span style="color:#e6db74">r</span><span style="color:#e6db74">&#34;$\beta$&#34;</span>);
</code></pre></div><p><img src="https://user-images.githubusercontent.com/57588650/92462296-44b9b180-f205-11ea-8e14-17f97b38567e.png" alt="output_49_0"></p>
<p>완연한 음의 상관관계를 띄고 있습니다. $\alpha$가 커질 수록 $\beta$는 작아지는 경향이죠. 앞장의 logistic function에서 봤을 때 $\beta$는 커질 수록 더 가파른 모양이 되고 $\beta$가 양수일 때 $\alpha$는 클 수록 왼쪽, 작을 수록 오른쪽으로 편향되게 됩니다. 그렇게 때문에 자연스럽게 $\alpha$가 작아지면 그래프를 오른쪽으로 당기는 형상이 되기 때문에 더 가팔라지게, 즉 $\beta$가 커지게 됩니다.</p>

		</div>
		<footer class="post__footer">
			
<div class="post__tags tags clearfix">
	<svg class="tags__badge icon icon-tag" width="16" height="16" viewBox="0 0 32 32"><path d="M32 19c0 1-1 2-1 2L21 31s-1 1-2 1-2-1-2-1L2 16c-1-1-1.4-2-1.4-2S0 12.5 0 11V3C0 1.5.8.8.8.8S1.5 0 3 0h8c1.5 0 3 .6 3 .6S15 1 16 2l15 15s1 1 1 2zM7 10a3 3 0 1 0 0-6 3 3 0 0 0 0 6z"/></svg>
	<ul class="tags__list">
		<li class="tags__item">
			<a class="tags__link btn" href="/tags/bayesian/" rel="tag">Bayesian</a>
		</li>
		<li class="tags__item">
			<a class="tags__link btn" href="/tags/tensorflow/" rel="tag">TensorFlow</a>
		</li>
		<li class="tags__item">
			<a class="tags__link btn" href="/tags/python/" rel="tag">Python</a>
		</li>
	</ul>
</div>
		</footer>
	</article>
</main>

<div class="authorbox clearfix">
	<div class="authorbox__header">
		<span class="authorbox__name"></span>
	</div>
</div>



			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2021 Tai Hwan Oh.
			<span class="footer__copyright-credits"></span>
		</div>
	</div>
</footer>
	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>